###
You have an Azure subscription named Sub1. Sub1 contains two resource groups named RG1 and RG2.
You need to ensure that Global Administrators can manage all resources contained in RG1 and RG2.
Solution: From the Azure Active Directory Properties blade, you enable Access management for Azure resources.
Does this solution meet the goal?
---
No
Yes *
---
This solution does meet the goal. The Access management for Azure resources property, located in the Azure Active Directory (Azure AD) tenant's settings, ensures that Azure AD users assigned to the Global Administrator role maintain full control over all subscription resources in the event that the identity is removed from Azure resource-level access lists. In keeping with least-privilege security, Microsoft recommends that you enable this property only when necessary.
---
Elevate access for a Global Administrator in Azure Active Directory;https://docs.microsoft.com/en-us/azure/role-based-access-control/elevate-access-global-admin
Manage access using RBAC and the Azure portal;https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-portal
Manage app and resource access using Azure Active Directory groups;https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-manage-groups
Administrator role permissions in Azure Active Directory;https://docs.microsoft.com/en-us/azure/active-directory/users-groups-roles/directory-assign-admin-roles
###
You have an Azure subscription named Sub1. Sub1 contains two resource groups named RG1 and RG2.
You need to ensure that Global Administrators can manage all resources contained in RG1 and RG2.
Solution: From the subscription's Access control (IAM) blade, you click Add role assignment.
Does this solution meet the goal?
---
No *
Yes
---
This solution does not meet the goal. Azure Active Directory (Azure AD) permissions are distinct from Azure resource permissions. In this case, you should enable the Access management for Azure resources property from the Azure AD tenant's Properties blade. This property, when enabled, ensures that Azure AD users assigned to the Global Administrators role maintain full resource access even if their account is stripped from resource-level access control lists (ACLs). The Add role assignment button is used to make an addition to that scope's ACL. For instance, you may need to add a new Azure administrator to the Owner role for a subscription, resource group, or resource.
---
Elevate access for a Global Administrator in Azure Active Directory;https://docs.microsoft.com/en-us/azure/role-based-access-control/elevate-access-global-admin
Manage access using RBAC and the Azure portal;https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-portal
Manage app and resource access using Azure Active Directory groups;https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-manage-groups
###
You have an Azure subscription named Sub1. Sub1 contains two resource groups named RG1 and RG2.
You need to ensure that Global Administrators can manage all resources contained in RG1 and RG2.
Solution: From the Azure Active Directory Roles and administrators blade, you modify the Global administrator role properties.
Does this solution meet the goal?
---
No *
Yes
---
This solution does not meet the goal. To ensure that Global Administrators maintain full access to Azure resources, you need to enable the Access management for Azure resources property from the Azure AD tenant's Properties blade.
The only properties of the Global Administrators (or any Azure AD) group that can be modified are the name, description, and membership type field. None of these properties accomplishes the scenario requirement.
---
Elevate access for a Global Administrator in Azure Active Directory;https://docs.microsoft.com/en-us/azure/role-based-access-control/elevate-access-global-admin
Manage access using RBAC and the Azure portal;https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-portal
Manage app and resource access using Azure Active Directory groups;https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-manage-groups
###
You create a Windows Server virtual machine (VM) in an Azure resource group named iaas-rg. You plan to generalize the operating system and capture a system for use in future deployments.
You need to ensure that other administrators make no changes to the virtual machine configuration until you complete the image capture process. You need to enact your solution as quickly as possible.
What should you do?
---
Set a Read only lock at the resource group level. *
Set a Delete lock at the VM level.
Edit the RBAC permissions at the resource group level.
Edit the RBAC permissions at the VM level.
---
Because time is of the essence, you should set a Read only lock at the resource group level. Resource locks in Azure allow you to prevent unwanted changes to Azure resources no matter what the user's privilege level is. For example, even subscription Owners would not be able to resize a VM if the resource has a Read only lock applied to it.
By settings the lock at the VM's parent resource group level, you ensure that other administrators can make no changes to the VM's entire configuration environment, including virtual network interface (vNIC), virtual hard disks (VHDs), and so forth.
We should not set a Delete lock at the VM level for two reasons. First, the Delete resource lock prevents only delete operations, so administrators would be able to undertake other management actions on the VM. Second, a resource-level lock does not affect related VM assets contained in the same resource group.
You should not edit the RBAC permissions at either the resource group or the VM level because the scenario states that you need to enact your solution as quickly as possible. Furthermore, by restricting other administrators' RBAC access, you potentially restrict them from undertaking actions on other VMs to which they should have management access.
---
Lock resources to prevent unexpected changes;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-lock-resources
What is role-based access control (RBAC)?;https://docs.microsoft.com/en-us/azure/role-based-access-control/overview
###
You manage a Windows Server virtual machine (VM) in Azure named prod-vm1. The VM uses managed disk storage, runs Windows Server 2012 R2, and resides in a resource group named prod-west-rg located in the West US region.
You need to move prod-vm1 to a resource group named prod-east located in the East US region.
What should you do?
---
Back up prod-vm1 and restore the VM to the prod-east-rg resource group. Delete the original VM instance. *
Author an Azure Resource Manager (ARM) template that moves prod-vm1 to the prod-east-rg resource group.
Move prod-vm1 to the prod-east-rg resource group by using the Move-AzureRmResource PowerShell cmdlet.
Use azcopy to copy prod-vm1 to the prod-east-rg resource group.
---
You should back up prod-vm1, restore the VM to the prod-east-rg resource group, and then delete the original VM instance. Unfortunately, managed disks are one of the few Azure resources that cannot be moved between resource groups or subscriptions. Because the VM in Azure has so many dependencies, this managed disk restriction means that you are unable to move the entire VM without redeploying the disks and configuration into the new resource group.
You cannot move prod-vm1 to the prod-east-rg resource group by using the Move-AzureRmResource PowerShell cmdlet because the scenario states that the VM uses managed disk storage. If the VM used unmanaged disk storage, the Move-AzureRmResource command could move the VM to another resource group or even another Azure subscription.
You cannot use azcopy to copy prod-vm1 to the prod-east-rg resource group. Azcopy is a cross-platform command-line tool with which you can copy or move binary large object (BLOB) data between storage accounts. In this case, the VM in question uses managed disk storage. Moreover, Azcopy cannot migrate VM configuration, only virtual hard disks (VHDs).
You cannot author an Azure Resource Manager (ARM) template that moves prod-vm1 to the prod-east-rg resource group because it uses managed disk storage.
---
Move resources to new resource group or subscription;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-move-resources
Frequently asked questions about Azure IaaS VM disks and managed and unmanaged premium disks;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/faq-for-disks
Transfer data with the AzCopy on Windows;https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy
Download the template for a VM;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/download-template
Move-AzureRmResource;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/move-azurermresource
###
C
You deploy an application in a resource group named App-RG01 in your Azure subscription.
App-RG01 contains the following components:
* Two App Services, each with an SSL certificate
* A peered virtual network (VNet)
* Redis cache deployed in the VNet
* Standard Load Balancer
You need to move all resources in App-RG01 to a new resource group named App-RG02.
Choose all that apply:
---
You need to delete SSL certificate from each App Service before moving it to the new resource group. *
You can move the Load Balancer only within the same subscription.
You need to disable the peer before moving the VNet. *
You can move the VNet only within the same subscription. *
---
You need to delete the SSL certificate from each App Service before moving it to the new resource group. You cannot move an App Service with an SSL certificate configured. If you want to do that, you need to delete the certificate, move the App Service and then upload the certificate again.
You cannot move the Load Balancer within the same subscription. A Standard Load Balancer cannot be moved either within the same subscription or between subscriptions.
You need to disable the peer before moving the VNet. When you want to move a VNet with a peer configured, you need to disable it before moving the VNet. When you move a VNet, you need to move all of its dependent resources.
You can only move the VNet within the same subscription. When you want to move a VNet, you also need to move all of its dependent resources. In this case, you also need to move the Redis cache, which can be moved only within the same subscription. Because you want to move the resources from App-RG01 to App-RG02, which is in the same subscription, you can move the VNet with no problem.
---
Move resources to new resource group or subscription; https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-move-resources
###
You deploy a Storage Account named store01 in your Azure subscription.
You grant the contributor role to some users in store01. The users work on an application that will use the storage account for storing some information.
The users report that they are not able to list the storage account keys for connecting their application to the storage account.
You need to identify the root cause of the issue.
What is the most probable cause?
---
You need to grant the users the owner role.
You configured a ReadOnly lock. *
You configured a CanNotDelete lock.
You need to grant the users the Storage Account Key Operator Service role.
---
The reason that the users are not able to list the storage account keys is that you configured a ReadOnly lock. Locks are applied to any operation that makes a request to the following URL: https://management.azure.com. When you apply a ReadOnly lock, you can unintentionally block access to other resources. In this case, you are blocking access to the keys because the list operation is handled through POST operations and the returned keys will be used for write operations.
Configuring a CanNotDelete lock does not affect the list keys operation. The CanNotDelete lock prevents a user from deleting a resource but still allows users to modify and read resources in the resource group.
You do not need to grant your users with Owner or Storage Account Key Operator Service roles. When you configure a lock in a resource or resource group, this takes precedence over any assigned role, even the Owner role. If you want to remove the lock, you need to have access to the Microsoft.Authorization/* or Microsoft.Authorization/locks/* actions. Only the Owner and User Access Administrator roles have enough privileges to manage locks. In this scenario, granting the Owner role to your users will enable them to remove the ReadOnly lock on their own.
---
Lock resources to prevent unexpected changes;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-lock-resources
Built-in roles for Azure resources;https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
###
You are the owner of your organization's Microsoft Azure subscription. You hire a new administrator to help you manage a virtual network that contains nine Windows Server virtual machines (VMs). The deployment is contained in a resource group named prod-rg.
You need to provide the administrator with least-privilege access only to the prod-rg resource group. The administrator should be allowed to manage all aspects of the Azure VMs. Your solution should minimize management effort.
What should you do?
---
Assign the Allowed virtual machine SKUs Azure Policy at the resource group scope.
Assign a custom Azure Policy at the management group scope.
Assign the administrator to the Contributor role at the resource group scope. *
Assign the administrator to the Virtual Machine Operator role at the virtual machine scope.
---
You should assign the administrator to the Contributor role at the resource group scope. The Contributor role-based access control (RBAC) role provides the new administrator with full read/write privileges at that scope. Inheritance ensures that the permissions cascade to the VMs within the prod-rg resource group and minimizes management overhead.
You should not assign the administrator to the Virtual Machine Operator role at the virtual machine scope. The Virtual Machine Operator role does not grant the administrator full access to all resources contained on the virtual network. Moreover, making multiple RBAC assignments requires much more management effort than making a single role assignment at a parent scope.
You should not assign the Allowed virtual machine SKUs Azure Policy at the resource group scope. Doing so only restricts the administrator from selecting VM instance stock-keeping units (SKUs) that are defined in the Azure Policy. The scenario states only that the administrator should be able to fully manage existing VMs within the prod-rg resource group.
You should not assign a custom Azure Policy at the management group scope. Azure Policy is a governance feature that restricts the types of resources administrators can select in Azure Resource Manager. In other words, Azure Policy is fundamentally different from RBAC, which limits the ability for administrators to take particular actions in the first place.
---
What is role-based access control (RBAC)?;https://docs.microsoft.com/en-us/azure/role-based-access-control/overview
Classic subscription administrator roles, Azure RBAC roles, and Azure AD administrator roles;https://docs.microsoft.com/en-us/azure/role-based-access-control/rbac-and-directory-admin-roles
What is Azure Policy?;https://docs.microsoft.com/en-us/azure/azure-policy/azure-policy-introduction
Create and manage policies to enforce compliance;https://docs.microsoft.com/en-us/azure/azure-policy/create-manage-policy
###
You determine that business units have Azure resources spread across different Azure resource groups.
You need to make sure that resources are assigned to their proper cost centers.
What should you do?
---
Create taxonomic tags and assign them at the resource level. *
Create taxonomic tags and assign them at the resource group level.
Deploy the Enforce tag and its value on resource groups Azure Policy.
Deploy the Enforce tag and its value Azure Policy.
---
You should create taxonomic tags and assign them at the resource level. Tags in Azure are key-value string pairs that administrators can associate with Azure resources for logical organization. Identifying cost centers is an excellent use case for tags. Because corporate divisions own Azure resources spread across different Azure resource groups, you have to assign cost center tags at the resource level. Wherever possible, it is best practice to organize related resources into the same resource groups because you can then bulk-assign taxonomic tags to all contained resources in a single operation.
You should not create taxonomic tags and assign them at the resource group level. The scenario states that business units have resources spread across different resource groups. If you assign a particular cost center tag at the resource group level, then you likely will mis-tag contained resources owned by another business unit.
You should not deploy the Enforce tag and its value Azure Policy. Doing so enforces the presence of a single specified tag and value pair. In this case, the scenario states that the organization has more than one cost center and therefore needs more than one taxonomic tag.
You should not deploy the Enforce tag and its value on resource groups Azure Policy for the same reasons. The company has more than one cost center, and the business units have resources spread across multiple resource groups.
---
Use tags to organize your Azure resources;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-using-tags
Prevent unexpected charges with Azure billing and cost management;https://docs.microsoft.com/en-us/azure/billing/billing-getting-started
What is Azure Policy?;https://docs.microsoft.com/en-us/azure/azure-policy/azure-policy-introduction
Create and manage policies to enforce compliance;https://docs.microsoft.com/en-us/azure/azure-policy/create-manage-policy
###
You are the cloud operations lead for your company's Microsoft Azure subscription. Your team consists of eight administrators who co-manage all Azure-deployed resources.
The corporate governance team mandates that all future Azure resources be deployed only within certain regions.
You need to meet the compliance requirement.
Which Azure feature should you use?
---
Taxonomic tags
Activity Log Analytics
Role-Based Access Control (RBAC)
Azure Policy *
---
To meet the new compliance requirement, you should deploy Azure Policy. Azure Policy is a governance feature that allows you to enforce requirements at two Azure scopes: the management group and the resource group. For example, you can require that all deployments are constrained to particular regions, or that only certain virtual machine (VM) sizes are allowed.
You should not use RBAC. RBAC focuses on user actions at different scopes. For example, a user may be restricted with RBAC from creating VMs in any Azure region. By contrast, Azure Policy customizes the properties a user can choose during resource deployment.
You should not use taxonomic tags. These key-value pairs are useful for organizing Azure resources (for instance, to identify different cost centers). However, tags have no authorization capability on their own.
You should not use Activity Log Analytics. This management solution aggregates Azure activity log data in a Log Analytics workspace. Specifically, the activity log records control plane activities such as resource creation, but does not enforce authorization.
---
What is Azure Policy?;https://docs.microsoft.com/en-us/azure/azure-policy/azure-policy-introduction
What is role-based access control (RBAC)?;https://docs.microsoft.com/en-us/azure/role-based-access-control/overview
Use tags to organize your Azure resources;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-using-tags
Collect and analyze Azure activity logs in Log Analytics;https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-activity
###
You use taxonomic tags to logically organize resources and to make billing reporting easier.
You use Azure PowerShell to append an additional tag on a storage account named corpstorage99. The code is as follows:
$r = Get-AzureRmResource -ResourceName "corpstorage99" -ResourceGroupName "prod-rg"
Set-AzureRmResource -Tag @{Dept="IT"} -ResourceId $r.ResourceId -Force
The code returns unexpected results.
You need to append the additional tag as quickly as possible.
What should you do?
---
Refactor the code by using the Azure Command-Line Interface (CLI).
Call the Add() method on the resource to append the new tag. *
Deploy the tag by using an Azure Resource Manager template.
Assign the Enforce tag and its value Azure Policy to the resource group.
---
You should call the Add() method on the storage account resource as shown in the second line of this refactored Azure PowerShell code:
$r = Get-AzureRmResource -ResourceName "corpstorage99" -ResourceGroupName "prod-rg"
$r.Tags.Add("Dept", "IT")
Set-AzureRmResource -Tag $r.Tags -ResourceId $r.ResourceId -Force
Unless you call the Add() method, the Set-AzureRmResource cmdlet will overwrite any existing taxonomic tags on the resource. The Add() method preserves existing tags and includes one or more tags to the resource tag list.
You should not deploy the tag by using an Azure Resource Manager template. Doing so is unnecessary in this case because the Azure PowerShell is mostly complete as-is. Furthermore, you must find the solution as quickly as possible.
You should not assign the Enforce tag and its value Azure Policy to the resource group. Azure Policy is a governance feature that helps businesses enforce compliance in resource creation. In this case, the solution involves too much administrative overhead to be a viable option. Moreover, the scenario makes no mention of the need for governance policy in specific terms.
You should not refactor the code by using the Azure Command-Line Interface (CLI). Either Azure PowerShell or Azure CLI can be used to institute this solution. It makes no sense to change the development language given that you have already completed most of the code in PowerShell.
---
Use tags to organize your Azure resources;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-using-tags
Set-AzureRmResource;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/set-azurermresource
What is Azure Policy?;https://docs.microsoft.com/en-us/azure/azure-policy/azure-policy-introduction
Azure CLI;https://docs.microsoft.com/en-us/cli/azure/
Quickstart: Create and deploy Azure Resource Manager templates by using the Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-quickstart-create-templates-use-the-portal
###
C
Your company has an Azure Subscription with several resources deployed. The subscription is managed by a Cloud Service Provider.
The accounting department is currently granted the billing reader role, so they are able to see cost-related information. They need to get a better understanding of the costs so they can assign them to the correct cost center.
You need to provide cost center information. Your solution should minimize the administrative effort.
What two actions should you perform? Each correct answer presents part of the solution.
---
Create a tag named CostCenter and assign it to each resource. *
Instruct the accounting department to use the Cost Analysis blade in the subscription panel.
Instruct the accounting department to use the Azure Account Center.
Create a tag named CostCenter and assign it to each resource group. *
---
You should create a tag named CostCenter and assign it to each resource group. Creating a tag and assigning it to each resource group allows you to easily identify the cost center associated with each resource group. When you associate a tag with a resource or resource group, you need to provide a value to that tag. You can instruct the accounting department to use the Azure Cost Management tool to review the costs associated with each cost center by filtering by the newly created tag.
You should also create a tag named CostCenter and assign it to each resource. If you apply a tag to a resource group, that tag is not inherited by the resources in the resource group. You need to manually configure the tag for each resource that you want to include in the cost center. You can automate this action by using a PowerShell or Azure CLI script.
You should not instruct the accounting department to use either the Cost Analysis blade in the subscription panel or the Azure Account Center. Because your subscription is managed by a Cloud Service Provider, you can get that information from your provider. You can also get this information by using the Azure Cost Management tool.
---
Use tags to organize your Azure resources;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-using-tags
Prevent unexpected charges with Azure billing and cost management;https://docs.microsoft.com/en-us/azure/billing/billing-getting-started
Use tags to organize your Azure resources;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-using-tags
What is Azure Cost Management?;https://docs.microsoft.com/en-us/azure/cost-management/overview-cost-mgt
###
C
Your company requires all resources deployed in Azure to be assigned to a cost center.
You use a tag named CostCenter to assign each resource to the correct cost center. This tag has a set of valid values assigned.
Some of the resources deployed in your subscription already have a value assigned to the CostCenter tag.
You decide to deploy a subscription policy to verify that all resources in the subscription have a valid value assigned.
Choose all that apply:
---
The Deny effect is not evaluated first. *
The Append effect modifies the value of an existing field in a resource.
The Audit effect will create a warning event in the activity log for non-compliant resources. *
The DeployIfNotExists effect is only evaluated if the request executed by the Resource Provider returns a success status code. *
---
The Deny effect is not evaluated first. When a policy is evaluated, the Disabled effect is always evaluated first to decide whether the rule should be evaluated afterwards. The correct order of evaluation of the policy effects is: Disabled, Append, Deny and Audit.
The Append effect does not modify the value of an existing field in a resource. The Append effect adds additional fields during the creation or update of a resource. If the field already exists in the resource and the values in the resource and the policy are different, then the policy acts as a deny and rejects the request.
The Audit effect will create a warning event in the activity log for non-compliant resources. The audit effect is evaluated last before the Resource Provider handles a create or update request. You typically use the audit effect when you want to track non-compliant resources.
The DeployIfNotExists effect is only evaluated if the request executed by the Resource Provider returns a success status code. Once the effect has been evaluated, it is triggered if the resource does not exist or the resource defined by ExistenceCondition is evaluated to false.
---
Understand Policy effects;https://docs.microsoft.com/en-us/azure/governance/policy/concepts/effects
Apply tag and its default value;https://docs.microsoft.com/en-us/azure/governance/policy/samples/apply-tag-def-val
###
You are the lead architect for your company's Microsoft Azure infrastructure.
To maintain corporate compliance certifications, you need to ensure that any virtual machines (VMs) are created only in approved Azure regions.
What should you do?
---
Create an Azure management group.
Enforce conditional access policy in Azure Active Directory (Azure AD).
Define and deploy a custom Azure Policy template. *
Define and deploy an Azure Automation Desired State Configuration (DSC) configuration.
---
You should define and deploy a custom Azure Policy by using JSON and Azure PowerShell. Azure Resource Manager includes a number of predefined policy templates that cover various governance use cases. However, you can also build a custom template and upload it to Azure to make it available in your subscriptions.
You should not define and deploy an Azure Automation DSC configuration. Azure Automation DSC prevents configuration drift on newly deployed or existing Azure or on-premises nodes. This scenario requires that you enforce compliance on VM locations at deployment time.
You should not deploy a management group. A management group is a scope level above the Azure subscription that allows you to assign Azure Policy that affects multiple subscriptions simultaneously. In your case, you need to define a policy in the first place, and then you can optionally scope the new custom policy to a management group.

You should not enforce conditional access policy on Azure Active Directory. This feature affects user accounts, not VMs deployed in Azure. Conditional access allows you to specify requirements for your users to access Azure AD-protected apps. For instance, you might require that users can only authenticate to an app if they are connecting from a corporate IP address.
---
Create and manage policies to enforce compliance;https://docs.microsoft.com/en-us/azure/azure-policy/create-manage-policy
Azure Automation State Configuration Overview;https://docs.microsoft.com/en-us/azure/automation/automation-dsc-overview
What is Azure Policy?;https://docs.microsoft.com/en-us/azure/azure-policy/azure-policy-introduction
Organize your resources with Azure management groups;https://docs.microsoft.com/en-us/azure/azure-resource-manager/management-groups-overview
What is conditional access in Azure Active Directory?;https://docs.microsoft.com/en-us/azure/active-directory/active-directory-conditional-access-azure-portal
###
Your company is developing a line-of-business (LOB) application that uses the Azure IoT Hub for gathering information from Internet of things (IoT) devices.
The LOB application uses the IoT Hub Service SDK to read device telemetry from the IoT Hub.
You need to monitor device telemetry and be able configure alerts based on device telemetry values. Your solution should require the least administrative effort.
What should you do?
---
Enable Azure Monitor resource diagnostics logs on the IoT Hub. *
Use Azure Resource Health.
Use Azure Activity Logs.
Use Azure Application Insights with the LOB application.
---
You should enable Azure Monitor resource diagnostics logs on the IoT Hub. Resource-level diagnostics logs allow you to monitor events that happen inside the resource. Each type of resource provides a different type of events. For the IoT Hub, the event category DeviceTelemetry fits your needs.
You should not use Azure Activity Logs. This service provides information about the actions performed on the resources in a subscription while using Resource Manager. Creating an IoT Hub, listing keys from a storage account, or starting a virtual machine are some examples of the type of activity logging information provided by Activity Logs.
You should not use Azure Resource Health. This service provides information about the high-level health status of the resource or if there is a regional outage. You would use this service to know if the IoT Hub is running or not.
You should not use Azure Application Insights with the LOB application. Application Insights provides information about the application performance while the application is running.
---
Collect and consume log data from your Azure resources;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-of-diagnostic-logs
Supported services, schemas, and categories for Azure Diagnostic Logs;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-diagnostic-logs-schema
What is Application Insights?;https://docs.microsoft.com/en-us/azure/application-insights/app-insights-overview
Azure Resource Health overview;https://docs.microsoft.com/en-us/azure/service-health/resource-health-overview
###
C
Your company has a line-of-business (LOB) application that uses Azure SQL Database for storing transactional information. Your company also has deployed System Center Service Manager.
You need to configure an alert when the database reaches the 70% of CPU usage. When this alert rises, you need to notify several users by email and by SMS. You also need to automatically create a ticket in the ITSM system. Your solution should require the minimum administrative effort.
Which two actions should you perform? Each correct answer presents part of the solution.
---
Configure one Action Group with three actions: one for email notification, one for SMS notification, and one for ITSM ticket creation. *
Configure System Center Service Manager with Azure Automation.
Configure two Action Groups: one Action Group for email and SMS notification and one for ITSM ticket creation.
Configure an IT Service Management Connector (ITSMC). *
---
You should configure an ITSMC. You need configure an ITSM connector for connecting Azure with your System Center Service Manager service. Using this connector, you can create work items in the ITSM system based on alerts.
You should also configure one Action Group with three actions: one for email notification, one for SMS notification, and one for ITSM ticket creation. Once the alert fires, you need to configure the actions that the alert will perform. You can configure several types of actions for the alert, like Azure App Push, Email, SMS, Voice, Runbooks, Logic Apps, ITSM, or Webhooks. You can add several actions to the same action group.
You should not configure two Action Groups. Although you can create two separate action groups with different actions and attach them to the same alert, this would require more administrative effort.
You should not configure System Center Service Manager with Azure Automation. You could configure an Azure Automation Hybrid Worker for running Azure Automation runbooks to create tasks in System Center Service Manager, but this solution would require much more effort.
---
Connect Azure to ITSM tools using IT Service Management Connector;https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-itsmc-overview
Auto Assign SCSM Incidents with Azure Automation;https://blogs.technet.microsoft.com/robdavies/2016/07/12/auto-assign-scsm-incidents-with-azure-automation/
Create and manage action groups in the Azure portal;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-action-groups
Monitoring and performance tuning;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-monitor-tune-overview
###
Your company has an Azure subscription that hosts all services that the company uses in production. The Finance department notices that the bills related to Azure are increasing. The company wants to keep the costs of this Azure subscription under control.
After reviewing the costs analysis reports you realize that there are several virtual machines that are consuming more resources than expected.
You need to inform management when the spend for these resources is unusual.
What should you do?
---
Configure the PowerBI content pack for Azure Enterprise.
Configure a billing alert in the subscription page of the account portal.
Use the costs-by-service blade in the cost analysis section of the subscription.
Configure a report schedule in the Cost Management portal. *
---
You should configure a report schedule in the Cost Management portal. The Cost Management portal allows you to perform detailed cost analysis of your resources. When running a cost report, you can set the filter for the virtual machines that are consuming more resources than expected. Then you can schedule that report to run periodically and send it to a list of recipients. You can also save it to a JSON or CSV report in a Storage Account. Then you can set three different alert levels for the report, one for the green level, one for the yellow level and one for the red level. You need to set the cost thresholds for levels yellow and red.
You should not configure a billing alert in the subscription page of the account portal. This allows you to create alerts based on billing totals or monetary credits that apply to the entire subscription. You cannot configure alerts for specific resources in the subscription.
You should not configure the Power BI content pack for Azure Enterprise. This option allows you to connect your Enterprise Agreement subscription with Power BI for cost analysis. You can create alerts in Power BI if you are using a Power BI Pro license. You also need an Enterprise Agreement subscription.
You should not use the costs-by-service blade in the cost analysis section of the subscription. You can use this section for reviewing the cost analysis per service, but you cannot configure any alert for the service consumption on this page.
---
Tutorial: Review usage and costs;https://docs.microsoft.com/en-us/azure/cost-management/tutorial-review-usage
Azure Cost Management Documentation;https://docs.microsoft.com/en-us/azure/cost-management/
Prevent unexpected charges with Azure billing and cost management;https://docs.microsoft.com/en-us/azure/billing/billing-getting-started
New Power BI content pack for Azure Enterprise users;https://azure.microsoft.com/en-us/blog/new-power-bi-content-pack-for-azure-enterprise-users/
###
C
Your company has a line-of-business (LOB) application that uses Azure SQL Database for storing transactional information. The LOB application also uses Windows and Linux virtual machines for business and presentation application layers.
Some users are reporting errors in the application.
You need to be alerted every time that an exception arises in any part of the application. Your solution should require the minimal administrative effort.
Which two actions should you perform? Each correct answer presents part of the solution.
---
Create an alert using a search query that looks for exceptions in Windows servers. *
Create an alert using a search query that looks for exceptions in business and presentation layer virtual machines.
Create an alert using a search query that looks for exceptions in application layer servers.
Create an alert using a search query that looks for exceptions in business layer servers.
Create an alert using a search query that looks for exceptions in Linux servers. *
---
You should create an alert using a search query that looks for exceptions in Windows servers. You need to use Log Analytics or Application Insight resource types and Log signal types. Then you can write a search query that gets all messages from Windows Events that contains the word "Exception".
You should also create an alert using a search query that looks for exceptions in Linux servers. You use the same configuration as for Windows Events, but you will use Syslog messages.
You should not create an alert using a search query that looks for exceptions in business and presentation layer virtual machines. When creating an alert, you can only select one target type. This means that you can only get information from Windows Events or Syslog, so you will not be able to query both data sources at the same time.
You should not create an alert using a search query that looks for exceptions in application layer servers or in the business layer. You need to query for specific log data sources. Application and business layers is a concept of a design pattern for applications that can be compound of Windows, Linux virtual machines, or other Azure services.
---
Get started with Log Analytics in the Azure portal;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-portal
Create, view, and manage alerts using Azure Monitor;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitor-alerts-unified-usage
Windows event log data sources in Log Analytics;https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-data-sources-windows-events
Syslog data sources in Log Analytics;https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-data-sources-syslog
###
You have a Microsoft Azure subscription that has 8 virtual machines (VMs).
You need to configure monitoring such that when either CPU usage or available memory reaches a threshold value, Azure both notifies administrators via email and creates a new issue in your corporate issue tracker.
What is the minimum number of Azure alerts and action groups you need to meet these requirements?
---
eight alerts and one action group
two alerts and two action groups
one alert and one action group *
one alert and two action groups
---
You should create one alert and one action group. A single alert can contain more than one metric-based condition. By contrast, if you needed alert conditions based on Activity Log events, as of this writing a single alert can contain no more than one Activity Log condition.
A single action group can contain more than one notification or remediation step. An action group is a sequence of actions that Azure takes in response to an alert condition. The Azure ITSM connector links Azure Monitor to your Information Technology Service Management (ITSM) solution to allow Azure to create issue tickets automatically.
---
Overview of alerts in Microsoft Azure;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-alerts
Create and manage action groups in the Azure portal;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-action-groups
Create, view, and manage metric alerts using Azure Monitor;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/alert-metric
Alerts on activity log;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-activity-log-alerts
###
You have 20 Azure subscriptions. All subscriptions are linked to the same Azure Active Directory (Azure AD) tenant named company.com.
You plan to generate detailed usage and spend reports across all Azure subscriptions.
You need to incorporate resource optimization suggestions into your reports.
What should you do?
---
Design metrics charts in Azure Monitor.
Run interactive queries in Azure Log Analytics.
Create a Stream Analytics job in the Azure portal.
Use Cloudyn reports. *
---
You should use Cloudyn reports. Cloudyn is a software-as-a-service (SaaS) product integrated into Azure that enables you to track resource expenditures. Cloudyn also offers in-depth guidance to help you reduce your monthly spend. Cloudyn is an extension of Azure Cost Management, Microsoft's native cost management solution in Azure.
You should not run interactive queries in Azure Log Analytics because the scenario does not state that Azure resources are configured to write their diagnostics data to an Azure Log Analytics workspace. If this were so, then you could indeed use KQL to generate resource cost data. However, Azure Log Analytics does not offer optimization suggestions.
You should not design metrics charts in Azure Monitor because the metrics charting capability does not support ad-hoc queries. Furthermore, you would use not Azure Monitor but Azure Cost Management or Azure Advisor to retrieve cost optimization advice from the Azure platform directly.
You should not create a Stream Analytics job in the Azure portal. Azure Stream Analytics is an event-processing engine that uses a Structured Query Language (SQL)-like syntax to filter and process data extracted from Azure Event Hubs or IoT Hubs.
---
What is the Cloudyn service?;https://docs.microsoft.com/en-us/azure/cost-management/overview
What is Azure Cost Management?;https://docs.microsoft.com/en-us/azure/cost-management/overview-cost-mgt
Analyze Log Analytics data in Azure Monitor;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/log-query-overview
Monitoring data collected by Azure Monitor;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/data-collection
What is Azure Stream Analytics?;https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-introduction
###
You have an Azure resource group named RG1. RG1 contains a Windows Server virtual machine (VM) named VM1.
You plan to use Azure Monitor to configure an alert rule for VM1.
You need to configure an alert that notifies you whenever the VM is restarted.
What should you do?
---
Define an action group with an ITSM action type.
Define an action group with a webhook action type.
Define a metric-based alert condition.
Define an Activity Log alert condition. *
---
You should define an Activity Log alert condition. The Azure Activity Log tracks all control-plane operations that occur within your subscriptions. You can define Azure alert conditions that fire when a particular Azure Activity log event transpires. In this case, you would add the Restart Virtual Machine signal to your alert condition list.
You should not define a metric-based alert condition. Metric-based alerts are triggered when diagnostic measurement data exceeds a given threshold. For instance, you might trigger an alert when the VM's average CPU consumption exceeds 75 percent over a 10 minute period.
You should not define an action group with either a webhook or an IT Service Management (ITSM) action type. Action groups define how Azure responds whenever an alert condition is triggered. In this case you need only a single notification action group to inform you whenever a VM is restarted.
---
Create, view, and manage activity log alerts using Azure Monitor;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/alert-activity-log
Create, view, and manage metric alerts using Azure Monitor;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/alert-metric
Create and manage action groups in the Azure portal;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/action-groups
###
C
You have a website hosted in Azure App Services that is used globally within your company. The website contains a mixture of dynamic and static content.
You are asked to put a Content Delivery Network (CDN) in place to optimize the experience for the end users.
You need to configure the CDN and web app to optimize both dynamic and static content where possible.
What two actions should you perform? Each correct answer presents part of the solution.
---
Implement general web delivery on the CDN.
Implement custom caching rules on the CDN. *
Implement cross origin sharing (CORS) on the website.
Implement dynamic site acceleration (DSA) on the CDN. *
---
You should implement Dynamic Site Acceleration (DSA) on the CDN. DSA adds support for route optimization, TCP optimizations, object prefetch, and adaptive image compression, all of which provide improved performance for dynamically generated content.
You should also implement custom caching rules on the CDN to identify the difference between static and dynamic content. DSA cannot cache content because by nature it is dynamic. In this case, if you implement DSA on the CDN, you need to implement custom caching rules to identify the source of static content, which can be cached within the CDN.
You should not implement general web delivery on the CDN. This will result in caching the static web content but not affect the dynamically generated content.
You should not implement CORS on the website. This allows scripting elements such as JavaScript to interact with the backend platforms in your environment.
---
Dynamic Site Acceleration via Azure CDN;https://docs.microsoft.com/en-us/azure/cdn/cdn-dynamic-site-acceleration
Optimize Azure CDN for the type of content delivery;https://docs.microsoft.com/en-us/azure/cdn/cdn-optimization-overview
Control Azure CDN caching behavior with caching rules;https://docs.microsoft.com/en-us/azure/cdn/cdn-caching-rules
Using Azure CDN with CORS;https://docs.microsoft.com/en-us/azure/cdn/cdn-cors
###
C
You are configuring the XML file specifying the data paths to use. This file will configure the export job to control the data exported. Your file currently looks like this:
<?xml version="1.0" encoding="utf-8"?> 
<BlobList> 
<BlobPath>pictures/animals/kangaroo.jpg</BlobPath> 
<BlobPathPrefix>/vhds/</BlobPathPrefix> 
<BlobPathPrefix>/movies/dramas</BlobPathPrefix> 
</BlobList> 
What will be exported based on the current XML file?
Choose all that apply:
---
You are configuring the XML file specifying the data paths to use. *
Everything in the vhds folder will be exported.
Everything in the dramas folder will be exported.
Files in the vhds folder but not the subfolders will be exported. *
Everything in the movies folder beginning with dramas will be exported. *
---
The Azure import export service has an executable process that can be used to configure the import and export jobs. This process is WAImportExport.exe and can take an XML file as input. Looking at the file supplied and what will happen is as follows.
The <BlobPath> option is used top specify the exact path to a blob file, in this case kangaroo.jpg. This file will be exported.
The <BlobPathPrefix> option indicates a couple of different scenarios. /vhds/ has a trailing slash, which means that everything inside the folder vhds will be exported, without exclusion. All files and folders will be exported.
The /movies/dramas path does not have a trailing slash. This syntax means that everything in the movies folder prefixed by the word dramas will be exported. In this case any file and folder starting with dramas as a prefix will be exported.
---
Use the Azure Import/Export service to export data from Azure Blob storage;https://docs.microsoft.com/en-us/azure/storage/common/storage-import-export-data-from-blobs
###
C
Your company has developed a web application that serves dynamic and static content to users. The application is deployed in several Azure Web Apps in different Azure regions to achieve the best performance.
The Support department for the web application receives complains from users about poor performance of the application.
You review the performance of all components of the application and determine that you need to deploy a Content Delivery Network (CDN).
You need to configure a CDN for achieving the best performance.
What are two ways that you can configure the CDN? Each correct answer presents a complete solution.
---
Configure a single Azure CDN Premium from Verizon endpoint, configure dynamic site acceleration, and configure caching rules.
Configure a single Azure CDN Standard from Akamai endpoint, configure dynamic site acceleration, and configure caching rules. *
Configure a single Azure CDN Standard Microsoft endpoint, configure dynamic site acceleration, and configure caching rules.
Configure a single Azure CDN Standard from Verizon endpoint, configure dynamic site acceleration, and configure caching rules. *
---
You should configure a single Azure CDN Standard from Akamai or Azure CDN Standard from Verizon endpoint, configure dynamic site acceleration (DSA), and configure caching rules. Dynamic site acceleration improves the performance when delivering dynamic content to end users. For static content, you can create cache rules only for the static content. Enabling caching rules for dynamic content may negatively impact dynamic content. Alternatively, you could create two different CDN endpoints, one endpoint optimized with DSA and another endpoint optimized for static content.
You should not configure a single Azure CDN Premium from Verizon endpoint, configure dynamic site acceleration, and configure caching rules. Although you can use this hybrid approach with Azure CDN Premium from Verizon endpoints, caching is configured using a rules engine instead of caching rules.
You should not configure a single Azure CDN Standard Microsoft endpoint, configure dynamic site acceleration, and configure caching rules. This type of CDN endpoint does not allows dynamic site acceleration features.
---
Dynamic site acceleration via Azure CDN;https://docs.microsoft.com/en-us/azure/cdn/cdn-dynamic-site-acceleration
Compare Azure CDN product features;https://docs.microsoft.com/en-us/azure/cdn/cdn-features
Control Azure CDN caching behavior with caching rules;https://docs.microsoft.com/en-us/azure/cdn/cdn-caching-rules
Override HTTP behavior using the Azure CDN rules engine;https://docs.microsoft.com/en-us/azure/cdn/cdn-rules-engine
###
Your company has line-of-business (LOB) application deployed in Azure. This LOB application creates a large amount of information that is stored in a storage account.
To optimize the costs for storage, the LOB application changes the storage tier from hot to archive for those blobs that will not be needed anymore.
You are requested to get the information that the LOB application archived. You decide to create an Azure Export job for getting the archived information.
When creating the export job, you are not able to see the storage account in the list of storage accounts where the data resides.
Why are you not able to see the storage account in the list?
---
You are using a General Purpose V2 storage account. *
You are using a General Purpose V1 storage account.
You are using Azure Files storage.
You are using a Page Blob.
---
You cannot see the storage account in the list because you are using a General Purpose V2 storage account. Only this kind of storage account has different three types of storage tiers: hot, cool, and archive. General Purpose V2 storage accounts are not supported for the Azure Import/Export Service.
General Purpose V1 and Page Blobs storage accounts are supported origins of information when configuring an Export job.
You are not using Azure Files. The LOB application changes the storage tier from hot to archive. This feature is only available on General Purpose V2 storage accounts. Azure Files is not a valid origin of information when configuring an Export job.
---
Use the Azure Import/Export service to export data from Azure Blob; storagehttps://docs.microsoft.com/en-us/azure/storage/common/storage-import-export-data-from-blobs
Azure Import/Export system requirements;https://docs.microsoft.com/en-us/azure/storage/common/storage-import-export-requirements
Azure Blob storage: Premium (preview), Hot, Cool, and Archive storage tiers;https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers
###
C
Your on-premises datacenter has a mixture of servers running Windows Server 2012 R2 Datacenter edition and Windows Server 2016 Datacenter edition.
You need to configure Azure Sync Service between the Azure Files service and the servers in the datacenter.
Which two activities must you complete to ensure that the service will operate successfully on your servers? Each correct answer presents part of the solution.
---
Disable Internet Explorer Enhanced Security for Admins and Users. *
Ensure that the PowerShell version deployed to the servers is at minimum version 5.1. *
Ensure that for fileserver clusters, Azure Active Directory Connect is deployed to at least one server in the cluster.
Disable Internet Explorer Enhanced Security for Admins only.
Ensure that the Windows Identity Framework is deployed to all servers.
---
To enable Azure File Sync, you must disable Internet Explorer Enhanced Security for all admin and user accounts.
Azure File Sync requires a minimum PowerShell version of 5.1. Windows Server 2016 supports that as the minimum default version, but it may have to be installed on Windows Server 2012 R2 servers.
The Windows Identity Foundation and Azure Active directory connect do not need to be installed on the file servers in the environment. Azure Active Directory Connect is used to synchronize on-premises identities to Azure Active Directory (Azure AD) and so is needed in the overall environment, but not on the file servers.
---
Deploy Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-deployment-guide
What is Windows Identity Foundation?;https://msdn.microsoft.com/en-us/library/ee748475.aspx
What is hybrid identity?;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/whatis-hybrid-identity
###
C
You are configuring the Azure File Sync service to synchronize data from your Windows Server failover cluster to Azure Files. Your Windows Server failover cluster is currently configured to support the Scale-Out file server for application data operational mode. The Failover Cluster is set up with data deduplication. The server endpoint is located on the system drive.
The Azure Files Sync service fails to operate on the failover cluster.
You need to rectify the situation.
What two actions should you perform? Each correct answer presents part of the solution.
---
Configure the cluster to support clustered shared volumes.
Move the server endpoint off the system volume.
Disable the deduplication feature of the Windows clustered file server. *
Configure the cluster to support File Server for General Use. *
---
With the Azure File Sync service, only certain cluster configuration types are supported. The File Server for General Use type must be configured on the Windows failover cluster. Scale-Out file server is not supported.
The deduplication feature of the Windows clustered file server must also not be enabled because this is incompatible with the Azure Sync Service.
Clustered shared volumes must not be enabled because these are incompatible with the Azure Sync Service.
The server endpoint being mounted to the system volume is not a problem in this scenario. This would only be a problem if cloud tiering was a requirement or if rapid name space restore was needed. Neither is relevant to the question, so moving the endpoint from the system volume would have no effect here.
---
Planning for an Azure File Sync deployment;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning
###
Your company has a file server that stores important information. The operating system for this file server is Windows Server 2012 R2 Standard Edition. The information is stored in a separate volume from the system volume. To improve security, the volume that stores corporate information is encrypted using BitLocker.
Your company wants to centralize the storage of information and improve the flexibility for accessing the information. You decide to use Azure File Sync for achieving this goal.
You configure an Azure File share and the appropriate firewall rules for allowing access from your company offices.
After configuring the Sync group, you receive an error about the cloud endpoint creation.
What is the most likely cause of the error?
---
You forgot to register the file server with Azure File Sync.
Windows Server 2012 R2 Standard Edition is not supported by the Azure File Sync service.
You are using firewall rules in the storage account. *
You are trying to sync an encrypted volume.
---
You are getting the error while creating the cloud endpoint because you are using firewall rules in the storage account. This is not a supported configuration. You cannot use firewall rules or virtual networks with the storage account that will host the synced data from for on-premises file servers.
You are not getting the error because you forgot to register the file server with Azure File Sync. You can download and install the Azure Storage Sync agent in the file server after configuring the cloud endpoint. Once you install the agent, you need to register the file server with the Azure File Sync service before you can create a server endpoint.
You are not getting the error because you are using Windows Server 2012 R2 Standard Edition. Windows Server 2012 R2 Standard and Datacenter editions as well as Windows Server 2016 Standard and Datacenter editions are supported operating systems for working with the Azure File Sync service.
You are not getting the error because you are trying to sync an encrypted volume. Using encrypted disks with BitLocker is a supported configuration.
---
Planning for an Azure File Sync deployment;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning
Deploy Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-deployment-guide
###
C
Your company deploys an Azure File Sync service. This service syncs with an on-premises file server located on your office. The server stores the information synced with Azure in a volume different from the system volume. The file server has an antivirus solution installed.
You notice that some infrequently accessed files are downloaded to the file server. After monitoring file system access, you determine that no user is accessing to the affected files.
You need to troubleshoot what is happening with those files.
What are two ways of meeting your goal? Each correct answer presents a complete solution.
---
Run the Set-AzureRmStorageSyncServerEndpoint -Id serverendpointid -CloudTiering true -VolumeFreeSpacePercent 60 PowerShell cmdlet.
Run the Test-NetConnection -ComputerName storage-account-name.file.core.windows.net -Port 443 PowerShell cmdlet.
Run the fltmc command at an elevated command prompt.
Review the Application event log. *
Review the Services\Microsoft\FileSync\Agent event log. *
---
You should review the Application or Services\Microsoft\FileSync\Agent event logs. These diagnostics and operational event logs gathers information about sync, recall, and tiering issues. Since you notice that infrequent accessed files are being downloaded to the file server, this means that you have enabled cloud tiering for this server. When cloud tiering is enabled, the Azure File Sync file system filter replaces the actual file with a pointer to the file in the Azure File share where all the data is stored. When a user access to a tiered file, the file is transparently downloaded to the server. This issue could happen when an antivirus solution is not aware of the offline NTFS attribute in the file. This attribute is set to allow third-party applications to identify tiered files.
You should not run the fltmc command at an elevated command prompt. You use the fltmc command to list all filesystem filters loaded in the file server. If the StorageSync.sys and StorageSyncGuard.sys file system filter drivers are not loaded, tiered files are not recalled and downloaded again to the file server. This is not the observed behavior.
You should not run the Test-NetConnection -ComputerName storage-account-name.file.core.windows.net -Port 443 PowerShell cmdlet. You use the Test-NetConnection cmdlet to check the connectivity with a computer. If you use the Fully Qualified Domain Name, you are also checking the DNS resolution. You can check the connectivity to a TCP port if you use the -Port parameter.
You should not run the Set-AzureRmStorageSyncServerEndpoint -Id serverendpointid -CloudTiering true -VolumeFreeSpacePercent 60 PowerShell cmdlet. You use this cmdlet to enable cloud tiering on a server endpoint. You have already enable cloud tiering on this server.
---
Troubleshoot Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-troubleshoot
Planning for an Azure File Sync deployment;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning
FLTMC.exe;https://ss64.com/nt/fltmc.html
###
C
You have a Windows Server 2012 R2 file server deployed in your on-premises infrastructure. You want to deploy a file server hybrid solution. You decide to use Azure File Sync.
Choose all that apply:
---
You can use cloud tiering with server endpoints on the system volume.
The Data tiering free space policy apply to each server endpoint individually.
For tiered files, the media file type will be partially downloaded as needed. *
The free space policy takes precedence over any other policy. *
You can sync files in a mount point inside a server endpoint.
---
You cannot use cloud tiering with server endpoints on the system volume. You can create endpoints on the system volume, but those files will not be tiered. This means that all files in the server endpoint will be synced with the configured cloud endpoint.
The Data tiering free space policy does not apply to each server endpoint individually. You can configure a policy for each server endpoint individually, but the most restrictive free space policy applies to the entire volume. This means that if you configure two server endpoints in the same volume with two distinct policies, for example 20% and 40%, the 40% of free space policy will be applied. The free space tiering policy forces the sync system to start tiering, or moving data to the cloud, when the free space limit is reached. When the sync system tiers a file, it creates a pointer in the file system, and the actual data is moved to Azure. You can still list the tiered file, but the real data is no longer stored on your local disk.
For tiered files, the media file type will be partially downloaded as needed. When you try to access to a tiered file, it automatically downloads the entire file transparently. The exception is for those file types than can be read even if the data has not been completely downloaded, like media files or zip files.
The free space policy takes precedence over any other policy. You can configure date and free space policies on the same server endpoint, but the free space policy will always have precedence over the date policy. This means that if you configure a 60-day date policy and a 50% free space policy for the same server endpoint, and the volume reaches 50% of free space, the sync system will tier the files that have been unmodified for more time (coolest files), even if they were modified fewer than 60 days ago.
You cannot sync files in a mount point inside a server endpoint. You can use a mount point as a server endpoint, but you cannot have mount points inside a server endpoint. In this case, all files in the server endpoint will be synced except those files stored inside each mountpoint in the endpoint.
---
Planning for an Azure File Sync deployment;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning
Cloud Tiering Overview;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-cloud-tiering
###
C
You have several Windows Server 2012 R2 file servers deployed in your on-premises infrastructure. You want to deploy a file server hybrid solution. You decide to use Azure File Sync with some of your file servers.
You configure two Azure File Storage accounts for this purpose. You are configuring the Azure File Sync.
Choose all that apply:
---
You can use more than one Azure file share in the same sync group.
A server can sync with multiple sync groups.
Changes made directly on the file share can take up to 24 to be synced. *
Pre-seeding is the best approach for doing the first synchronization.
---
You cannot use more than one Azure file share in the same sync group. An Azure file share is represented by a cloud endpoint. You can only have one cloud endpoint per sync group. You can add as many server endpoints as you want. You should think of sync groups as the replication hub in the sync process.
A server can sync with multiple sync groups. You can configure as many server endpoints as you need in a single server and each endpoint can be synced with different sync groups. This means that you can have the same server synced with a different sync group as long as you use different server endpoints. Remember that you cannot use NAS or mounted shares as server endpoints, and tiering will be applied only to those endpoints that are not stored in a system volume.
Changes made directly on the file share can take up to 24 to be synced. You can make changes directly on an Azure file share that is a member of a sync group, but you should bear in mind that this change will not be effective until the change is discovered by the Azure File Sync change detection job that runs every 24 hours. This means that, in the worst case, a change made directly on the Azure file share can take up to 24 to be synced.
Pre-seeding is not the best approach for doing the first synchronization. When you onboard with Azure File Sync you typically prefer to have a zero-downtime synchronization. You can achieve this by using only one server that hosts the dataset that you will sync and perform the first synchronization with this server. Once this first synchronization is done, you can add any additional server to the sync group. If you use pre-seeding, you need to manually copy all the datasets to the Azure file share using a mechanism like SMB copy or Robocopy. If you decide to use this method, you need to ensure that you can afford the downtime and that there will not be any changes to the dataset.
---
Deploy Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-deployment-guide?tabs=powershell
###
C
You have an Azure subscription that contains a storage account.
Your on-premises environment includes six file servers that host a total of 12 file shares.
You need to meet the following technical requirements:
* Requirement 1: Reduce the storage footprint of the on-premises file servers.
* Requirement 2: Provide fault tolerance for the on-premises file shares.
* Requirement 3: Secure the hybrid cloud connection with IPSec.
You plan to configure Azure File Sync.
Choose all that apply:
---
Azure File Sync meets technical requirement 1. *
Azure File Sync meets technical requirement 2. *
Azure File Sync meets technical requirement 3.
---
Azure File Sync meets technical requirement 1. Azure File Sync reduces the storage footprint of the on-premises file servers. Cloud tiering is an Azure File Sync feature that generates a heat map of on-premises file share data and archives infrequently accessed files to the cloud endpoint, thus freeing up local disk storage on your file servers.
Azure File Sync meets technical requirement 2. Azure File Sync provides fault tolerance for the on-premises file shares. If a file server goes offline, you can easily restore its file shares to another file server simply by reconfiguring your Azure File Sync sync group.
Azure File Sync does not meet technical requirement 3. Azure File Sync does not secure the hybrid cloud connection with IPSec. Instead, Azure File Sync communicates over Transmission Control Protocol (TCP) 443 using Secure Sockets Layer (SSL). By contrast, IPSec is used with Azure site-to-site virtual private network (VPN) connections.
---
Planning for an Azure File Sync deployment;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning
Deploy Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-deployment-guide?tabs=portal
Create a Site-to-Site connection in the Azure portal;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-portal
###
C
You have a Microsoft Azure subscription that contains a storage account.
Your on-premises environment includes six file servers that host a total of 12 file shares. These file shares are consolidated in a Distributed File System Replication (DFS-R) configuration.
You plan to deploy Azure File Sync to centralize the distributed file shares in Azure and to enable cloud tiering. You configure Azure File Sync as follows:
* Two Storage Sync Service instances with 6 file servers in each instance
* Four Sync Groups
* Two cloud endpoints
Choose all that apply:
---
All servers in the topology can sync with each other
The topology requires six registered servers. *
You need to decommission the DFS-R environment before enabling Azure File Sync
---
All servers in the topology cannot sync with each other because your topology includes two Storage Sync Service instances. Only servers registered within a single Storage Sync Service instance and Sync Group can sync with each other.
The topology requires six registered servers. You need to install the Azure File Sync agent on every local file server and register each with its respective Sync Group.
You do not need to decommission the DFS-R environment before enabling Azure File Sync because Azure File Sync supports DFS-R environments.
---
Planning for an Azure File Sync deployment;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning
Deploy Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-deployment-guide?tabs=portal
###
You are asked to configure an Azure storage account to be accessible from only one specific Virtual Network in an Azure Virtual Network (VNet). It must not be accessible from any other network or region in use across your company's Azure subscription.
You need to implement this requirement.
What should you do?
---
Add a network security group.
Create a VNet service endpoint. *
Deploy Azure Traffic Manager.
Activate the Secure transfer required option.
---
You should implement a VNet service endpoint. Service endpoints are used to limit the network access to a specific set of resources. To meet the requirement, you can implement a storage endpoint on an Azure Resource Manager deployed storage account to restrict the access to a specific VNet and exclude access from all other resources including the Internet and on-premises connected resources.
You should not add a network security group. This is used to limit the access to the resources within a VNet by implementing rules such as IP filters and role based access control. It cannot restrict access to a storage account by itself.
You should not deploy Azure Traffic Manager. This is used to control the flow of network traffic into and out of Azure networks. It cannot restrict access to a storage account by itself.
You should not activate the Secure transfer required option. This feature forces all the traffic into and out of the storage account to be secured over HTTPS instead of allowing fallback to HTTP.
---
Virtual Network Service Endpoints;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview
Security groups;https://docs.microsoft.com/en-us/azure/virtual-network/security-overview
Traffic Manager;https://docs.microsoft.com/en-us/azure/traffic-manager/
Require secure transfer in Azure Storage;https://docs.microsoft.com/en-gb/azure/storage/common/storage-require-secure-transfer
###
C
You manage several Windows Server virtual machines (VMs) located in a virtual network (VNet) named prod-vnet. These VMs are used internally by development staff and are not accessible from the Internet.
You need to provide your development staff with secure access to object and table data to support their Azure-based applications. The storage account data reside in Azure, but must not be exposed to the Internet.
What two actions should you perform? Each correct answer presents part of the solution.
---
Configure a service endpoint. *
Deploy a blob storage account.
Deploy an Azure File Sync sync group.
Configure a point-to-site (P2S) virtual private network (VPN).
Deploy a general-purpose storage account. *
Configure an Azure Content Delivery Network (CDN)profile.
---
You should deploy a general-purpose storage account, and then configure a service endpoint. A general-purpose storage account consists of four services, two of which are called for in the scenario:
* Binary large object (blob) object storage
* Table (key-value pair) storage
* Queue (messaging) storage
* File (Server Message Block (SMB) file share) storage
Service endpoints allow you to bind certain Azure services, including storage accounts and Azure SQL Databases, to a VNet in order to restrict their access. In this scenario, you would create a service endpoint on prod-vnet to allow the Microsoft.Storage resource provider access. You would then complete the configuration by associating the storage account with the target VNet.
You should not deploy a blob storage account because a blob storage account has only one service and the scenario requires both object and table storage to support your developers. The blob storage account includes access tiers that save costs on cool and cold storage (archival) for block blobs such as documents or media files.
You should not deploy an Azure File Sync sync group. Azure File Sync is a mechanism to offer tiered and synchronized storage for on-premises Server Message Block (SMB) file shares. This feature meets none of the scenario's requirements.
You should not configure a CDN profile. CDN profiles are used in conjunction with Azure App Service web applications to deliver static website assets to worldwide customers with low latency.
You should not configure a P2S VPN. A P2S VPN is appropriate when you need to give individual users a secure connection to an Azure VNet. In this case you are concerned with providing secure access from the VNet to a storage account.
---
Introduction to Azure Storage;https://docs.microsoft.com/en-us/azure/storage/common/storage-introduction

Virtual Network Service Endpoints;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview

What is a content delivery network on Azure?;https://docs.microsoft.com/en-us/azure/cdn/cdn-overview

About Point-to-Site VPN;https://docs.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about

Deploy Azure File Sync;https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-deployment-guide?tabs=portal
###
You create a binary large object (blob) storage account named reportstorage99 that contains archival reports from past corporate board meetings.

A board member requests access to a specific report. The member does not have an Azure Active Directory (Azure AD) user account. Moreover, he has access only to a web browser on his Google Chromebook device.

You need to provide the board member with least-privilege access to the requested report while maintaining security compliance and minimizing administrative overhead.

What should you do?
---
Create an Azure AD account for the board member and grant him role-based access control (RBAC) access to the storage account.
Deploy a point-to-site virtual private network (VPN)connection on the board member's Chromebook and grant the board member role-based access control (RBAC) access to the report.
Copy the report to an Azure File Service share and provide the board member with a PowerShell connection script.
Generate a shared access signature (SAS) token for the report and share the Uniform Resource Locator (URL) with the board member. *
---
You should generate an SAS token for the report and share the URL with the board member. SAS enables you to define time-limited read-only or read-write access to Azure storage account resources. It is important that you set the time restriction properly because the SAS includes no authentication. Any person with access to the URL can access the target resource(s) within the token's lifetime.  In this case, you both minimize administrative effort as well as maintain security compliance because the SAS token points only to a single file, not the entire blob container that hosts the requested report.

You should not create an Azure AD account for the board member and grant him RBAC access to the storage account. First, it requires significant management overhead to create and manage Azure AD accounts, even for external (guest) users. Second, SAS and not RBAC is the way Azure provides screened access to individual storage account resources. You can use RBAC roles only at the storage account scope.

You should not copy the report to an Azure File Service share and provide the board member with a PowerShell connection script. Here you create security and governance problems by creating multiple copies of the source report, as well as producing unnecessary administrative complexity.

You should not deploy a point-to-site (P2S) VPN connection on the board member's Chromebook and grant the board member RBAC access to the report. The scenario stipulates that the board member is limited to using a web browser on his Chromebook. Furthermore, the Azure P2S VPN client is supported only on Windows, macOS, and endorsed Linux distributions. Chrome OS is not supported.
---

Using shared access signatures (SAS);https://docs.microsoft.com/en-us/azure/storage/common/storage-dotnet-shared-access-signature-part-1

Manage access for external users using RBAC;https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-external-users

What is Azure Files?;https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction

About Point-to-Site VPN;https://docs.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about
###
The development team asks you to provision an Azure storage account for their use.

To remain in compliance with IT security policy, you need to ensure that the new Azure storage account meets the following requirements:

* Data must be encrypted at rest.
* Access keys must facilitate automatic rotation.
* The company must manage the access keys.

What should you do?
---
Require secure transfer for the storage account.
Enable Storage Service Encryption (SSE) on the storage account.
Create a service endpoint between the storage account and a virtual network (VNet).
Configure the storage account to store its keys in Azure Key Vault. *
---
You should configure the storage account to store its keys in Azure Key Vault. Azure Key Vault provides a mechanism to store secrets, such as storage account keys, user credentials, and digital certificates, securely in the Microsoft Azure cloud. You can access the underlying Representational State Transfer (REST) application programming interface (API) to rotate or retrieve the secrets in your source code.

You should not enable SSE on the storage account for two reasons. First, SSE is enabled automatically on all Azure storage accounts and encrypts all storage account data at rest. Second, SSE in its native form uses Microsoft-managed access keys, which violates the scenario constraint for customer-managed keys.

You should not require secure transfer for the storage account. Secure transfer forces all REST API calls to use HTTPS instead of HTTP. This feature has nothing to do with either access keys or their management and rotation.

You should not create a service endpoint between the storage account and a VNet. A service endpoint allows you limit traffic to a storage account from resources residing on an Azure VNet.
---
Storage Service Encryption using customer-managed keys in Azure Key Vault;https://docs.microsoft.com/en-us/azure/storage/common/storage-service-encryption-customer-managed-keys
Azure Storage Service Encryption for Data at Rest;https://docs.microsoft.com/en-us/azure/storage/common/storage-service-encryption
Require secure transfer in Azure Storage;https://docs.microsoft.com/en-us/azure/storage/common/storage-require-secure-transfer
Virtual Network Service Endpoints;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview
###
C
Your company is developing a .NET application that stores part of the information in an Azure Storage Account. The application will be installed on end user computers.

You need to ensure that the information stored in the Storage Account is accessed in a secure way. You ask the developers to use a shared access signature (SAS) when accessing the information in the Storage Account. You need to make the required configurations on the storage account to follow security best practices.

Choose all that apply:
---
You need to configure a stored access policy. *
You should set the SAS start time to now.
You should validate data written using SAS. *
One option for revoking a SAS is by deleting a stored access policy. *
---
You need to configure a stored access policy. When you use SAS, you have two different options. You can either use ad-hoc SAS or configure a stored access policy. By using ad-hoc SAS, you specify the start time, expiration time, and permission in the URI. If someone copies this URI, they will have the same level of access as the corresponding user. This means that this type of SAS can be used by anyone in the world. By configuring a stored access policy, you define the start time, expiration time, and permissions in the policy and then associate a SAS with the policy. You can associate more than one SAS with the same policy.

You should not set the SAS start time to now. When you set the start time of a SAS to now, there can be subtle differences in the clock of the servers that host the Storage Account. These differences could lead to an access problem for a few minutes after the configuration. If you need your SAS to be available as soon as possible, you should set the start time 15 minutes before the current time, or you can just not set the start time. Not setting the start time parameter means that the SAS will be active immediately.

You should validate data written using SAS. The information written to the storage account when the user uses a SAS can cause problems, such as communication issues or corruption. Because of this, it is a best practice to validate the data written to the storage account after it is written and before the information is used by any other service or application.

You can revoke a SAS by deleting a stored access policy. If you associate a SAS with a stored access policy, the start time, expiration time, and permission are inherited from the policy. If you remove the policy, you are invalidating the SAS and thus making it unusable. Keep in mind that if you remove a stored access policy with associated SAS and then create another stored access policy with the exact same name as the original policy, the associated SAS will be enabled again.
---

Using shared access signatures (SAS);https://docs.microsoft.com/en-us/azure/storage/common/storage-dotnet-shared-access-signature-part-1
###
Your company wants to configure a storage account.

You need to ensure that the storage is available in case of failure of an entire datacenter. You also need to move the data to different access tiers depending on the frequency of access. Your solution needs to be the most cost-effective.

What type of storage should you configure?
---
Read-Access Geo Redundant Storage (RA-GRS)
Geo Redundant Storage (GRS)
Local Redundant Storage (LRS)
Zone Redundant Storage (ZRS) *
---
You should configure a storage account with ZRS replication. This type of replication makes a synchronous copy of the data between three different availability zones in the same region. Each availability zone is autonomous from the others and has separate networking and utility features. Because you also need to be able to move data between different access tiers based on the data access frequency, you need to configure a General Purpose v2 storage account. This is the most cost-effective solution.

You should not configure the storage account with LRS replication. This type of replication makes a copy of the data between different storage scale units inside the same datacenter. This type of replication is not resilient to a datacenter failure.

You should not configure the storage account with GRS or RA-GRS. This type of replication makes your data available in case of a datacenter or regional failure. This type of replication makes your data resilient to a datacenter failure but is not the most cost-effective solution.
---

Azure Storage replication;https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy
###
C
You have performed a lift and shifted migration of several Windows Servers to Azure Infrastructure as a Service (IaasS).

You need to configure the servers to support Azure Backup.

What are two ways of achieving your goal? Each correct answer presents a complete solution.
---
Execute the Backup-AzureRmBackupItem PowerShell cmdlet.
Install the Azure VM Agent on the migrated VMs. *
Install the Azure VM Backup Agent on the migrated VMs. *
Enable Backup via the Backup Blade in the Azure VM Configuration Panel.
---
When you lift and shift VMs from on premises to Azure IaaS, the VMs do not have the prerequisites to setup backup operations in Azure. Before you can setup backup operations, you have to perform one of two actions.

You can install the Azure VM Agent on the migrated VMs. This will also deploy the Azure VM Backup Agent on the VMs by default. You can also manually deploy the Azure VM Backup Agent on the migrated VMs. Both options will result in a VM that can be configured for Azure VM Backup protection.

You should not enable Backup via the Backup Blade in the Azure VM Configuration Panel. This option cannot be used unless the VM already have the Backup Agent deployed first.

You should not execute the Backup-AzureRmBackupItem cmdlet. This cmdlet can run a non-policy based backup activity but also requires the Azure Backup Agent to have been deployed on the VM being targeted for backup.
---

Back up a Windows Server or client to Azure using the Resource Manager deployment model;https://docs.microsoft.com/en-us/azure/backup/backup-configure-vault

Back up VMs to Recovery Services vault;https://docs.microsoft.com/en-us/azure/backup/backup-azure-vms-first-look-arm

Backup-AzureRmBackupItem;https://docs.microsoft.com/en-us/powershell/module/azurerm.backup/backup-azurermbackupitem
###
You are tasked with managing the corporate Microsoft Azure subscription. Presently, a site-to-site virtual private network (VPN) connects the company's on-premises network infrastructure to a virtual network (VNet) named prod-vnet.

You need to implement a backup strategy for nine virtual machines (VMs) located on prod-vnet.

What should you do first?
---
Define an Azure Site Recovery (ASR) recovery plan.
Deploy Azure Backup Server in your on-premises environment.
Create a Recovery Services vault. *
Install the VM Backup extension on the Azure-based VMs.
---
The first thing you should do is create a Recovery Services vault in Azure. The Recovery Services vault is a Microsoft-managed disaster backup repository that is used both by Azure VM Backup and Azure Site Recovery (ASR).

You do not need to install the VM Backup extension on the Azure-based VMs. Azure automatically distributes the VM extension to any VMs that you associate with a Recovery Services vault.

You should not deploy Azure Backup Server in your on-premises environment. Azure Backup Server is a specialized edition of System Center Data Protection Manager (DPM) and is used to back up on-premises workloads to Azure.

You should not define an ASR recovery plan. ASR is a migration and data replication feature, and is not used for a basic backup and restore disaster recovery (DR) scenario.
---
Back up Azure virtual machines to Recovery Services vault;https://docs.microsoft.com/en-us/azure/backup/backup-azure-vms-first-look-arm

Prepare to back up Azure VMs;https://docs.microsoft.com/en-us/azure/backup/backup-azure-arm-vms-prepare

Install and upgrade Azure Backup Server;https://docs.microsoft.com/en-us/azure/backup/backup-azure-microsoft-azure-backup

Create and customize recovery plans;https://docs.microsoft.com/en-us/azure/site-recovery/site-recovery-create-recovery-plans
###
You back up all Azure-based virtual machines (VMs) to a Recovery Services vault. One of these VMs is a Windows Server 2016 domain member server named app1 that hosts an internally developed line of business (LOB) web application.

A developer informs you that she needs to review three-month-old log files stored on app1. You need to retrieve these files as efficiently as possible.

What should you do?
---
Download the appropriate virtual hard disk (VHD) files from the Recovery Services vault to your administrative workstation.
Retrieve the files from the appropriate backed-up virtual hard disks (VHDs) by using Azure Storage Explorer.
Mount the virtual hard disks (VHDs) from the relevant VM backup as drives on your administrative workstation. *
Make a Remote Desktop Protocol (RDP) connection to app1 and use the Previous Versions feature to restore the requested log files.
---
To retrieve the old log files as efficiently as possible, you should use Azure File Recovery to mount the backed-up VHDs as drives on your administrative workstation. The process works like this:

* In the Recovery Services vault, start File Recovery.
* Select the appropriate recovery point.
* Download and run the provided PowerShell script. The script mounts the operating system and data VHDs as local drives on your administrative system.
* Retrieve the necessary files from the app1 file system.
* Disconnect the network drive mappings.

You should not download the appropriate VHD files from the Recovery Services vault to your administrative workstation. Azure File Recovery makes this step unnecessary. Likewise, you should not have to restore the VHDs or the entire VM to an alternate location in order to recover individual files from its file system.

You should not retrieve the files from the appropriate backed-up VHDs by using Azure Storage Explorer. Storage Explorer is a cross-platform desktop application that makes it easy to interact with Azure storage accounts. Recovery Services vaults do not expose their contents to Storage Explorer.

You should not make an RDP connection to app1 and use the Previous Versions feature to restore the requested log files. First, you need to work as efficiently as possible. Second, there is no guarantee that the server's current run state has three months' worth of log files.
---

Recover files from Azure virtual machine backup;https://docs.microsoft.com/en-us/azure/backup/backup-azure-restore-files-from-vm

Recovery Services vaults overview;https://docs.microsoft.com/en-us/azure/backup/backup-azure-recovery-services-vault-overview

Get started with Storage Explorer;https://docs.microsoft.com/en-us/azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows

Tip: Create and Restore Shadow Copies on Windows Server 2008;https://technet.microsoft.com/en-us/library/dd637757.aspx
###
You have an Azure resource group named RG1. RG1 contains a Linux virtual machine (VM) named VM1.

You need to automate the deployment of 20 additional Linux VMs. The new VMs should be based upon VM1's configuration.

Solution: From the virtual machine's Automation script blade, you click Deploy.

Does this solution meet the goal?
---
No
Yes *
---
The solution meets the goal. Every deployment in Azure is described in a template in JavaScript Object Notation (JSON) format. You can access the underlying template from the Automation script blade of the VM resource, and can then deploy multiple new instances of a resource by modifying the template parameters. Optionally, you can store customized Azure Resource Manager templates directly in the Azure portal from the Templates blade.
---

Deploy resources with Resource Manager templates and Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-portal

Download the template for a VM;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/download-template

Create a Windows virtual machine from a Resource Manager template;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ps-template
###
You have an Azure resource group named RG1. RG1 contains a Linux virtual machine (VM) named VM1.

You need to automate the deployment of 20 additional Linux VMs. The new VMs should be based upon VM1's configuration.

Solution: From the Templates blade, you click Add.

Does this solution meet the goal?
---
No
Yes *
---
The solution meets the goal. The Templates blade in the Azure portal enables you to store JavaScript Object Notation (JSON) documents that automate Azure resource deployment. In this case, you could store the Linux VM properties in a template and deploy the 20 additional VMs simply by editing the template parameter values for each additional VM.
---

Deploy resources with Resource Manager templates and Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-portal

Download the template for a VM;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/download-template

Create a Windows virtual machine from a Resource Manager template;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ps-template

Quickstart: Create and deploy Azure Resource Manager templates by using the Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-quickstart-create-templates-use-the-portal
###
You have an Azure resource group named RG1. RG1 contains a Linux virtual machine (VM) named VM1.

You need to automate the deployment of 20 additional Linux VMs. The new VMs should be based upon VM1's configuration.

Solution: From the resource group's Policies blade, you click Assign policy.

Does this solution meet the goal?
---
No *
Yes
---
This solution does not meet the goal. To automate the deployment of the 20 additional VMs, you should access the virtual machine's underlying JavaScript Object Notation (JSON) template and deploy the new resources by using the template and custom deployment parameters. By contrast, Azure Policy is a governance product that makes it easier for Azure administrators to constrain deployments to meet organizational requirements. For example, you could deploy an Azure policy that requires all resource deployments to occur within only company-authorized geographic locations.
---

Deploy resources with Resource Manager templates and Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-portal

Download the template for a VM;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/download-template

Create a Windows virtual machine from a Resource Manager template;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ps-template

What is Azure Policy?;https://docs.microsoft.com/en-us/azure/governance/policy/overview
###
You manage a Windows Server 2016 virtual machine (VM) named VM1.

You need to configure an additional public IPv4 address for VM1.

Solution: From the VM's Networking blade, you click Attach network interface.

Does this solution meet the goal?

Complete the Case Study
---
No *
Yes
---
This solution does not meet the goal. You can configure multiple public and private IP addresses to an Azure VM by modifying the IP configuration of its bound virtual network interface card. Because a network interface card can have more than one IP configuration, in this case you should add a second configuration and configure a new static IP address to that new configuration. Simply attaching another network interface does not guarantee that the additional interface has a public IP address associated with it.
---

Add network interfaces to or remove network interfaces from virtual machines;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface-vm

Assign multiple IP addresses to virtual machines using the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-multiple-ip-addresses-portal

Add, change, or remove IP addresses for an Azure network interface;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface-addresses
###
You manage a Windows Server 2016 virtual machine (VM) named VM1.

You need to configure an additional public IPv4 address for VM1.

Solution: From the network interface's IP configurations blade, you click Add.

Does this solution meet the goal?
---
No
Yes *
---
This solution meets the goal. You configure IP addresses for Azure VMs by modifying the IP configuration(s) of one or more associated virtual network interfaces. Each network interface has a single IP configuration, but you can include additional configurations with additional public and private IP addresses if the VM has more complex virtual network addressing or routing requirements. Azure allows both Windows Server and Linux VMs to have more than one virtual network card and therefore reside on multiple subnets within the same virtual network.
---

Add network interfaces to or remove network interfaces from virtual machines;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface-vm

Assign multiple IP addresses to virtual machines using the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-multiple-ip-addresses-portal

Add, change, or remove IP addresses for an Azure network interface;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface-addresses
###
You manage a Windows Server 2016 virtual machine (VM) named VM1.

You need to configure an additional public IPv4 address for VM1.

Solution: From the virtual machine's Extensions blade, you click Add.

Does this solution meet the goal?
---
No *
Yes
---
This solution does not meet the goal. To add another public IP address to the VM, you should add a second IP configuration to the network interface associated with VM1 and configure a public IP address. By contrast, VM extensions are software agents that broaden the capabilities of Windows Server and Linux VMs running in Azure. Extensions are not related to IP address assignment.
---

Add network interfaces to or remove network interfaces from virtual machines;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface-vm

Assign multiple IP addresses to virtual machines using the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-multiple-ip-addresses-portal

Add, change, or remove IP addresses for an Azure network interface;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface-addresses

Virtual machine extensions and features for Windows;https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/features-windows
###
Your company has two Azure subscriptions, subsA and subsB, for different lines of business. Each subscription has its own Azure Active Directory (Azure AD) tenant assigned.

You have a virtual machine (VM) deployed in the subsA subscription, in a resource group named RG-A1. You attempt to move the VM to another resource group named RG-B2 that is configured in the subsB subscription.

While you are trying to move the VM, you get an error.

You need to identify the cause of the error so you can move the VM.

What is the most likely cause?
---
The subscriptions are in different Azure AD tenants. *
The VM is a classic VM.
The VM has managed disks configured.
The destination resource group is in a different subscription.
---
You cannot move the VM because the subscriptions are in different Azure AD tenants. One of the prerequisites for being able to move a resource between different subscriptions or resource groups is that the source and destination subscriptions need to exist in the same Azure AD tenant. You need to transfer the ownership of one of the subscriptions to the other Azure AD tenant before you will be able to move the VM.

You can move classic VMs between resource groups or subscriptions. Moving this type of VM has some restrictions. The cloud service associated with the VM needs to be moved with the VM, and all VMs in a cloud service need to be moved together. However, moving classic VMs is still technically possible.

It is true that you cannot move a VM if it has managed disks configured, but in this situation, you cannot make the move because of the different Azure AD tenants, not the managed disks.

You can move resources between resources groups in different subscriptions. As long as the source and destination subscriptions exist within the same Azure AD tenant, and the destination resource group exists prior to the move, this operation is allowed.
---
Move resources to new resource group or subscription;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-move-resources
Move a Windows VM to another Azure subscription or resource group;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/move-vm
###
Your company has an Azure subscription with some virtual machines (VMs) deployed. One of these VMs is used by the development team for testing purposes.

You receive a call from the development team stating that they are not able to access the VM. After doing some troubleshooting and resetting the Remote Desktop Protocol (RDP) configuration, you decide to redeploy the VM.

You need to use PowerShell to redeploy the VM.

Which cmdlet should you use?
---
Set-AzureRmVM *
New-AzureRmVMConfig
Remove-AzureRmVM
Restart-AzureRmVM
Update-AzureRmVM
---
You should use the Set-AzureRmVM cmdlet with the -Redeploy switch. You need to provide the resource group name and the VM name that you want to redeploy.

You should not use the Update-AzureRmVM cmdlet. You use this cmdlet for updating the state of a VM to the values stored in a VM object that you can usually get using the Get-Azure RmVM cmdlet.

You should not use the Restart-AzureRmVM cmdlet. This cmdlet will restart the VM. Restarting a VM does not redeploy it to a new host.

You should not use the New-AzureRmVMConfig cmdlet. This cmdlet is intended for a creating new VM object configuration that you can use with other cmdlets.

You should not use the Remove-AzureRmVM cmdlet. You typically use this cmdlet when you want to remove a VM from Azure.
---

Set-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/set-azurermvm

Restart-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/restart-azurermvm

Remove-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/remove-azurermvm

Update-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/update-azurermvm

New-AzureRmVMConfig;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermvmconfig
###
C
You have a Windows Server 2012 R2 virtual machine (VM) that is experiencing connectivity issues. You are not able to connect to the VM using Remote Desktop (RDP).

You need to move the VM to a different node inside the Azure infrastructure.

Which two commands can you use? Each correct answer presents a complete solution.
---
az vm redeploy *
az vm deallocate
New-AzureRmVM
Update-AzureRmVM
Set-AzureRmVM *
az vm convert
---
You can use either the az vm redeploy command or the Set-AzureRmVm cmdlet to redeploy a VM. When you redeploy a VM, Azure tries to gracefully shutdown the VM and move it to another node inside the Azure Infrastructure. Azure copies all the current settings for the VM to the new location. This operation helps when you are experiencing connectivity issues with your VM and you are not able to connect to the VM using RDP or SSH.

You should not use the az vm deallocate Azure CLI command. This command shuts down the VM and disconnects all compute resources from the VM. You are not billed for deallocated VMs.

You should not use the az vm convert Azure CLI command. You use this command when you want to convert unmanaged disks in a VM to managed disks.

You should not use the Update-AzureRmVM cmdlet. This cmdlet updates the state of a VM. You use this cmdlet when you want to update the properties of the VM. This cmdlet does not redeploy the VM.

You should not use the New-AzureRmVM cmdlet. This cmdlet creates a new VM but does not redeploy an existing VM to a new node in the Azure infrastructure.
---

az vm;https://docs.microsoft.com/en-us/cli/azure/vm

Set-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/set-azurermvm

Redeploy Windows virtual machine to new Azure node;https://docs.microsoft.com/en-us/azure/virtual-machines/troubleshooting/redeploy-to-new-node-windows

Net-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermvm

Update-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/update-azurermvm
###
Your company purchases a new application and is planning to deploy it in Azure. The application requires Windows Server 2016. It also requires high-availability, so it will be deployed using a scalability set.

You are asked to prepare the virtual machine (VM) to automatically deploy all needed requirements for the application to run. You decide to use a custom script extension.

Before deploying the custom script, you test it and ensure that the script runs with no errors in the local environment. You store the script and some dependencies needed for the application in a blob storage account.

While you are testing automatic deployment, you realize that the custom script is not running.

What is the reason for the custom script not running?
---
The operation is taking more than 90 minutes.
You need to add an entry in the Network Security Group (NSG). *
You need to configure a proxy server for the custom script.
You need to sign the script.
---
Your custom script is failing to run because you need to add an entry in the NSG. By default, communication with external systems are restricted. If you store your script in any external resource, like Azure Storage, Github, or a local server, you need to configure the firewall/NSG.

Your custom script is not failing to run because you need to sign the script. You can invoke your custom script by using the following command:

powershell -ExecutionPolicy Unrestricted -File your-custom-script.ps1

Your script is failing to run because the resource manager is not able to access to it due to communication restrictions.

Your custom script is not failing to run because the operation is taking more than 90 minutes. The issue is that the script is not able to run at all because the resource manager is not able to access it due to communication restrictions.

Your custom script is not failing to run because you need to configure a proxy server for the custom script. A custom script does not support proxy settings. If you need to use a proxy for connecting to an external resource, you can use third-party applications like curl.

---

Custom Script Extension for Windows;https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/custom-script-windows

Tutorial - Deploy applications to a Windows virtual machine in Azure with the Custom Script Extension;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-automate-vm-deployment

Security groups;https://docs.microsoft.com/en-us/azure/virtual-network/security-overview
###
Last month you deployed an Ubuntu Linux server virtual machine (VM) named linux1 to a virtual network (VNet) in Azure.

Today, you need to perform emergency remote management of linux1 from your Windows 10 Enterprise Edition workstation. Your solution must minimize both setup time and administrative effort.

What should you do?
---
Connect to the VM by using Secure Shell (SSH) and Azure Cloud Shell. *
Connect to the VM by using Secure Shell (SSH) and Windows Subsystem for Linux.
Connect to the VM by using Remote Desktop Protocol (RDP) and PowerShell Core 6.0.
Connect to the VM by using Remote Desktop Protocol (RDP) and Remote Desktop Connection.
---
You should connect to the VM by using SSH and Azure Cloud Shell. SSH is the default protocol for remote Linux server management. Azure Cloud Shell is a browser-based command shell that gives you access to SSH and a variety of other Azure management tools. In this situation time is of the essence. Therefore, logging into the Azure portal, starting a Cloud Shell, and making an SSH-based connection to linux1 meets all scenario requirements.

You should not connect to the VM by using SSH and Windows Subsystem for Linux. The feature is available in Windows 10 Pro, Education, or Enterprise, and allows you to run native Linux commands directly on Windows. However, Windows Subsystem for Linux is not installed by default, and taking the time to install and configure the feature violates the scenario requirements for minimized setup time and administrative overhead.

You should not connect to the VM by using RDP and Remote Desktop Connection. While it is true that you can install an RDP server on Linux VMs running in Azure, this is not a default configuration and requires too much time and management effort.

You should not connect to the VM by using RDP and PowerShell Core 6.0. PowerShell Core 6.0 is available on Linux VMs deployed in Azure from the Azure Marketplace. However, the two in-box PowerShell remote management protocols are Web Services-Management (WS-Man) and SSH, not RDP.
---

Overview of Azure Cloud Shell;https://docs.microsoft.com/en-us/azure/cloud-shell/overview

Windows 10 Installation Guide;https://docs.microsoft.com/en-us/windows/wsl/install-win10

How to connect and log on to an Azure virtual machine running Windows;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/connect-logon

PowerShell Remoting Over SSH;https://docs.microsoft.com/en-us/powershell/scripting/core-powershell/ssh-remoting-in-powershell-core?view=powershell-6
###
Your company's Azure environment consists of the following resources:

* 4 virtual networks (VNets)
* 48 Windows Server and Linux virtual machines (VMs)
* 6 general purpose storage accounts

You need to design a universal monitoring solution that enables you to query across all diagnostic and telemetry data emitted by your resources.

What should you do first?
---
Activate resource diagnostic settings.
Create a Log Analytics workspace. *
Install the Microsoft Monitoring Agent.
Enable Network Watcher.
---
You should create a Log Analytics workspace. Azure Log Analytics is the central resource monitoring platform in Azure. The Log Analytics workspace is the data warehouse to which associated resources send their telemetry data. Azure Log Analytics has its own query language with which you can generate reports that stretch across all your Azure deployments and management solutions.

You should not install the Microsoft Monitoring Agent (MMA). This agent is indeed required to associate Windows physical and virtual servers (on-premises and in Azure). However, Log Analytics automatically deploys the MMA to your Azure virtual machines when you onboard them to your Log Analytics workspace.

You should not enable Network Watcher. Network Watcher is a virtual network diagnostics platform. While you can link Network Watcher to Azure Log Analytics, you still need to create the Log Analytics workspace first.

You should not activate resource diagnostic settings. Before Microsoft developed Log Analytics, administrators were required to configure diagnostic settings on a per-resource level. This is no longer necessary because Microsoft Monitoring Agent configures nodes to send their diagnostics logs to a Log Analytics workspace.
---

Create a Log Analytics workspace in the Azure portal;https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-quick-create-workspace

Analyze Log Analytics data in Azure Monitor;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/log-query-overview

Connect Windows computers to the Log Analytics service in Azure;https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-agent-windows

Create an Azure Network Watcher instance;https://docs.microsoft.com/en-us/azure/network-watcher/network-watcher-create

Collect and consume log data from your Azure resources;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-of-diagnostic-logs
###
Your company's Azure environment consists of two virtual networks (VNets) arranged in the following topology:

* prod-vnet: 9 virtual machines (VMs)
* dev-vnet: 9 virtual machines (VMs)

The VMs in the prod-vnet should run continuously. The VMs in dev-vnet are used only between 7:00 A.M. and 7:00 P.M. local time.

You need to automate the shutdown and startup of the dev-vnet VMs to reduce the organization's monthly Azure spend.

Which Azure feature should you use?
---
Azure Auto-Shutdown
Azure Change Tracking
Azure Automation Desired State Configuration (DSC)
Azure Automation runbook *
---
You should create an Azure Automation runbook. Azure Automation is a management solution that allows you to publish PowerShell or Python scripts in Azure and optionally schedule Azure to run them automatically. In this case, best practice is to write a PowerShell workflow script that automates VM startup and shutdown, and then bind the script to two Azure Automation schedules: one to describe shutdown time, and the other to describe startup time.

You should not use Azure Automation Desired State Configuration (DSC). DSC is a PowerShell feature that prevents configuration drift on your Azure and/or on-premises servers. For example, you could deploy a DSC configuration that prevents server services from stopping.

You should not use Azure Auto-Shutdown. This feature, part of Azure DevTest Labs, allows you to schedule Azure VMs to shut down at the same time every day or night. However, this feature does not provide for automated VM startup.

You should not use Azure change tracking. Change tracking is an IT service management (ITSM) feature that is part of Azure Automation service and records all configuration changes to your Azure VM resources.
---

My first PowerShell Workflow runbook;https://docs.microsoft.com/en-us/azure/automation/automation-first-runbook-textual

Azure Automation State Configuration Overview;https://docs.microsoft.com/en-us/azure/automation/automation-dsc-overview

Azure Virtual Machine auto-shutdown;https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/09/12/azure-virtual-machine-auto-shutdown/

Track changes in your environment with the Change Tracking solution;https://docs.microsoft.com/en-us/azure/automation/automation-change-tracking

About Azure DevTest Labs;https://docs.microsoft.com/en-us/azure/lab-services/devtest-lab-overview
###
Your media production company recently moved all its infrastructure into Azure.

Every 14 days you run a batch to render several thousand video clips into various media formats for customers. At the moment the batch job is run on a single H-series virtual machine (VM).

You need to design a scalable compute solution. The solution must meet the following technical and business requirements:

* Must use VM instance sizes smaller than H series
* Must support automatic scale out and scale in based on CPU metrics
* Must minimize deployment time
* Must minimize administrative overhead

What should you do?
---
Deploy a virtual machine scale set (VMSS). *
Create an Azure Data Factory pipeline.
Configure an auto-scaling rule on the existing VM.
Author an Azure Resource Manager (ARM) template that creates additional VMs.
---
You should deploy a virtual machine scale set (VMSS). Scale sets represent the only way to horizontally scale Azure VMs automatically. A scale set is a collection of two or more identically configured Windows Server or Linux VMs that provide full, centralized control over their lifecycle. Scale sets support up to 1,000 instances when you use VM images in the Azure Marketplace.

You cannot configure an auto-scaling rule on the existing VM. Scale sets are the only way to horizontally autoscale Azure VMs. By contrast, Azure App Service apps can be configured individually with auto-scaling rules based on time, date, or CPU metric.

You should not create an Azure Data Factory pipeline. Azure Data Factory is a cloud-based data orchestration engine similar in function to SQL Server Integration Services (SSIS). Therefore, Data Factory is not appropriate for this scenario.

You should not author an ARM template that creates additional VMs. While you can indeed use ARM templates to automate the deployment and removal of VMs, doing so violates the scenario constraints of minimized setup time and management overhead.
---

What are virtual machine scale sets?;https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/overview

Autoscaling;https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling

Get started with Autoscale in Azure;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-autoscale-get-started

Introduction to Azure Data Factory;https://docs.microsoft.com/en-us/azure/data-factory/introduction

Deploy resources with Resource Manager templates and Azure PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy

###

You have a Microsoft Azure subscription named Sub1.

You deploy a Windows Server 2016 virtual machine (VM) named VM1 to Sub1.

You need to change the availability set assignment for VM1.

What should you do?
---
Redeploy VM1 from a recovery point. *
Move VM1 to a different availability zone.
Migrate VM1 to another Azure region.
Assign VM1 to the new availability set.
---
You should redeploy VM1 from a recovery point. In Azure, you can assign a VM to an availability set only during initial deployment. Therefore, to reassign the VM to another availability set in this case, you would need to perform the following actions:

1. Take a backup of the current VM.
2. Delete the current VM.
3. Deploy a new VM based on the most recent restore point to the correct availability set

You should not move VM1 to a different availability zone because availability zones are mutually exclusive from availability sets.

You should not assign VM1 to the new availability set because, as previously discussed, this is not a supported action in the Azure service fabric.

You should not migrate VM1 to another Azure region because by definition members of the same availability set must reside in the same region.
---

Change the availability set for a Windows VM;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/change-availability-set

What are Availability Zones in Azure?;https://docs.microsoft.com/en-us/azure/availability-zones/az-overview

Manage the availability of Windows virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/manage-availability
###
You have an Azure resource group named RG1. RG1 contains four virtual machines (VMs) and their associated resources.

You need to generate resource usage reports by using interactive queries.

What should you use?
---
Azure Monitor
Azure Alerts
Azure Log Analytics *
Azure Service Bus
---
You should use the Log Search feature of Azure Log Analytics to run interactive queries and to build reports based on VM diagnostics data resident in your Azure Log Analytics workspace. Log Search uses Kusto Query Language (KQL), a new query language based on Structured Query Language (SQL), Splunk Processing Language (SPL), and PowerShell.

You should not use Azure Monitor because Monitor does not support interactive queries itself. Instead, Monitor allows you to:

* Enable diagnostics logging
* Plot resource metrics
* Configure alerts

The Log Search functionality in Azure Monitor is actually a shortcut to Log Search in your Azure Log Analytics workspace.

You should not use Azure alerts. Alerts in Azure Monitor can be based on resource metrics (for example, CPU utilization of a VM) or Activity Log alerts (for instance, whenever a VM is powered off or restarted).

You should not use Azure Service Bus. Azure Service Bus is an enterprise-class messaging platform that supports microservice application architectures. It is not related to resource monitoring.

---

Viewing and analyzing data in Log Analytics;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/portals

Get started with queries in Log Analytics;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-queries

Azure Monitor overview;https://docs.microsoft.com/en-us/azure/azure-monitor/overview

Overview of alerts in Microsoft Azure;https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-alerts

What is Azure Service Bus?;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview
###
You have a Microsoft Azure subscription that has four virtual machines (VMs) located in the East US region.

You configure the four VMs identically to act as web servers.

You need to ensure that traffic is distributed equally across the four web servers. You also need to protect the web servers against the most common web application security risks. Your solution must minimize expense.

What should you do?
---
Deploy a virtual machine scale set.
Deploy Azure Application Gateway. *
Deploy a Traffic Manager profile.
Deploy an Azure Content Delivery Network (CDN) profile.
---
You should deploy Azure Application Gateway. Application Gateway is a software load balancer that is specialized for web workloads. In addition to providing load balancing services, Application Gateway also includes a web application firewall (WAF) that protects back-end pool web servers against the most common web application vulnerabilities.

You should not deploy a virtual machine scale set because this solution requires the deployment of additional VMs. Moreover, a scale set offers no native protection against web application vulnerabilities.

You should not deploy a Traffic Manager profile because the scenario states that the web servers reside in the same geographic area. Traffic Manager is a Domain Name System (DNS)-based load balancer that works across multiple Azure regions.

You should not deploy an Azure Content Delivery Network (CDN) profile. A CDN makes user access to static web resources faster by geo-distributing those resources. CDN is unrelated to this scenario.
---

What is Azure Application Gateway?;https://docs.microsoft.com/en-us/azure/application-gateway/overview

Web application firewall (WAF);https://docs.microsoft.com/en-us/azure/application-gateway/waf-overview

What is Traffic Manager?;https://docs.microsoft.com/en-us/azure/traffic-manager/traffic-manager-overview

What are virtual machine scale sets?;https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/overview

What is a content delivery network on Azure?;https://docs.microsoft.com/en-us/azure/cdn/cdn-overview
###
You have a Linux virtual machine (VM) named VM1 that runs in Azure. VM1 has the following properties:

* Size: Standard_D4s_v3
* Number of virtual CPUs: 2
* Storage type: Premium
* Number of data disks: 6
* Public IP address: Standard SKU

You attempt to resize the VM to the Standard_D2s_v3 size, but the resize operation fails.

Which VM property is the most likely cause of the failure?
---
Storage type
Number of virtual CPUs
Public IP address
Number of data disks *
---
In this case, the VM resize failure is caused by the VM's current number of data disks. The Standard_D4s_v3 instance size supports up to 8 data disks, but the Standard D2s_v3 instance size supports only up to 4 data disks. Therefore, you will be unable to make the VM size reduction unless you detach the extra data disks from the VM.

The number of virtual central processing units (vCPUs) is not a problem because Standard_D4s_v3 supports 4 vCPUs and Standard_D2s_v3 supports 2 vCPUs.

The storage type is not a problem because both instance sizes support premium disk storage.

The public IP address resource is not a problem because this resource is associated at the network interface level and not the VM level.
---

Sizes for Windows virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes

General purpose virtual machine sizes;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sizes-general

Azure Managed Disks Overview;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/managed-disks-overview

IP address types and allocation methods in Azure;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-ip-addresses-overview-arm
###
C
You use Azure VM Backup to back up all Windows Server and Linux VMs in Azure to a Recovery Services vault.

One of your colleagues informs you that he accidentally deleted corp-archive-vm1. You inspect Azure Monitor and verify that the server has been backed up every night for the past two months even though it has been powered off the entire time.

You need to restore the VM to its original location as quickly as possible.

What two actions should you perform? Each correct answer presents part of the solution.
---
Select the most recent application-consistent restore point.
Restore the corp-archive-vm1 disks and ARM template and redeploy the VM using Azure PowerShell.
Select the most recent crash-consistent restore point. *
Restore corp-archive-vm1 by creating a new VM. *
---
You should select the most recent crash-consistent restore point. A crash-consistent restore point is an Azure VM backup that is not guaranteed to boot and/or experience data loss. This is the only restore point possible when an Azure VM is backed up while it is powered off.

You should then restore corp-archive-vm1 by creating a new VM. Azure VM Backup allows you to restore only the VM's disks, the entire VM as a new resource, or individual files from the VM's disks. In this situation you need to put the deleted VM back online as quickly as possible, so letting Azure VM Backup restore a new VM by using the restore point makes the most sense.

You should not select the most recent application-consistent restore point. This type of restore point is not available because the VM had been backed up while powered off. An application-consistent restore point is available when a Windows Server in Azure is backed up and the Shadow Copy Service (VSS) writer can guarantee the restored VM will boot up with no data loss or data corruption.

You should not restore the corp-archive-vm1 disks and ARM template and redeploy the VM using Azure PowerShell. Doing so violates the time constraint in the scenario.
---

Use the Azure portal to restore virtual machines;https://docs.microsoft.com/en-us/azure/backup/backup-azure-arm-restore-vms

Restore a disk and create a recovered VM in Azure;https://docs.microsoft.com/en-us/azure/backup/tutorial-restore-disk

Plan your VM backup infrastructure in Azure;https://docs.microsoft.com/en-us/azure/backup/backup-azure-vms-introduction

Create VM from existing VHDs and connect it to existing VNET;https://azure.microsoft.com/en-us/resources/templates/201-vm-os-disk-and-data-disk-existing-vnet/
###
You manage an Azure Windows Server virtual machine (VM) that hosts several SQL Server databases.

You need to configure backup and retention policies for the VM. The backup policy must include transaction log backups.

What should you do?
---
Configure a point-in-time snapshot from the Disks Azure portal blade.
Configure point-in-time and long-term retention policies from the SQL Servers Azure portal blade.
Configure a continuous delivery deployment group from the Virtual Machine Azure portal blade.
Configure a SQL Server in Azure VM backup policy from the Recovery Services Azure portal blade. *
---
You should configure a SQL Server in Azure VM backup policy from the Recovery Services Azure portal blade. The Azure Recovery Services vault has three default policy templates:

* Azure Virtual Machine
* Azure File Share
* SQL Server in Azure VM

Because you need to back up both the SQL Server databases as well as transaction logs, you should create a SQL Server in Azure VM backup policy. These policies also enable you to specify backup retention durations at the daily, weekly, monthly, and yearly scopes.

You should not configure point-in-time and long-term retention policies from the SQL Servers Azure portal blade. These backup and retention policies are available for the Azure SQL Database platform-as-a-service (PaaS) offering, and not for Azure virtual machines hosting SQL Server databases.

You should not configure a continuous delivery deployment group from the Virtual Machine Azure portal blade. This feature is unrelated to VM backup and  recovery, and allows you to integrate a VM in a Visual Studio Team Services (VSTS) continuous integration/continuous deployment (CI/CD) workflow.

You should not configure a point-in-time snapshot from the Disks Azure portal blade. The snapshot functionality in Azure does not have formal policy associated with it, nor does it back up VM configuration.

---

Prepare to back up Azure VMs;https://docs.microsoft.com/en-us/azure/backup/backup-azure-arm-vms-prepare

Back up Azure VMs with the Azure Backup Service;https://docs.microsoft.com/en-us/azure/backup/backup-azure-vms-first-look-arm

Automated Backups;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-automated-backups

Publish an ASP.NET Web App to an Azure VM from Visual Studio;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/publish-web-app-from-visual-studio

Create a snapshot;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/snapshot-copy-managed-disk
###
C
You deploy Azure Recovery Services in your Azure Subscription. You are making a backup of all the virtual machines (VMs) in this subscription.

Some of the VMs in the subscription were deployed using custom images. You also have encrypted VMs.

Due to your company's disaster recovery plan, you need to be able to recover VMs.

Choose all that apply:
---
You can use the replace existing option with encrypted VMs
When you restore a VM, you can customize the VM configuration using PowerShell. *
You can only restore VMs that have single NICs.
Restoring VMs created using custom images using the replace existing option is unsupported. *
---
You cannot use the replace existing option with encrypted VMs. If you need to recover an encrypted VM, you need to use the restore disks option. Then you need to create a new VM from restored disks.

When you restore a VM, you can customize the VM configuration using PowerShell. When you restore a VM using the create virtual machine option, the new VM is created using a Quick Create option provided by the portal. If you need to change this default configuration, you can do it by using PowerShell for the restoration process. You can also perform a restore from backup disks and create a new VM from these disks.

You can also restore VMs that have multiple NICs. You can backup and restore VMs that have special network configurations like VMs with multiple NICs, VMs with multiple reserved IP addresses, or load-balanced VMs. You need to perform some additional steps when you want to restore these types of VMs.

Restoring VMs created using custom images using the replace existing option is unsupported. You cannot use the replace existing restore type with encrypted VMs, VMs that have been created from custom images, generalized VM, or VMs configured with unmanaged disks. If you want to restore these types of VMs, you need to use the create virtual machine or restore backed-up disks options.
---

Use the Azure portal to restore virtual machines;https://docs.microsoft.com/en-us/azure/backup/backup-azure-arm-restore-vms

Back up and restore encrypted virtual machines with Azure Backup;https://docs.microsoft.com/en-us/azure/backup/backup-azure-vms-encryption
###
Your company has a custom line-of-business (LOB) application that uses several Azure resources. All resources assigned to the LOB application are in the same resource group. After the first deployment of the LOB application, the company adds more features to the application. You also add more resources to the resource group in different additional deployments.

You need to create a template to redeploy the resources needed for the LOB application.

What should you do?
---
Use the Get-AzureRmResourceGroupDeployment cmdlet.
Use the Save-AzureRmResourceGroupDeploymentTemplate cmdlet.
Use the Export-AzureRmResourceGroup cmdlet. *
Use the Get-AzureRmResourceGroupDeploymentOperation cmdlet.
---
You should use the Export-AzureRmResourceGroup cmdlet. When you use this cmdlet, you get all resources in a resource group and save it as a template. This like a snapshot of the configuration of the resource group. This template has many values hard-coded directly in the template.

You should not use the Save-AzureRmResourceGroupDeploymentTemplate cmdlet. This cmdlet allows you to create a template from a deployment that is in the deployment history of a resource group. Since you have made several modifications to the resource group by adding more resources in additional deployments, the deployments in the deployment history do not contain the whole group of resources needed for the LOB application.

You should not use the Get-AzureRmResourceGroupDeployment cmdlet. This cmdlet returns the deployment history for a resource group.

You should not use the Get-AzureRmResourceGroupDeploymentOperation cmdlet. This cmdlet returns all the operations performed during a deployment. This is useful if you need to troubleshoot a failed deployment.
---

Export Azure Resource Manager templates with PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-export-template-powershell

Get-AzureRmResourceGroupDeploymentOperation;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/get-azurermresourcegroupdeploymentoperation

Get-AzureRmResourceGroupDeployment;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/get-azurermresourcegroupdeployment
###
You have an ARM template for creating a Windows virtual machine. You got this template from an existing resource group with a single virtual machine, using the automation script option.

You want to reuse this template for other deployments. You need all the resources in the resource group to be on the same location.

What should you do?
---
Edit the parameters file and add a new parameter named location of type string with the default value of [resourceGroup().location].
Edit the template file and update each location parameter with the value [resourceGroup().location]. *
Use the New-AzureRmResourceGroup cmdlet with the location parameter to create a resource group in the desired location. Then use the New-AzureRmResourceGroupDeployment cmdlet using the newly created resource group.
Use the Azure portal and create a resource group in the desired location. Then use the New-AzureRmResourceGroupDeployment cmdlet using the newly created resource group.
---
You should edit the template file and update each location parameter with the value [resourceGroup().location]. The resourceGroup() function gets the resource group object that will be used for deploying the template. This way, all resources in the template will use the same location as the resource group. You need to ensure that all resources are supported in the location that you are using for the resource group.

You should not edit the parameters file and add a new parameter named location of type string with the default value of [resourceGroup().location]. This is the first step for centralizing the location value in the template, but you also need to update the location parameter in the template file with the value [parameters('location')].

You should not use the Azure portal and create a resource group in the desired location and then use the New-AzureRmResourceGroupDeployment cmdlet using the newly created resource group. If the resource group is deployed in a location different than the configured in the template file, the resources will be deployed in different locations. You need to modify the location parameter in the template file to the value [resourceGroup().location] to inherit the location from the parent resource group.

You should not use the New-AzureRmResourceGroup cmdlet with the location parameter to create a resource group in the desired location and then use the New-AzureRmResourceGroupDeployment cmdlet using the newly created resource group. If the resource group is deployed in a location different than the configured in the template file, the resources will be deployed in different locations. You need to modify the location parameter in the template file to the value [resourceGroup().location] to inherit the location from the parent resource group.
---
Resources section of Azure Resource Manager templates;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-templates-resources

Resource functions for Azure Resource Manager templates;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-functions-resource

Deploy resources with Resource Manager templates and Azure PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy
###
C
Your company is planning to deploy a new application in its Azure subscription. The application consists of several Linux virtual machines (VMs).

You are asked to deploy the needed VMs for this new application. The VMs will run version 18.04-LTS of Ubuntu server. You decide to create an ARM template for the deployment.

You need to ensure that the VM image can automatically update after the initial deployment. You also need to use VM images from the marketplace.

Which two ARM parameters should you configure? Each correct answer presents part of the solution.
---
osType
vmSize
sku *
offer *
version
---
You should configure the sku and offer parameters. The sku parameter is used for setting the major release version of the operating system distribution. You use the offer parameter for setting the name of the images created by the publisher. For this situation, you need to set sku to 18.04-LTS and offer to UbuntuServer.

You should not use the version parameter. You typically use this parameter for setting the version of the image of the selected sku. You can use the version number using the format Major.Minor.Build or use the keyword latest. If you set this parameter to latest, you will always use the latest available version at deployment time, but the image will not be update when a new version becomes available.

You should not use the vmSize parameter. This parameter is used to set the amount of hardware resources assigned to the VM. It is not related to the operating system used in the VM.

You should not use the osType parameter. You use this parameter to specify the operating system installed on the osDisk when you use a user-image or specialized virtual hard disk (VHD) to deploy the VM.
---
Microsoft.Compute/virtualMachines template reference;https://docs.microsoft.com/en-us/azure/templates/microsoft.compute/virtualmachines
###
You have a resource group named APP-RG that consists of several resources.

You are asked to add a storage account to the resource group. You decide to deploy the new storage account by using an ARM template and the New-AzureRmResourceGroupDeployment cmdlet. This template does not contain any linked or nested templates.

After the deployment finishes successfully, you realize that all the resources in the resource group have been replaced by the new storage account.

Why did this happen?
---
You used the -mode complete parameter with the New-AzureRmResourceGroupDeployment cmdlet. *
The template contains the mode parameter with the value of incremental.
You did not use the -mode parameter with the New-AzureRmResourceGroupDeployment cmdlet.
The template contains the mode parameter with the value of complete.
---
The resources in the resource group have been replaced by the new storage account because you used the -mode complete parameter with the New-AzureRmResourceGroupDeployment cmdlet. This cmdlet has two deployment modes, incremental and complete. When you use the complete mode, all resources in the resource group that are not included in the template are deleted.

This did not happen because you did not use the -mode parameter with the New-AzureRmResourceGroupDeployment cmdlet. When you do not use the -mode parameter, you are using the default incremental deployment mode. In this mode, any resource that is not present in the template is maintained in the resource group. If a resource in the resource group is present in the template, if any parameter in the template differs from the values in the resource group, that value is updated in the resource present in Azure. You should use this mode when deploying the template.

Since the template that you are using does not contains any linked or nested templates, the mode parameter should not be present in the template with either value. This parameter is part of the deployment resource type and is typically used with nested or linked templates. Deployment modes, complete and incremental, behave the same way as in the New-AzureRmResourceGroupDeployment cmdlet.
---

Deploy resources with Resource Manager templates and Azure PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy

Microsoft.Resources/deployments template reference;https://docs.microsoft.com/en-us/azure/templates/microsoft.resources/deployments

New-AzureRmResourceGroupDeployment;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/new-azurermresourcegroupdeployment
###
C
You deploy a line of business (LOB) application. All resources that are part of the LOB application are deployed in a resource group named APP-RG.

The resources that are part of the LOB application were added in different phases.

You need to export the current configuration of the resources in APP-RG to an ARM template. You will later use this template for deploying the LOB application infrastructure in different environments for testing or development purposes.

For each of the following statements, select Yes if the statement is true. Otherwise, select No.
---
You need to export the ARM template from the latest deployment.
Each deployment contains only the resources that have been added in that deployment. *
The parameters file contains the values used during the deployment. *
The template contains needed scripts for deploying the template. *
---
You do not need to export the ARM template from the latest deployment. In this scenario, the LOB application was deployed in several phases. The latest deployment will export only the latest resources added to the application. If you want to export the ARM template with all needed resources for the LOB application, you need to export the ARM template from the resource group.

Each deployment contains only the resources that have been added in that deployment. When you export an ARM template from a deployment, the template only contains the resources created during that deployment.

The parameters file contains the values used during the deployment. The parameters file is a JSON file that stores all the parameters used in the ARM template. You can use this file to reuse the template in different deployments, just changing the values of the parameters file. If you use this file in templates created from resource groups, you need to make significant edits to the template before you can effectively use the parameters file.

The template contains needed scripts for deploying the template. When you download an ARM template from a deployment or a resource group, the downloaded package contains seven files: the ARM template, the parameters file, an Azure CLI script, a PowerShell script, a Ruby script and a .NET class for deploying the template.
---

Export an Azure Resource Manager template from existing resources;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-export-template
###
C
You need to deploy several virtual machines (VMs) in your Azure Subscription. All VMs will be deployed in the resource group RG01 based on an ARM template that is stored in GitHub.

You need to automate this operation.

Which two commands can you use? Each correct answer presents a complete solution
---
New-AzureRmVM
az group deployment create *
az vm create
New-AzureRmResourceGroupDeployment *
---
You could use the az group deployment create Azure CLI command. This command creates a new deployment using the template provided in the -template-uri parameter. In this case, you need to use the URL that points to GitHub where you stored the ARM template that you want to use to deploy the new VMs.

You could also use the New-AzureRmResourceGroupDeployment cdmlet. This cmdlet creates a new deployment using the template provided in the -TemplateUri paramenter.

You should not use az vm create or New-AzureRmVM. You use these commands to create a new VM from custom or marketplace images, but not from ARM templates.
---

Quickstart: Create a Linux virtual machine in Azure with PowerShell;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-powershell

Quickstart: Create a Linux virtual machine with the Azure CLI;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-cli

How to create a Linux virtual machine with Azure Resource Manager templates;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/create-ssh-secured-vm-from-template

az group deployment;https://docs.microsoft.com/en-us/cli/azure/group/deployment

New-AzureRmResourceGroupDeployment;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/new-azurermresourcegroupdeployment
###
Your company deploys a line-of-business (LOB) application. This application is installed on three separate virtual machines (VMs).

You receive some performance alerts on one of the VMs. After some troubleshooting, you identify a deficiency in the IO of the storage system.

You need to add an additional new empty data disk to the existing VM. You decide to use an unmanaged disk.

Which PowerShell cmdlet should you use?
---
New-AzureRmDiskConfig
Add-AzureRmVhd
Add-AzureRmVMDataDisk *
New-AzureRmDisk
New-AzureRmVMDataDisk
---
You should use the Add-AzureRmVMDataDisk cmdlet to add a new data disk to your existing VM. This cmdlet gets as a parameter the name of the VM to which you want to add the new virtual disk. You can also configure the size, location, caching, and type of virtual disk that you will add. If you use the ManagedDiskId parameter, you can add a managed disk to the VM. If you omit this parameter, you will use unmanaged disks instead.

You should not use the New-AzureRmDiskConfig cmdlet. You use this cmdlet for creating an object that represents the disk configuration of the VM.

You should not use the New-AzureRmDisk cmdlet. This cmdlet creates a new managed virtual disk but does not attach it to the VM. After using the cmdlet, you need to add the virtual disk to the VM using the Add-AzureRmVMDataDisk cmdlet with the CreateOption Attach parameter. You decided to use an unmanaged virtual disk, so you cannot use this cmdlet.

You should not use the Add-AzureRmVhd cmdlet. This cmdlet uploads a virtual hard disk (VHD) file from an on-premises computer to Azure. This cmdlet is not useful for adding a new virtual disk to your VM.

You should not use the New-AzureRmVMDataDisk cmdlet. This cmdlet creates a managed virtual data disk for a VM, but it does not add the virtual disk to the VM.
---

New-AzureRmVMDataDisk;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermvmdatadisk

Add-AzureRmVhd;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/add-azurermvhd

Add-AzureRmVMDataDisk;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/add-azurermvmdatadisk

New-AzureRmDisk;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermdisk

New-AzureRmDiskConfig;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermdiskconfig

Attach a data disk to a Windows VM using PowerShell;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
