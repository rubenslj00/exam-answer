###
You need to recommend a solution that will monitor Azure subscription activity and send alerts to a non-Azure system for processing.

Notification of alerts sent to the external system must be automated.

Which mechanism should you recommend?
---
Azure Stream Analytics
Azure Event Hubs
Power BI
Webhook *
---
You should recommend using a webhook. Azure alerts use HTTP POST to send the alert contents in JSON format to a webhook URI that you provide when you create the alert. Azure posts one entry per request when an alert is activated.

You should not recommend Power BI. This service is used to present and analyze both historical and live data. The external system would need to retrieve the data from Power BI.

You should not recommend Azure Event Hubs. Although this service is used to ingest data, you would need an additional component to send data to an external system.

You should not recommend Azure Stream Analytics. This service is used to process large amounts of data on the fly and to perform complex data analytics and aggregations.
---
Monitor Subscription Activity with the Azure Activity Log;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/platform-logs-overview

Webhook actions for log alert rules;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/alerts-log-webhook

Connect to Azure Audit Logs with Power BI;https://docs.microsoft.com/en-us/power-bi/service-connect-to-services

Stream the Azure Activity Log to Event Hubs;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log-export

Stream data as input into Stream Analytics;https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-inputs
###
You are taking over as the IT administrator for an Azure subscription. You want a simple, efficient, and free way to view and manage all the blobs in the subscription.

You need to download the most appropriate tool.

Which tool should you use?
---
Visual Studio Ultimate
Visual Studio Code
Storage Explorer *
Storage Emulator
---
You should use Storage Explorer. This tool is free and simple to use. It allows you to manage different types of Azure storage accounts, including blobs, tables, and queues.

You should not use Visual Studio Ultimate. This is a fully-featured integrated development environment (IDE) that allows you to write code for applications and websites. Although you can use the built-in Azure Cloud Explorer tool to view blobs, Storage Explorer is easier to use.

You should not use Visual Studio Code. This is a light-weight IDE that allows you to write code for applications and websites. It does not provide a built-in user interface for managing blobs.

You should not use Storage Emulator. This tool allows you to emulate Azure storage accounts. It does not connect to real Azure storage accounts.
---
Azure Storage Explorer;https://azure.microsoft.com/en-us/features/storage-explorer/

Use the Azure storage emulator for development and testing;https://docs.microsoft.com/en-us/azure/storage/common/storage-use-emulator

What are the differences between Visual Studio Code and Visual Studio;https://stackoverflow.com/questions/30527522/what-are-the-differences-between-visual-studio-code-and-visual-studio

Manage the resources associated with your Azure accounts in Visual Studio Cloud Explorer;https://docs.microsoft.com/en-us/visualstudio/azure/vs-azure-tools-resources-managing-with-cloud-explorer?view=vs-2019
###
A blob associated with an Azure Blob storage account contains data that is accessed several times per day.

You plan to add a new blob to the Blob storage account. The data in the new blob will be viewed infrequently but must be available immediately when accessed.

You must configure the storage tier for the new blob. The solution must minimize storage costs.

What should you do?
---
Set the storage tier for the new blob to Cool. *
Set the storage tier for the new blob to Archive.
Set the default storage tier for the account to Cool.
Set the default storage tier for the account to Hot.
---
You should set the storage tier for the new blob to Cool. Cool storage is intended for data that is accessed infrequently and stored for 30 days or more. Cool storage has a similar time-to-access as Hot data. Although it has a slightly lower availability compared to Hot data, storage costs are lower.

You should not set the storage tier for the new blob to Archive. Although Archive storage is the least expensive, it also has several hours of retrieval latency.

You should not set the default storage tier for the account to Hot. Only the original blob in the storage account is accessed frequently. If the tier for the account is set to Hot, this applies to the new blob as well.

You should not set the default storage tier for the account to Cool. This is appropriate only for the new blob. If the tier for the account is set to Cool, this applies to the original blob as well.
---

Azure Blob storage: Premium (preview), Hot, Cool, and Archive storage tiers;https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal
###
You are planning to deploy 15 identical virtual machines (VMs) to Azure. All 15 VMs must be based on the settings of a local on-premises computer.

You need to choose the best strategy for deploying the VMs.

What should you do?
---
Create an Extensible Markup Language (XML) file that describes a single VM. Use Azure CLI to deploy a template to Azure.
Create a VM in Azure. Use PowerShell to copy that VM 14 times.
Create a JavaScript Object Notation (JSON) file that describes a single VM. Use PowerShell to deploy a template to Azure. *
Create a VM in Azure. Use Azure CLI to copy that VM 14 times.
---
You should create a JSON file that describes a single VM. This file is referred to as an Azure Resource Manager (ARM) template in Azure. You should then use deployment commands to deploy the template to Azure. One tool that you can use is PowerShell. Once the template is deployed, you can use it to create actual VMs.

You should not create an XML file to describe a single VM. ARM templates must be written in JSON syntax.

You should not create the VM in Azure and then use PowerShell or Azure CLI to copy it. ARM templates provide a way to describe a VM before you create it.
---

Quickstart: Create and deploy Azure Resource Manager templates by using the Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/quickstart-create-templates-use-the-portal
###
You need to deploy a virtual machine (VM) to Azure from a third-party online template.

Which PowerShell cmdlet should you use?
---
New-AzureRmResourceGroupDeployment *
New-AzureVM
New-AzureQuickVM
New-AzureRmVMConfig
---
You should use New-AzureRmResourceGroupDeployment. This cmdlet allows you to use Azure Resource Manager (ARM) templates to create Azure resources. In this scenario, it allows you to create a VM from an ARM template.

You should not use New-AzureQuickVM or New-AzureVM. Both cmdlets allows you to create a VM from an Azure template, not from a third-party online template.

You should not use New-AzureRmVMConfig. This cmdlet creates a VM configuration, not an actual VM.

---

Quickstart: Create and deploy Azure Resource Manager templates by using the Azure portal;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/quickstart-create-templates-use-the-portal

Deploy resources with Resource Manager templates and Azure PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-powershell

New-AzureVM;https://docs.microsoft.com/en-us/powershell/module/servicemanagement/azure/new-azurevm?view=azuresmps-4.0.0

New-AzureRmVMConfig;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermvmconfig?view=azurermps-6.13.0

New-AzureQuickVM;https://docs.microsoft.com/en-us/powershell/module/servicemanagement/azure/new-azurequickvm?view=azuresmps-4.0.0
###
You manage two on-premises networks, each located in a separate branch office. You must connect both networks to Azure while controlling costs.

Which type of connection should you choose?
---
Point-to-site VPN
Multi-protocol label switching (MPLS) network
Multi-site VPN *
ExpressRoute connection
---
You should choose a multi-site VPN. This accomplishes the goal of connecting the branch offices to Azure while controlling costs.

You should not choose an ExpressRoute connection. ExpressRoute connects an on-premises network to a virtual network via wide area network (WAN). Although this solution provides a fast, secure connection, it is not a low-cost option.

You should not choose an MPLS network. This is also not a low-cost option.

You should not choose a point-to-site connection. This option connects one or more machines and a site via the Internet and is not an appropriate solution for connecting branch offices.
---

ExpressRoute connectivity models;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-connectivity-models

Add a Site-to-Site connection to a VNet with an existing VPN gateway connection;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-multi-site-to-site-resource-manager-portal
###
You are the Azure administrator for a web API that uses the Free plan.

You need to monitor the web API to determine whether or not you should change the plan to Basic.

Which metric should you monitor?
---
Average Response Time
Thread Count
Requests
CPU Time *
---
You should monitor CPU time. This represents the number of CPU minutes used by the web API. For the Free plan, a web app or web API is allowed 60 CPU minutes per day. By monitoring this metric, you can decide whether or not to scale up the web API.

You should not monitor Average Response Time. This represents the average number of milliseconds used to serve a single request. An App Service Plan can affect the response time, but it is not feasible to use the response time to determine whether or not to scale up an app due to other factors. For example, the average response time can increase due to the number of simultaneous requests made, such as during peak times.

You should not monitor Requests. This represents the total number of HTTP requests made to the web API. An App Service Plan does not limit the number of requests made to a web API.

You should not monitor Thread Count. This represents the total number of working threads used to service requests. An App Service Plan does not limit the number of threads used by a web API.
---

Monitor apps in Azure App Service;https://docs.microsoft.com/en-us/azure/app-service/web-sites-monitor

App Service Pricing;https://azure.microsoft.com/en-us/pricing/details/app-service/windows/
###
Your company has on-premises Domain Name System (DNS) servers that are authoritative for its domain. You create a directory in Azure Active Directory (Azure AD). You want to create a custom domain for this directory that matches your company's domain.

You need to configure the environment so that you can have Azure verify the custom domain.

What should you do?
---
Add a CNAME record at your company's domain registrar.
Add a CNAME record to your company's DNS servers.
Add a TXT record at your company's domain registrar.
Add a TXT record to your company's DNS servers. *
---
You should add a TXT record to your company's DNS servers. When you ask Azure to verify a custom domain, it issues DNS queries for TXT records. Because your company has on-premises DNS servers that are authoritative for its domain, Azure sends the DNS queries to your company's DNS servers. If the TXT entry in Azure matches the TXT entry in your company's DNS servers, verification succeeds.

You should not add a TXT record to your company's domain registrar. You should do this only if the registrar is authoritative or the domain.

You should not add CNAME records. CNAME records are alias records that allow you to forward requests from a domain name to another domain name or server.
---

Add your custom domain name using the Azure Active Directory portal;https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/add-custom-domain

Directory portal Configuring a custom domain name for an Azure cloud service;https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-custom-domain-name-portal
###
C
You plan to use Azure AD join in a federated environment. You need to ensure that the identity provider supports WS-* protocols to ensure that Azure AD join works natively.

Which two protocols must be supported? Each correct answer presents part of the solution.
---
WS-Fed *
WS-Policy
WS-Reliability
WS-Trust *
---
You should make sure that the identity provider supports the WS-Fed protocol. This protocol is required to join a device to Azure AD.

You should also make sure that the identity provider supports the WS-Trust protocol. This protocol is required to sign in to an Azure AD joined device. Both of these protocols are needed if Azure AD join is intended to work natively.

You should not make sure that the identity provider supports the WS-Reliability protocol. This protocol guarantees reliable messaging in Web Services applications. WS-Reliability was superseded by WS-ReliableMessaging.

You should not make sure that the identity provider supports the WS-Policy protocol. This protocol describes the capabilities and constraints of the security policies on communication endpoints.
---

How to: Plan your Azure AD join implementation;https://docs.microsoft.com/en-us/azure/active-directory/devices/azureadjoin-plan

###
Your company uses Azure Active Directory (AD). You find that the service account defined on the Azure AD Connector cannot contact Azure AD because the password has expired.

You need to provide Azure AD Global admin credentials.

Which cmdlet should you use?
---
Get-PasswordSyncLogStatus
Set-ADSyncAADPasswordResetConfiguration
Set-FullPasswordSync
Add-ADSyncAADServiceAccount *
---
You should use the Add-ADSyncAADServiceAccount cmdlet to provide Azure AD Global admin credentials. You need to pass the connector name and the credentials of the administrator.

You should not use the Set-ADSyncAADPasswordResetConfiguration cmdlet to provide Azure AD Global admin credentials. This cmdlet is used to disable and enable password writeback.

You should not use the Set-FullPasswordSync cmdlet to provide Azure AD Global admin credentials. This cmdlet resets the password sync state information, which forces a full sync the next time the service is started.

You should not use the Get-PasswordSyncLogStatus cmdlet to provide Azure AD Global admin credentials. This cmdlet is used to retrieve the current logging level for the Password Sync feature of the Azure Active Directory Sync tool.
---

Azure AD Connect sync: How to manage the Azure AD service account;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-azureadaccount

###
You are the IT administrator for your company. Your company hosts Active Directory (AD). You want to also use Azure AD.

You need to configure your environment so that password hash synchronization can be used for authentication.

What should you do?
---
Create a site link on an Azure virtual machine (VM).
Create a site link bridge on an on-premises server.
Install Azure AD Connect on an on-premises server. *
Install AD Domain Services on an Azure virtual machine (VM).
---
You should install Azure AD Connect on an on-premises server. This tool allows you to synchronize password hashes from a domain controller to Azure AD.

You should not install AD Domain Services on an Azure VM. This does not allow synchronization from an on-premises AD infrastructure. It simply places a domain controller in the cloud instead of on-premises.

You should not create a site link on an Azure VM. A site link is an AD object that allows replication across on-premises domain controllers.

You should not create a site link bridge on an on-premises server. A site link bridge is an AD object that represents a collection of site links, which allow replication across on-premises domain controllers.

---
Getting started with Azure AD Connect using express settings;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-install-express

What is hybrid identity?;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/whatis-hybrid-identity

Join a Windows Server virtual machine to a managed domain;https://docs.microsoft.com/en-us/azure/active-directory-domain-services/join-windows-vm

Active Directory Replication Concepts;https://docs.microsoft.com/en-us/windows-server/identity/ad-ds/get-started/replication/active-directory-replication-concepts
###
You implement Azure Active Directory (Azure AD) Connect so you can synchronize accounts in your on-premises AD with those in Azure AD. You decide to synchronize only a specific organizational unit.

You receive the following error during the first synchronization:

"Number of deletions exceeds the default threshold of 500 objects".

You need to successfully synchronize the accounts.

Which cmdlet should you use?
---
Disable-ADSyncExportDeletionThreshold *
Enable-ADSyncExportDeletionThreshold -ThresholdPercentage 10
Enable-ADSyncExportDeletionThreshold -DeletionThreshold 1000
Get-ADSyncExportDeletionThreshold
---
You should run the Disable-ADSyncExportDeletionThreshold cmdlet. This cmdlet disables the deletion protection and allows the synchronization to complete without errors. When you install Azure AD Connect, it prevents accidental deletes by default. The default configuration does not allow an export with more than 500 deletes. This feature is designed to protect from accidental configuration changes and changes to the on-premises directory that would affect many users and other objects.

You should not run the Enable-ADSyncExportDeletionThreshold -DeletionThreshold 1000 cmdlet. It changes the threshold from the default value (500) to 1000 elements. When the number of elements is reached, an error occurs.

You should not run the Enable-ADSyncExportDeletionThreshold -ThresholdPercentage 10 cmdlet. It changes the threshold from the default value (500 elements) to percentage values. When the number of elements is reached, an error occurs.

You should not run the Get-ADSyncExportDeletionThreshold cmdlet. It is used to display the current threshold value.
---
Azure AD Connect sync: Prevent accidental deletes;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sync-feature-prevent-accidental-deletes
###
You need to enable encryption for a running Windows Infrastructure-as-a-Service (IaaS) virtual machine (VM).

Which PowerShell cmdlet should you use?
---
ConvertTo-AzVMManagedDisk
Set-AzDiskDiskEncryptionKey
Set-AzVMDataDisk
Set-AzVMDiskEncryptionExtension *
---
You should use the Set-AzVMDiskDiskEncryptionExtension cmdlet. This cmdlet is used to enable encryption on a running VM by installing the disk encryption extension. This cmdlet is used to enable encryption for a Windows or supported Linux VM. You should create a snapshot of the VM before enabling encryption.

You should not use the Set-AzVMDataDisk cmdlet. This cmdlet is used to modify properties for a VM data disk but does not include properties related to encryption.

You should not use the Set-AzDiskDiskEncryptionKey cmdlet. This cmdlet sets the disk encryption key properties on a disk but does not enable encryption.

You should not use the ConvertTo-AzVMManagedDisk cmdlet. This cmdlet is used to convert a VM with blob-based disks to a VM with managed disks.
---
Azure Disk Encryption for virtual machines and virtual machine scale sets;https://docs.microsoft.com/en-us/azure/security/fundamentals/azure-disk-encryption-vms-vmss

Enable Azure Disk Encryption for Windows IaaS VMs;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/disk-encryption-overview

Set-AzVMDiskEncryptionExtension;https://docs.microsoft.com/en-us/powershell/module/az.compute/set-azvmdiskencryptionextension?view=azps-3.8.0

Set-AzVMDataDisk;https://docs.microsoft.com/en-us/powershell/module/az.compute/set-azvmdatadisk?view=azps-3.8.0

Set-AzDiskDiskEncryptionKey;https://docs.microsoft.com/en-us/powershell/module/az.compute/set-azdiskdiskencryptionkey?view=azps-3.8.0

Update-AzDisk;https://docs.microsoft.com/en-us/powershell/module/az.compute/update-azdisk?view=azps-3.8.0
###
An Azure resource group was initially deployed from an Azure Resource Manager (ARM) template. Resources have since been added and modified manually through Azure portal.

You need to create a new template based on the current state of the resource group.

Which PowerShell cmdlet should you use?
---
Save-AzureRmResourceGroupDeploymentTemplate
Export-AzureRmResourceGroup *
Save-AzureRmDeploymentTemplate
New-AzureRmResourceGroupDeployment
---
You should use the Export-AzureRmResourceGroup cmdlet. This cmdlet captures a specified resource group and saves it as a template to a JSON file. This gives you a way to create a template based on the current resources in a resource group. You also have the option of exporting a running resource group as a template from Azure portal.

You should not use the Save-AzureRmResourceGroupDeploymentTemplate cmdlet. This saves a resource group deployment, not the current resource group, to a file. You must specify both the deployment name and resource group name.

You should not use the Save-AzureRmDeploymentTemplate cmdlet. This saves an existing deployment template to a new template file.

You should not use the New-AzureRmResourceGroupDeployment cmdlet. This cmdlet is used to apply a template to an existing resource group, not create a new template file.
---

Announcing template export feature in Azure Resource Manager;https://azure.microsoft.com/en-us/blog/export-template/

Save-AzureRmResourceGroupDeploymentTemplate;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/save-azurermresourcegroupdeploymenttemplate?view=azurermps-6.13.0

Export-AzureRmResourceGroup;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/export-azurermresourcegroup?view=azurermps-6.13.0

New-AzureRmResourceGroupDeployment;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/new-azurermresourcegroupdeployment?view=azurermps-6.13.0

Save-AzureRmDeploymentTemplate;https://docs.microsoft.com/en-us/powershell/module/azurerm.resources/save-azurermdeploymenttemplate?view=azurermps-6.13.0
###
C
You are the IT administrator for an automobile dealership on the west coast of the United States. The dealership wants to take advantage of Microsoft Azure by first moving its website to the cloud. The dealership wants to use the lowest cost solution possible.

Business Requirements
One of the problems the dealership has been facing is website downtime. The dealership typically provides maintenance every Sunday and Wednesday at 2:00 A.M. Eastern Time. However, because the dealership wants to attract customers all over the world, it wants to ensure that the website is always available. During peak seasons, the dealership notices that the website responds slower. The dealership wants this bottleneck eliminated.

Technical Requirements
The website is currently hosted at the dealership's domain registrar. The dealership wants move the site to Azure on Windows Server virtual machines (VMs). Users must be able to use the same domain name to reach the website. The website must be hosted in only one Azure region. The VMs must use a four-gigabyte (GB) solid state drive (SSD). The dealership expects there be less hands-on maintenance and administration once the infrastructure is moved to Azure.

You need to create the VM and assign it to the availability set named WebSiteAvailabilitySet.

Which commands should you use? Select correct placeholder values.

$set = Get-AzureRmAvailabilitySet -ResourceGroupName WebSiteResoureGroup -Name WebSiteAvailabilitySet 
$vm = PLACEHOLDER 1
-VMName "DealershipWebServer" -VMSize "PLACEHOLDER 2" -AvailabilitySetId 
"PLACEHOLDER 3"
"PLACEHOLDER 4" -ResourceGroupName WebSiteResourceGroup 
"PLACEHOLDER 5"
---
PLACEHOLDER 1: New-AzureRmVM
PLACEHOLDER 1: New-AzureRmVMConfig *
PLACEHOLDER 2: 4 GiB
PLACEHOLDER 2: Standard_B1s *
PLACEHOLDER 3: $set
PLACEHOLDER 3: $set.id *
PLACEHOLDER 3: WebSiteAvailabilitySet
PLACEHOLDER 4: $vm |
PLACEHOLDER 4: New-AzureRmVM *
PLACEHOLDER 4: New-AzureRmVMConfig
PLACEHOLDER 5: -Location "westus"
PLACEHOLDER 5: -Location "westus" -VM $vm *
---
You should use the following commands:

$set = Get-AzureRmAvailabilitySet
       -ResourceGroupName WebSiteResoureGroup
       -Name WebSiteAvailabilitySet

$vm = New-AzureRmVMConfig
       -VMName "DealershipWebServer"
       -VMSize "Standard_B1s"
       -AvailabilitySetId $set.Id

New-AzureRmVM -ResourceGroupName WebSiteResourceGroup
       -Location "westus" -VM $vm

The first command uses Get-AzureRmAvailabilitySet to retrieve the availability set named WebSiteAvailabilitySet and store it in a variable named $set.

The second command uses New-AzureRmVMConfig to create a VM configuration that sets the VM name to DealershipWebServer and the size to a B-series size named Standard_B1s. This is a Standard offering with a 4-GB SSD. This command also places the VM in the availability set retrieved by the first command. It stores the result in a variable named $vm.

The third command uses New-AzureRmVM to actually create the VM. It uses the configuration stored in the $vm variable to create the VM, and it places the VM in the West United States region.

You should not call New-AzureRmVM before New-AzureRmVMConfig. New-AzureRmVMConfig allows you to create the VM configuration, while New-AzureRmVM uses that configuration to create the VM.

You should not specify 4 GiB as the value for the -VMSize parameter. The value must be in the form <Offering>_<VM Size>.

You should not specify $set or WebSiteAvailabilitySet as the value of the -AvailabilitySetId parameter. The value must be the ID of an availability set.

You should not call New-AzureRmVM without specifying a value for the -VM parameter. Otherwise an empty VM is created.

You should not call New-AzureRmVMConfig last. This command is used to create a VM configuration, not to create the actual VM.
---

New-AzureRmVM;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermvm?view=azurermps-6.13.0

New-AzureRmVMConfig;https://docs.microsoft.com/en-us/powershell/module/azurerm.compute/new-azurermvmconfig?view=azurermps-6.13.0
###
C
You are the IT administrator for an automobile dealership on the west coast of the United States. The dealership wants to take advantage of Microsoft Azure by first moving its website to the cloud. The dealership wants to use the lowest cost solution possible.

Business Requirements
One of the problems the dealership has been facing is website downtime. The dealership typically provides maintenance every Sunday and Wednesday at 2:00 A.M. Eastern Time. However, because the dealership wants to attract customers all over the world, it wants to ensure that the website is always available. During peak seasons, the dealership notices that the website responds slower. The dealership wants this bottleneck eliminated.

Technical Requirements
The website is currently hosted at the dealership's domain registrar. The dealership wants move the site to Azure on Windows Server virtual machines (VMs). Users must be able to use the same domain name to reach the website. The website must be hosted in only one Azure region. The VMs must use a four-gigabyte (GB) solid state drive (SSD). The dealership expects there be less hands-on maintenance and administration once the infrastructure is moved to Azure.

You need to eliminate the bottleneck during peak seasons.

Which two Azure resources should you create? Each correct answer presents part of the solution.
---
Service Fabric cluster
Load balancer *
Scale set *
API Management gateway
Traffic Manager profile
---
You should create a scale set. A scale set contains one or more identical VMs. It can be configured to automatically scale out more VMs as the CPU threshold increases.

You should also create a load balancer. A load balancer distributes traffic evenly across a set of VMs.

You should not create a Service Fabric cluster. Service Fabric allows you to scale out micro-services. In this scenario, you need to scale out VMs.

You should not create a Traffic Manager profile. Traffic Manager distributes traffic across Azure regions. It uses DNS to determine the nearest Azure datacenter to which external traffic should be routed.

You should not create an API Management gateway. API Management allows API developers to publish and secure web APIs.
---

What are virtual machine scale sets?;https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/overview

Overview of Azure Service Fabric;https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-overview

What is API Management?;https://docs.microsoft.com/en-us/azure/api-management/api-management-key-concepts
###
You are the IT administrator for an automobile dealership on the west coast of the United States. The dealership wants to take advantage of Microsoft Azure by first moving its website to the cloud. The dealership wants to use the lowest cost solution possible.

Business Requirements
One of the problems the dealership has been facing is website downtime. The dealership typically provides maintenance every Sunday and Wednesday at 2:00 A.M. Eastern Time. However, because the dealership wants to attract customers all over the world, it wants to ensure that the website is always available. During peak seasons, the dealership notices that the website responds slower. The dealership wants this bottleneck eliminated.

Technical Requirements
The website is currently hosted at the dealership's domain registrar. The dealership wants move the site to Azure on Windows Server virtual machines (VMs). Users must be able to use the same domain name to reach the website. The website must be hosted in only one Azure region. The VMs must use a four-gigabyte (GB) solid state drive (SSD). The dealership expects there be less hands-on maintenance and administration once the infrastructure is moved to Azure.

You need configure Azure to automatically notify the owner of the dealership when peak season appears to have started. The solution must minimize expense and difficulty to implement.

What should you do?
---
Use Machine Learning to create a model that examines historical memory usage and send an email when consumption is high.
Use Monitor to capture the average CPU percentage over time and create an alert when a CPU threshold is exceeded. *
Create a Function that uses a timed trigger to monitor CPU usage and send a text message when a CPU threshold is exceeded.
Create a WebJob that uses a timed trigger to monitor memory usage and invoke WebHook when consumption is high.
---
You should use Monitor to create an alert when a CPU threshold is exceeded. With Monitor, you first choose a resource to monitor. In this scenario, the resource is a VM. You then choose a condition to monitor. In this scenario, when peak season starts, the website's response time is slower. This means that the CPU is doing more work than usual. Therefore, you should create a condition that monitors CPU percentage. You then choose an action. You can configure an action to e-mail the owner of the dealership when the CPU percentage exceeds a specific threshold.

You should not use Machine Learning. With Machine Learning, you import historical data into a model to predict future outcomes. You cannot monitor VM metrics like CPU usage and memory consumption.

You should not create a Function. This requires you to create an App Service resource. Also, you would need to manually write code to monitor CPU usage on the VM and send the text message.

You should not create a WebJob. This requires you to create an App Service resource. Also, you would need to manually write code to monitor memory consumption on the VM and invoke the WebHook. You would also need to code the WebHook to send the message to the owner.
---
How to monitor virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/monitor

What is automated machine learning?;https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml

Azure Functions triggers and bindings concepts;https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings

Run Background tasks with WebJobs in Azure App Service;https://docs.microsoft.com/en-us/azure/app-service/webjobs-create
###
C
You are the IT administrator for an automobile dealership on the west coast of the United States. The dealership wants to take advantage of Microsoft Azure by first moving its website to the cloud. The dealership wants to use the lowest cost solution possible.

Business Requirements
One of the problems the dealership has been facing is website downtime. The dealership typically provides maintenance every Sunday and Wednesday at 2:00 A.M. Eastern Time. However, because the dealership wants to attract customers all over the world, it wants to ensure that the website is always available. During peak seasons, the dealership notices that the website responds slower. The dealership wants this bottleneck eliminated.

Technical Requirements
The website is currently hosted at the dealership's domain registrar. The dealership wants move the site to Azure on Windows Server virtual machines (VMs). Users must be able to use the same domain name to reach the website. The website must be hosted in only one Azure region. The VMs must use a four-gigabyte (GB) solid state drive (SSD). The dealership expects there be less hands-on maintenance and administration once the infrastructure is moved to Azure.
---
Assign a DNS name label. *
Assign a public static IP address.
Add an inbound port rule. *
Add an extension.
Add an outbound port rule.
---
You should add an inbound port rule to the VM. This rule should allow traffic over an HTTP port, which by default is port 80. (For HTTPS, the port is 443.)

You should also add a DNS name label to the VM. This is a host (A) record that resolves to the public IP address assigned to the VM. The public IP address is dynamic by default, and this does not cost any more money. At the domain registrar, you can create a CNAME record that points your website domain name to Azure at [dnsnamelabel].[region].cloudapp.azure.net.

You should not add a VM extension. A VM extension is a small application that provides post deployment tasks. For example, an extension can automatically install anti-virus software whenever a VM is deployed through script.

You should not add an outbound port rule to the VM. The VM should allow all outbound traffic by default.

You should not assign a public static IP address to the VM. This causes the IP address assigned to it to always remain the same. However, this is not necessary and it costs more money. You can use a CNAME record at the domain registrar and a DNS name label in Azure.
---

Tutorial: Map an existing custom DNS name to Azure Web Apps;https://docs.microsoft.com/en-us/azure/app-service/app-service-web-tutorial-custom-domain

Create a virtual machine with a static public IP address using the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-deploy-static-pip-arm-portal

Security groups;https://docs.microsoft.com/en-us/azure/virtual-network/security-overview

Virtual machine extensions and features for Windows;https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/features-windows
###
You are the IT administrator for a small law firm. The company has one lawyer and one legal assistant. The company has two Windows 10 Professional desktop computers and a Linux server that hosts a web-based case management system.

Existing Infrastructure
The two desktop computers and the Linux server are connected by a network hub. The hub itself is connected to a router, which connects directly to the Internet via cable. No inbound ports are open on the router. The desktop computers host client applications that connect to the case management system at IP address 10.10.10.10 over TCP port 24000.

Business Requirements
The owner of the firm wants it to transition to a virtual firm. The lawyer and the assistant must be able to work from home by connecting to the Windows 10 desktop computers from any device. The owner wants you to move the existing infrastructure to Azure and make the system work as if it were in the physical office. However, the owner wants to use the minimum amount of resources and the least expensive options.

Technical Requirements
The two computers and server should be imported into Azure as virtual machines (VMs). The VMs for the lawyer and assistant should be always available, even during periods of upgrades or maintenance. As more cases are imported into the case management system, the disk attached to the Linux VM should automatically resize to ensure that it always has 20 percent of free space.

You create two Windows 10 virtual machines for the lawyer and legal assistant. You must ensure that the lawyer and legal assistant can connect to their desktop computers from any location and from any device.

What should you do?
---
Move each VM into its own subnet.
Place the two VMs in the same availability set.
Add an inbound port rule to each VM. *
Assign a static public IP address to each VM.
---
You should add an inbound port rule to each VM. An inbound port rule specifies the port that must be open for the VM. In this scenario, you can open a Remote Desktop Protocol (RDP) port to allow the lawyer and legal assistant to remotely connect to the VMs.

You should not place the two VMs in the same availability set. An availability set allows one VM to be responsive when another VM is down for maintenance or some unexpected event. It does not allow users to connect to a VM remotely.

You should not move each VM into its own subnet. This increases resource management. Both VMs can be part of the same subnet.

You should not assign a static public IP address to each VM. This is not necessary, and it will add to the monthly cost. You can continue to use the dynamic public IP address that is assigned to each VM by default.
---

Create a virtual machine with a static public IP address using Azure portal;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-deploy-static-pip-arm-portal

Manage the availability of Windows virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/manage-availability

How to open ports to a virtual machine with the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal

Virtual networks and virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/network-overview
###
You are the IT administrator for a small law firm. The company has one lawyer and one legal assistant. The company has two Windows 10 Professional desktop computers and a Linux server that hosts a web-based case management system.

Existing Infrastructure
The two desktop computers and the Linux server are connected by a network hub. The hub itself is connected to a router, which connects directly to the Internet via cable. No inbound ports are open on the router. The desktop computers host client applications that connect to the case management system at IP address 10.10.10.10 over TCP port 24000.

Business Requirements
The owner of the firm wants it to transition to a virtual firm. The lawyer and the assistant must be able to work from home by connecting to the Windows 10 desktop computers from any device. The owner wants you to move the existing infrastructure to Azure and make the system work as if it were in the physical office. However, the owner wants to use the minimum amount of resources and the least expensive options.

Technical Requirements
The two computers and server should be imported into Azure as virtual machines (VMs). The VMs for the lawyer and assistant should be always available, even during periods of upgrades or maintenance. As more cases are imported into the case management system, the disk attached to the Linux VM should automatically resize to ensure that it always has 20 percent of free space.

You need to meet the availability demands for Windows computers.

What should you do?
---
Implement vertical auto-scaling.
Create one availability set for each VM. *
Implement horizontal auto-scaling.
Create one availability set for both VMs.
---
You should create one availability set for each VM. An availability set allows you to group VMs for availability. For example, the first availability set can contain the Windows 10 computer for the assistant, with additional VM instances for failover support. The second availability set can contain the Windows 10 computer for the lawyer, with additional VM instances for failover support.

You should not create one availability set for both VMs. This would cause the lawyer's VM to be used when the assistant's VM is being upgraded, and vice versa.

You should not implement horizontal auto-scaling. Horizontal auto-scaling allows more VMs to be created as load on a particular VM increases. It does not provide failover support.

You should not implement vertical auto-scaling. Vertical auto-scaling allows more resources to be added to a VM as load on a particular VM increases. It does not provide failover support.

---

Manage the availability of Windows virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/manage-availability

Overview of autoscale with Azure virtual machine scale sets;https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview

Automatically scale a virtual machine scale set in the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-portal
###
C
You are the IT administrator for a small law firm. The company has one lawyer and one legal assistant. The company has two Windows 10 Professional desktop computers and a Linux server that hosts a web-based case management system.

Existing Infrastructure
The two desktop computers and the Linux server are connected by a network hub. The hub itself is connected to a router, which connects directly to the Internet via cable. No inbound ports are open on the router. The desktop computers host client applications that connect to the case management system at IP address 10.10.10.10 over TCP port 24000.

Business Requirements
The owner of the firm wants it to transition to a virtual firm. The lawyer and the assistant must be able to work from home by connecting to the Windows 10 desktop computers from any device. The owner wants you to move the existing infrastructure to Azure and make the system work as if it were in the physical office. However, the owner wants to use the minimum amount of resources and the least expensive options.

Technical Requirements
The two computers and server should be imported into Azure as virtual machines (VMs). The VMs for the lawyer and assistant should be always available, even during periods of upgrades or maintenance. As more cases are imported into the case management system, the disk attached to the Linux VM should automatically resize to ensure that it always has 20 percent of free space.

You need to ensure that the Linux virtual machine (VM) automatically expands its disk size when it is running low on space.

What two actions should you perform? Each correct answer presents part of the solution.
---
Install a script on the VM that monitors the disk space and sends a notification to Azure. *
Create an Azure Function that uses an HTTP trigger. *
Configure Azure Monitor with an alert rule.
Run an Azure PowerShell command from the VM.
Run an Azure CLI command from the VM.
---
You should install a script on the VM that monitors the disk space and sends a notification to Azure. This script can be written in the language of your choice. The type of notification should be an HTTP request.

You should also create an Azure Function that uses an HTTP trigger. When this trigger is invoked, it should stop the VM, expand the disk, and then restart the VM.

You should not configure Azure Monitor with an alert rule. Azure Monitor can monitor a VM for free disk space and an alert rule can trigger an alert. However, the alert is only shown in the Azure portal, so no action is triggered based on the alert. If you do this, the Linux VM disk will not be expanded.

You should not run an Azure PowerShell or Azure CLI command from the VM. Although both types of commands can be used to expand a disk, they should be run from a separate computer or VM instance.
---

Expand virtual hard disks on a Linux VM with the Azure CLI;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/expand-disks

How to monitor virtual machines in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/monitor

Azure Monitor data platform;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/data-platform
###
C
You need to create an alert for a virtual machine named VM1 that will be fired when the VM's CPU utilization is greater than 95 percent for at least 10 minutes. You also need to add an action group named AG1 to this alert.

What should you do? Select correct placeholder values.

az monitor metrics alert PLACEHOLDER 1 -n A1 -g RG1 -- PLACEHOLDER 2 "avg Percentage CPU > 95"
-- PLACEHOLDER 3 10m -- PLACEHOLDER 4 AG1
---
PLACEHOLDER 1: create *
PLACEHOLDER 1: list 
PLACEHOLDER 1: show
PLACEHOLDER 2: condition *
PLACEHOLDER 2: condition description
PLACEHOLDER 2: scopes
PLACEHOLDER 3: action
PLACEHOLDER 3: evaluation-frequency
PLACEHOLDER 3: window-size *
PLACEHOLDER 4: action *
PLACEHOLDER 4: condition
PLACEHOLDER 4: name
---
You should use the following command:

az monitor metrics alert create -n A1 -g RG1 --condition "avg Percentage CPU > 95"

--window-size 10m --action AG1

You should use the az monitor metrics alert create command to create a metric-based alert rule. The list and show commands list alert rules and show a specific alert rule.

You should use the condition parameter to specify the condition that triggers the rule. The scopes option defines an action group associated with an alert, and the description option provides a free-text description of the rule.

You should use the window-size option to define a time window in which the value of the condition is aggregated. You should not use the evaluation-frequency option to define a time window in which the value of the condition is aggregated. This option is used to define the frequency at which measured values are calculated. The action option defines an action group associated with an alert.

You should use the action option to define an action group associated with the alert. The name option assigns a name to the rule. The condition parameter specifies the condition that triggers the rule.
---
az monitor metrics alert;https://docs.microsoft.com/en-us/cli/azure/monitor/metrics/alert?view=azure-cli-latest
###
C
You need to provide information from Azure Log Analytics for the following sources:

* Windows event log and Syslog
* Application insights about traces, requests, and page views
* Performance metrics

You need to deliver all data from the event log and Syslog. You must deliver only matched data for application insights and performance metrics.

Which operators are required in the Log Analytics query for the data that you need to deliver?

Select correct placeholder values.

Windows event log PLACEHOLDER 1
Syslog PLACEHOLDER 2
Application insights PLACEHOLDER 3
Performance metrics PLACEHOLDER 4
---
PLACEHOLDER 1: union *
PLACEHOLDER 1: inner join
PLACEHOLDER 1: inner unique join
PLACEHOLDER 2: union *
PLACEHOLDER 2: inner join
PLACEHOLDER 2: inner unique join
PLACEHOLDER 3: union
PLACEHOLDER 3: inner join *
PLACEHOLDER 3: inner unique join
PLACEHOLDER 4: union
PLACEHOLDER 4: inner join *
PLACEHOLDER 4: inner unique join
---
You should use the union operator to deliver all data from the Windows event log and Syslog. The operator takes all rows from first source and appends all data from the second source. The structure of the sources must be identical.

You should use the inner join operator to deliver only matched data from application insights and performance metrics. The inner join operator returns matching records from both sources.

You should not use the inner join operator to deliver all data from the event log and Syslog. The inner join operator requires that sources have columns that can be used as keys to perform matching.

You should not use the inner unique join operator to deliver all data from the event log and Syslog. The inner unique join operator requires that sources have columns that can be used as keys to perform matching. The inner unique join operator removes duplicates.

You should not use the union operator to deliver only matched data from application insights and performance metrics. The union operator takes all rows from the first source and appends all data from the second source. The structure of the sources must be identical.

You should not use the inner unique join operator to deliver only matched data from application insights and performance metrics. The inner unique join operator removes duplicates.
---
Analyze Log Analytics data in Azure Monitor;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/log-query-overview
###
C
You need to retrieve data from Log Analytics on virtual machines (VMs) hosted on Azure. You must write a Log Analytics query that meets the following requirements:

* Find VMs that have failed to send a heartbeat signal within the previous hour
* Summarize the data by operating system type

How should you complete the query? Select correct placeholder values.

Heartbeat
| where PLACEHOLDER 1
| summarize distinct_computers= PLACEHOLDER 2 (Computer) by OSType
---
PLACEHOLDER 1: now() - TimeGenerated > 1h
PLACEHOLDER 1: TimeGenerated > ago(1h) *
PLACEHOLDER 1: TimeGenerated > now(1h)
PLACEHOLDER 2: Count
PLACEHOLDER 2: Dcount *
PLACEHOLDER 2: Dcountif
---
You should use the following command:

Heartbeat
|where TimeGenerated > ago(1h)
|summarize distinct_computers=Dcount(Computer) by OSType

You should use the TimeGenerated > ago(1h) condition to find all heartbeats that have been generated within the last hour. The ago(1h) function is a shortcut of the now(-1h) function and has the same meaning.

You should not use the TimeGenerated > now(1h) condition to find all heartbeats that have been generated within last hour. The now(1h) function would find events older than one hour.

You should not use the now()-TimeGenerated > 1h condition to find all heartbeats that have been generated within last hour. The now()-TimeGenerated > 1h function would find events older than one hour.

You should use the Dcount function to calculate the distinct number of computers that have sent a heartbeat signal within the last hour.

You should not use the count function to calculate the distinct number of computers that have sent a heartbeat signal within the last hour. The count function would sum all the heartbeat signals.

You should not use the Dcountif function to calculate the distinct number of computers that have sent a heartbeat signal within the last hour. This function is used to add a filter to the counting process. For example, you could count only computers running Linux.
---
Azure Monitor log queries;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/query-language
###
C
You monitor security events collected from virtual machines (VMs) hosted on Azure.

You prepare a static table that consists of the security event codes. You need to show the description of the event and how many times it occurred on the VM. If an event code is not present, zero should be displayed.

Select correct placeholder values.

Recuirement: Join to use to match data from the events with static table: Query option: PLACEHOLDER 1
Recuirement: Function to use to count the number of events: Query option: PLACEHOLDER 2
---
PLACEHOLDER 1: Innerunique
PLACEHOLDER 1: Leftanti
PLACEHOLDER 1: Leftouter *
PLACEHOLDER 2: Count *
PLACEHOLDER 2: DCount
PLACEHOLDER 2: DCountIf
---
You should use a Leftouter join to match data from the events with the static table. For this type of join, all records in the left table and matching records in the right table are included in the results. Unmatched output properties contain nulls.

You should not use the Innerunique join type to match data from the events with the static table. This is the default join mode. The values of the matched column on the left table are found, and duplicate values are removed. Then, the set of unique values is matched against the right table.

You should not use the Leftanti join type to match data from the events with the static table. Records from the left side that do not have matches on the right side are included in the results. The results table has only columns from the left table.

You should use the Count aggregation function. This function returns a count of the security events.

You should not use the DCount aggregation function to count the number of security events. The DCount function is used to calculate the distinct count values and remove duplicates from the dataset. In this case, you would observe only one event per VM.

You should not use the DCountIf aggregation function to count the number of security events. The DCountIf function is used to calculate the distinct count values and remove duplicates from the dataset. In this case, you would observe only one event per VM.
---

Azure Monitor log queries;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/query-language

Joins in Azure Monitor log queries;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/joins
###
C
You are the IT administrator for an Azure subscription. You create a Log Analytics workspace that you want to use to monitor all the virtual machines (VMs) in the subscription that have not been responsive today.

You need to create the query.

How should you create the query? To answer, select the appropriate code segments from the drop down menus.

PLACEHOLDER 1
| where TimeGenerated > ago(7d)
| summarize PLACEHOLDER 2 by Computer
| where PLACEHOLDER 3 < ago(1d)
---
PLACEHOLDER 1: Heartbeat *
PLACEHOLDER 1: max(TimeGenerated)
PLACEHOLDER 1: TimeGenerated
PLACEHOLDER 2: Heartbeat
PLACEHOLDER 2: max(TimeGenerated) *
PLACEHOLDER 2: max_TimeGenerated
PLACEHOLDER 2: TimeGenerated
PLACEHOLDER 3: Heartbeat
PLACEHOLDER 3: max_TimeGenerated *
PLACEHOLDER 3: TimeGenerate
---
You should use the following query:

Heartbeat
| where TimeGenerated > ago(7d)
| summarize max(TimeGenerated) by Computer
| where max_TimeGenerated < ago(1d)

This query searches the Heartbeat table for all events, TimeGenerated, that were generated more than seven days ago. It summarizes those events by the maximum time, max(TimeGenerated). It then filters those events where the maximum time generated, max_TimeGenerated, is less than one day.
---
Analyze log data in Azure Monitor;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/log-query-overview
###
C
You are the Azure administrator for an online personal training company. You create a blob storage account to store training videos. Only you should be able to manage the storage account.

The storage account has a container that personal trainers use to upload their videos. Only personal trainers that your company approves should be able to upload video files.

Choose all that apply:
---
You should create a shared access signature. *
You should set the access level of the blob container to Public.
You should share the storage account key with the personal trainers.	
---
You should create a shared access signature. This is a URI that contains access rights to an Azure resource.

You should not set the access level of the blob container to Public. This allows anyone to access the container, including anonymous users. You should instead set the access level to Private. By doing this and giving out the shared access signature, you can control who has access to the blob container.

You should not share the storage account key with the personal trainers. This allows the personal trainers to manage the storage account, including the ability to delete other trainers' videos.
---
Using shared access signatures (SAS);https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview
###
C
You are a Cloud Solutions Architect for a mobile application development company. The company has worldwide users that require consistently high performance.

You now want to drop the dependency on physical datacenter storage. You plan to create a new storage solution for the enterprise that uses Azure Storage for disaster recovery, high availability, and performance.
Choose all that apply:
---
You should use Premium Storage for global replication.
If your app needs a lower recovery time objective (RTO), you should use a second regional deployment. *
You can use HTTP and HTTPS to authorize blob and queue operations with an OAuth token.	
---
You should not use Premium Storage for global replication. Premium Storage is available only for locally redundant storage (LRS) replication. Also, Premium Storage is not available for all regions.
 
Recovery time objective (RTO) is the maximum acceptable time that an application can be unavailable after an incident. For example, if your RTO is 50 minutes, you can restore the application to a running state within 50 minutes after the start of an incident. However, if you have a very low RTO, you might keep a second regional deployment continually running an active/passive configuration on standby to protect against a regional outage.
 
You cannot authorize the Azure Storage from HTTP. To authorize blob and queue operations with an OAuth token, you must use HTTPS.
---

Azure Storage redundancy;https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy

Use an Azure AD identity to access Azure Storage with CLI or PowerShell (Preview);https://docs.microsoft.com/en-us/azure/storage/common/authorize-active-directory-powershell?toc=%2Fazure%2Fstorage%2Fblobs%2Ftoc.json

Designing resilient applications for Azure;https://docs.microsoft.com/en-us/azure/architecture/framework/resiliency/overview
###
C
You are determining which type of Azure storage replication is appropriate for your storage account.

You must consider the features of each replication option and choose the most appropriate one: locally-redundant storage (LRS), zone-redundant storage (ZRS), geo-redundant storage (GRS), or read-access geo-redundant storage (RA-GRS).

Which replication options should you use to provide the features listed in the answer area? Choose all that apply:
---
Projects against hardware failures, but not region-wide unavailability: LRS *
Projects against hardware failures, but not region-wide unavailability: GRS
Projects against hardware failures, but not region-wide unavailability: RA-GRS
Projects against hardware failures, but not region-wide unavailability: ZRS
Can be used with premium performance storage accounts: LRS *
Can be used with premium performance storage accounts: GRS
Can be used with premium performance storage accounts: RA-GRS
Can be used with premium performance storage accounts: ZRS
Provides default replication for Azure storage accounts: LRS
Provides default replication for Azure storage accounts: GRS
Provides default replication for Azure storage accounts: RA-GRS *
Provides default replication for Azure storage accounts: ZRS
---
LRS maintains three copies of your data within a single datacenter in a single region. This type of replication does not protect your data from failure of a single data center or region, but it protects you from hardware failures. 

Premium storage supports only locally redundant storage (LRS). 

RA-GRS replicates your data to another datacenter in a secondary region and provides read-only access to the data in the secondary location. This replication option is the default option for new storage accounts. 
---

Azure Storage redundancy;https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy

Locally redundant storage (LRS): Low-cost data redundancy for Azure Storage;https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy
###
C
You create an Azure storage account that is used to store financial records. These records are accessed frequently. In the event of a data center outage, you want to ensure that the records can still be retrieved, even if they cannot be modified. All applications use REST APIs to access the financial records.

You need to choose the most appropriate, least expensive configuration.
How should you configure the storage account? Choose all that apply:
---
Which access tier should you use? - Cool
Which access tier should you use? - Hot *
Which replication strategy should you use? - LRS
Which replication strategy should you use? - GRS
Which replication strategy should you use? - RS - GRS *
Which performance tier should you use? - Standard *
Which performance tier should you use? - Premium
---
You should use the Hot access tier. This tier is feasible for storage accounts that are accessed frequently.

You should use the RA-GRS replication strategy. With this strategy, if a failure occurs at a datacenter, data is replicated to another datacenter in another region, and it is available for read-only access.

You should use the Standard performance tier. This tier uses magnetic drives to store data at low cost.

You should not use the Cool access tier. This tier is feasible for storage accounts that are not accessed frequently.

You should not use LRS. This replication strategy only copies data within a datacenter. It is feasible for scenarios such as power supply failure or disk failure.

You should not use GRS. This replication strategy copies data to other regions. However, the data is not available to be read unless Microsoft initiates a failover to that region.

You should not use the Premium performance tier. This tier uses solid state drives at a higher cost. These storage accounts can only be used with virtual machine (VM) disks.
---
Azure Storage redundancy;https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy

Azure Blob storage: Premium (preview), Hot, Cool, and Archive storage tiers;https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal
###
You are the IT administrator for an Azure subscription that contains 20 virtual machines (VMs).

You need to write a Log Analytics query to determine which VMs have not been responsive within the past hour.

How should you complete the query? 
---
Heartbeat | where TimeGenerated > ago(1h) *

Heartbeat | where TimeGenerated < ago(1h)

Perf | where Heartbeat > ago(1h)

Perf | where Heartbeat < ago(1h)
---
You should use the following query:

Heartbeat | where TimeGenerated > ago(1h)

This query finds all computers that have had a heartbeat within the past hour. Computers send a heartbeat to let Azure know that they are responsive. The ago(1h) means the timestamp is one hour ago. If TimeGenerated is greater than that timestamp, the heartbeat occurred within the past hour.

You should not use Perf as a source. This source looks at performance counters. In this scenario, you need to search the Heartbeat source, not performance counters.

You should not use the following query:

Heartbeat | where TimeGenerated < ago(1h)

This query finds all computers that have sent a heartbeat before one hour ago.
---
Get started with Azure Monitor log queries;https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-queries
###
C
You are the IT administrator for your company. Your company has a main office in California and a branch office in Amsterdam. Only employees work at the main and branch offices. Contractors can work remotely from anywhere in the world.

An Azure subscription contains a virtual network (VNet) that contains resources to which all employees and contractors must access. Only the main office has a VPN server.

You need to choose a connection type to ensure that each group of workers can access the full network.

Which connection types should you use? Choose all that apply:
---
Use site-to-site for contractors.
Use point-to-site for employees in California.	
Use ExpressRoute for employees in Amsterdam. *
---
You should not use site-to-site for contractors. This connection type allows you to connect to on-premises datacenters by using VPN. It requires that each datacenter host a VPN server. You should instead use site-to-site for the employees in California.

You should not use point-to-site for employees in California. This connection type allows workers to connect to an Azure VNet over the public network. You should use point-to-site for contractors who work remotely.

You should use ExpressRoute for employees in Amsterdam. This connection type allows you to create a private connection between Azure and an on-premises network. It does not require the on-premises location to host a VPN server.
---

Configure ExpressRoute and Site-to-Site coexisting connections (classic);https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-coexist-classic

ExpressRoute FAQ;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-faqs
###
C
You create a VPN gateway using the Resource Manager deployment model and want to verify the connection.

How can you verify the connection?
---
You can use the az network vpn-connection show Azure CLI command to verify connectivity. *
You can use the Get-AzureVNetConnection PowerShell cmdlet to verify connectivity.	
In the Azure portal, you can navigate to the gateway and click Connection to verify connectivity. *
---
You can use the az network vpn-connection show Azure CLI command to show connection status for a gateway created using the Resource Manager deployment model. When the connection is established, its status shows Connected.

You cannot use the Get-AzureVNetConnection PowerShell cmdlet to verify connectivity. The Get-AzureVNetConnection cmdlet is used to show the connection status for a classic VPN gateway. To show the status of a gateway created using the Resource Manager deployment model, you must use the Get-AzureRmVirtualNetworkGatewayConnection PowerShell cmdlet.

In the Azure portal, you can navigate to the gateway and click Connection to verify connectivity for a Resource Manager VPN gateway. You can also click the connection to open Essentials, which shows more information about the connection.
---

Verify a VPN Gateway connection;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-verify-connection-resource-manager
###
C
You have three virtual networks (VNets) named VNET1, VNET2 and VNET3. The VNets have the following subnets:

*VNET1: Subnet11, Subnet12
*VNET2: Subnet21
*VNET3: Subnet31, Subnet32

You perform the following actions:

*Add peering from VNET1 to VNET2
*Add peering from VNET2 to VNET3
*Add peering from VNET3 to VNET2

You need to identify network connectivity between subnets.

Which network connectivity should you identify for each subnet? Choose all that apply:
---
Subnet11 has connectivity with: Subnet12 only *
Subnet11 has connectivity with: Subnet12 and Subnet21 only
Subnet11 has connectivity with: Subnet12, Subnet21 and Subnet31 only
Subnet11 has connectivity with: Subnet12, Subnet21, Subnet31 and Subnet32
Subnet21 has connectivity with: Subnet11 only
Subnet21 has connectivity with: Subnet11 and Subnet12 only
Subnet21 has connectivity with: Subnet31 and Subnet32 only *
Subnet21 has connectivity with: Subnet11, Subnet12, Subnet31 and Subnet32
---
Virtual network (VNet) peering enables you to connect VNets. Peered VNets appear as one for connectivity purposes. You must add peering to both VNets that you want to connect. If you add peering to only one VNet, peering is in the Initiated state, and VNets will not have connectivity.

Subnet11 has network connectivity with Subnet12 only. Those two subnets are on the same VNet. Subnets on the same VNet always have full network connectivity.

Subnet11 does not have network connectivity with Subnet21. Subnet11 is on VNET1, and Subnet21 is on VNET2. You have only added peering between VNET1 and VNET2 in one direction. For this reason, peering is in the Initiated state and the two VNets do not have connectivity. Because the VNets are not connected, Subnet11 does not have connectivity with Subnet21.

Subnet21 has network connectivity with Subnet31 and Subnet32 only. Subnet21 is on a different VNet than Subnet31 and Subnet32. You add peering from VNET2 to VNET3 and from VNET3 to VNET2. Because the VNets are connected, the subnets on VNET2 have full connectivity to subnets on VNET3.

You added peering from VNET1 to VNET2, but you did not add peering from VNET2 to VNET1. Because the peering was only added to one of the VNets, there is no network connectivity between VNET1 and VNET2 and Subnet21 does not have connectivity with Subnet11 and Subnet12.
---

Virtual network peering;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview

Create, change, or delete a virtual network peering;https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-manage-peering
###
You create two Azure virtual machines (VMs) named vm1 and vm2, and then you add them to a virtual network. The private IP addresses for vm1 and vm2 are 10.1.0.10 and 10.1.0.11, respectively. You connect to vm1 by using Remote Desktop from your laptop computer.

You run the following PowerShell cmdlet on vm1:

ping 10.1.0.11

You receive an error message that the request timed out.

You must ensure that the ping command is successful.

You need to run a PowerShell cmdlet on vm2.

How should you complete the cmdlet? 
---
New-NetFirewallRule -DisplayName "Ping" -Protocol ICMPv4 *
New-NetFirewallRule -DisplayName "Ping" -Protocol TCP -LocalPort 3389
New-NetIPsecRule -InboundSecurity Require -RemoteAddress 10.1.0.10
New-NetIPsecRule -InboundSecurity Require -RemoteAddress 127.0.0.1
---
You should run the following cmdlet on vm2:

New-NetFirewallRule -DisplayName "Ping" -Protocol ICMPv4

This cmdlet creates a firewall rule that allows inbound Internet Control Message Protocol (ICMP) traffic to reach vm2. This is necessary because the ping command uses ICMP to communicate.

You should not run the following cmdlet on vm2:

New-NetFirewallRule -DisplayName "Ping" -Protocol TCP -LocalPort 3389

This cmdlet opens TCP port 3389 on vm2. This is the default port for Remote Desktop. The problem is that the ping command is not successful. Also, all of the parts for that cmdlet are not available.

You should not run the following cmdlet on vm2:

New-NetIPsecRule -InboundSecurity Require -RemoteAddress 10.1.0.10

The New-NetIPsecRule cmdlet allows you to configure an IPsec rule. IPsec is a collection of protocols that allow secure communication across IP networks. The problem in this scenario is related to ping, not IPsec.
---

How to open ports to a virtual machine with the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal

Quickstart: Create a virtual network using the Azure portal;https://docs.microsoft.com/en-us/azure/virtual-network/quick-create-portal

New-NetIPsecRule;https://docs.microsoft.com/en-us/powershell/module/netsecurity/new-netipsecrule?view=win10-ps
###
C
You need to change the public IP address for an Azure virtual machine (VM) named sn2-prod-091 to 13.65.243.111.

How should you complete the command? Choose all that apply:
---
Get-AzureVM *
Set-AzureStaticVNetIP *
Update-AzureVM *
Add-AzureRmVMNetworkInterface
New-AzureRmVMConfig
---
You should call the Get-AzureVM cmdlet to retrieve an instance to the Azure VM. Next you should call the Set-AzureStaticVNetIP cmdlet to set the public static IP address of the virtual adapter assigned to that VM. Finally, you should call Update-AzureVM to update the changes.

You should not call Add-AzureRmVMNetworkInterface. This cmdlet adds a new virtual network interface to a VM.

You should not call New-AzureRmVMConfig. This cmdlet creates a configuration that can be used to update a VM. However, it does not actually update the VM.
---

How to reset network interface for Azure Windows VM;https://docs.microsoft.com/en-us/azure/virtual-machines/troubleshooting/reset-network-interface
###
C
You plan to perform an Azure Active Directory (Azure AD) Access Review because you have found a higher number of users than you expected in certain groups and roles.

You need to review the security group members, Azure AD roles, and Azure resource roles.

Where will you create reviews for the different groups? Choose all that apply:
---
Security group members: Azure AD Access reviews *
Security group members: Azure AD enterprise apps
Security group members: Azure AD PIM
Azure AD roles: Azure AD Access reviews
Azure AD roles: Azure AD enterprise apps
Azure AD roles: Azure AD PIM *
Azure resource roles: Azure AD Access reviews
Azure resource roles: Azure AD enterprise apps
Azure resource roles: Azure AD PIM *
---
The review for security group members should be created in Azure AD Access reviews. This can be done from the access panel in Azure. To use the access reviews, you need to have an Azure AD Premium P2 license and an Enterprise Mobility + Security E5 license.

The review for Azure AD roles and Azure resource roles should be created in Azure AD Privileged Identity Management (PIM). This can be done from the Azure portal. Azure PIM is a service that enables you to manage, control, and monitor access to important resources in your organization.

Azure AD enterprise apps is used for reviews of users assigned to connected apps.
---

What are Azure AD Access Reviews;https://docs.microsoft.com/en-us/azure/active-directory/governance/access-reviews-overview

What is Azure AD Privileged Identity Management?;https://docs.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-configure
###
C
You have an Azure Active Directory (Azure AD) tenant named Adatum.com that includes the following users:

• User1, who is a member of a group named Group1.
• User2, who is a member of a group named Group2.

The following Windows 10 computers are joined to Adatum.com:

• Computer1, which is a member of a group named GroupA.
• Computer2, which is a member of a group named GroupA.
• Computer3, which is a member of a group named GroupB.

Enterprise State Roaming in Adatum.com is enabled for Group1 and GroupA only. Choose all that apply:
---
If User1 modifies the desktop background on Computer1, User1 will have the modified background when he is signed in to Computer2. *
If User1 modifies the desktop background on Computer1, User1 will have the modified background when he is signed in to Computer3. *
If User2 modifies the desktop background on Computer1, User2 will have the modified background when he is signed in to Computer2.	
If User2 modifies the desktop background on Computer1, User2 will have the modified background when he is signed in to Computer3.	
---
Enterprise State Roaming (ESR) can be enabled only for users. If device accounts are in a group for which you enable ESR, device accounts are ignored.

If User1 modifies the desktop background on Computer1, User1 will have the modified background when he is signed in to Computer2. ESR is enabled for Group1, which User1 is member of. Desktop background is one of the settings that is roamed by ESR. Because ESR is enabled for User1, the modified desktop background will be visible on all Windows 10 computers on which User1 signs in. That means that the modified desktop will be used also when User1 signs in to Computer3.

If User2 modifies the desktop background on Computer1, User2 will not have the modified background when he is signed in to Computer2. ESR is not enabled for User2 (or for Group2, which User2 is member of). This means that if User2 performs customization at one computer, those customizations will not roam and will not be used when User2 signs in to a different computer.
---

What is enterprise state roaming?;https://docs.microsoft.com/en-us/azure/active-directory/devices/enterprise-state-roaming-overview

Enable Enterprise State Roaming in Azure Active Directory;https://docs.microsoft.com/en-us/azure/active-directory/devices/enterprise-state-roaming-enable
###
C
You plan to enable Azure Active Directory (AD) Identity Protection for your company. The configuration must include the following:

* A role that allows full access to Identity Protection but without resetting passwords for users
* A policy that will analyze user sign-in and learn typical user behavior

Which role and policy will meet these requirements? Choose all that apply:
---
Role: Global Administrator
Role: Security Administrator *
Role: Security Reader
Policy: MFA registration policy
Policy: Sign-in risk policy
Policy: User risk policy *
---
You should recommend the Security administrator role. This role provides full access to Identity Protection but cannot reset user passwords.

You should not recommend the Global administrator role. This role has a full access to Identity Protection but can reset user passwords.

You should not recommend the Security reader role. This role has read-only access to Identity Protection and cannot configure policies or reset passwords.

You should recommend a user risk policy. With this type of policy, Azure AD analyzes each user's sign-in so it can detect suspicious actions (risk events) related to the sign-in. After a particular learning period, the system can learn typical user behavior.

You should not recommend an MFA registration policy. This type of policy provides a second layer of security to user sign-ins and transactions, but it does not analyze user sign-ins and learn typical user behavior.

You should not recommend a sign-in policy. This type of policy is used to define a response for a specific sign-in risk level. It does not analyze user sign-in or learn typical user behavior.
---

Azure AD Identity Protection;https://docs.microsoft.com/en-us/azure/active-directory/identity-protection/

How To: Configure risk policies in Azure Active Directory identity protection (refreshed);https://docs.microsoft.com/en-us/azure/active-directory/identity-protection/howto-identity-protection-configure-risk-policies
###
C
Your company has a hybrid solution that uses an on-premises Active Directory (AD) infrastructure and Azure AD. You want to enable password writeback so that whenever users change their passwords in Azure, the change is reflected on-premises.

You need to perform the required tasks to support password writeback.

Which tasks do you need to perform? For each of the following tasks, select Yes if the task should be performed. Choose all that apply:
---
Assign the Azure AD Premium 1 license to your AD tenant. *
Install Azure AD Connect on an on-premises server. *
Deploy Azure AD Passthrough Authentication.
---
You should assign the Azure AD Premium 1 license to your AD tenant. This is the minimum license required to install Azure AD Connect. Azure AD Connect allows you to synchronize password hashes from a domain controller to Azure AD.

You should install Azure AD Connect on an on-premises server. This tool allows you to synchronize password hashes from a domain controller to Azure AD. You must install this tool to enable password writeback.

You should not deploy Azure AD Passthrough Authentication. This allows users to sign in to Azure AD with the same password as they use with an on-premises directory. This is not required to enable password writeback.
---

How-to: Configure password writeback;https://docs.microsoft.com/en-us/azure/active-directory/authentication/tutorial-enable-sspr-writeback

Getting started with Azure AD Connect using express settings;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-install-express

What is hybrid identity?;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/whatis-hybrid-identity
###
C
You plan to use Azure Active Directory (AD) Connect as a solution that spans from your on-premises directory to cloud servers.

The on-premises Active Directory contains approximately 200,000 objects. The solution must meet the following requirements:

* Use Azure Multi-Factor Authentication (MFA)
* Ensure that no password hashes are stored in the cloud
* Support smartcard authentication

You need to choose the installation type, version, and hybrid identity option. Choose all that apply:
---
You should use password hash synchronization from on-premises to Azure AD for single sign-on.
You should choose the custom installation type. *
You should install the full version of SQL Server for the AD Connect database. *
---
You should not use password hash synchronization from on-premises to Azure AD for single sign-on. This would be appropriate for Office 365 hybrid scenarios. You also should not recommend pass-through authentication. Although it ensures that no passwords will be stored in the cloud, it does not support smartcard authentication. You should, instead, use federation from on-premises to Azure AD for single sign-on because it allows cloud multi-factor authentication, ensures that no password hashes are stored in the cloud, and supports smartcard authentication.

You should choose the custom installation type because you need to enable cloud multi-factor authentication solutions and you have more than 100,000 objects in the on-premises AD. In-place upgrade performs the upgrade from DirSync or Azure AD Sync. Express installation should be used only when you have less than 100,000 objects in the on-premises AD. You also must have an enterprise administrator account that you can use for the installation.

You should install the full version of SQL Server for the Azure AD Connect database because you have more than 100,000 objects in the on-premises AD. For a smaller number of objects, you can use the default database installation, which is LocalDb. You cannot install SQL Server Express for the Azure AD Connect database because you have more than 100,000 objects in the on-premises AD. The SQL Server Express version has a data size limitation and can use only 1 GB RAM.
---

Prerequisites for Azure AD Connect;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-install-prerequisites

Select which installation type to use for Azure AD Connect;https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-install-select-installation
###
Your company plans to use a custom image based on an existing Azure Windows virtual machine (VM) to provision new VMs in multiple regions.

You need to prepare the VM so it can be used to create a custom image.

Which three commands should you run first in sequence?
---
1. New-AzImageConfig 2. New-AzImage 3. New-AzVm
1. Sysprep 2. Set-AzVm 3. Stop-AzVm
1. Sysprep 2. Stop-AzVm 3. Set-AzVm *
1. New-AzVm 2. Stop-AzVm 3. Set-Az-Vm
---
You need to start by running the following commands in order:

1. Sysprep
2. Stop-AzVm
3. Set-VzVm

A custom image is similar to an Azure marketplace image. The primary difference is that you create the image yourself from an existing VM. The result is a reusable image that can be used to create as many VMs as you want.

You start by running the Sysprep command to remove personal information and generalize the image. You then use the Stop-AzVm cmdlet to deallocate the VM. Finally, you need to identify the VM as generalized to Azure using the Set-AzVm command.

Once you have prepared the image, you run Get-AzVM to retrieve the image and load it into a variable, New-AzImageConfig to create the image configuration by specifying the image location, and finally New-AzImage to create the image, specifying the image name and location.

At this point, you can use the New-AzVm to create new VMs from the image.
---
Tutorial: Create a custom image of an Azure VM with Azure PowerShell;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-custom-images

Tutorial: Create and Manage Windows VMs with Azure PowerShell;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-vm

Create a VM from a managed image;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/create-vm-generalized-managed

Create a managed image of a generalized VM in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/capture-image-resource
###
C
A company is using a template to provision a new virtual machine (VM) in the RG03 resource group using PowerShell.

You need to ensure the following:

* The new VM is deployed.
* Resources already in the resource group are not affected.

How should you complete the PowerShell script? Select correct placeholder values.

PLACEHOLDER 1 -Mode PLACEHOLDER 2
-Name NewVMDeployment -ResourceGroupName RG03
-TemplateFile c:\MyTemplates\newvm.json
---
PLACEHOLDER 1: New-AzResourceGroup
PLACEHOLDER 1: New-AzResourceGroupDeployment *
PLACEHOLDER 1: Set-AzResourceGroup
PLACEHOLDER 2: Complete
PLACEHOLDER 2: Incremental *
---
You should complete the PowerShell script as follows:

New-AzResourceGroupDeployment -Mode Incremental
  -Name NewVMDeployment -ResourceGroupName RG03
  -TemplateFile c:\MyTemplates
ewvm.json

The New-AzResourceGroupDeployment cmdlet is used to add a deployment to an existing resource group. You need to specify the incremental mode to add the new VM without changing the existing resources. You can use incremental mode to apply changes to existing resources, but you need to include all of that resource's parameters in the template.

You should not run the New-AzResourceGroup cmdlet. This is used to create a new resource group, not deploy resources to an existing group.

You should not run the Set-AzResourceGroup cmdlet. The cmdlet lets you modify resource group properties by to adding, changing, or deleting Azure tags applied to the resource group. It does not let you manage resources in the resource group.

You should not choose the Complete mode. This would cause any resources not included in the template to be deleted.
---
Azure Resource Manager deployment modes;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/deployment-modes

Deploy resources with Resource Manager templates and Azure PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-powershell

New-AzResourceGroup;https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroup?view=azps-3.8.0

New-AzResourceGroupDeployment;https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroupdeployment?view=azps-3.8.0

Set-AzResourceGroup;https://docs.microsoft.com/en-us/powershell/module/az.resources/set-azresourcegroup?view=azps-3.8.0
###
C
Your company is researching ways to improve data security for Windows and Linux Infrastructure-as-a-Service (IaaS) virtual machines (VM)s. You need to determine if Azure Disk Encryption (ADE) can meet the company's requirements.  Choose all that apply:
---
ADE is supported for Basic, Standard, and Premium tier VMs.		
You must encrypt the OS volume before you can encrypt any data volumes on a Windows VM. *
You can use the an on-premises key management service to safeguard encryption keys.
---
ADE is not supported for Basic tier VMs. It is supported for Standard, and Premium tier VMs. ADE supports Windows Server 2008 and later and a subset of Azure Linux images. Custom Linux images are not supported.

You must encrypt the boot volume before you can encrypt any data volumes on a Windows VM. ADE does not let you encrypt a data volume unless you first encrypt the OS volume. This is different for Linux VMs, which let you encrypt data without first encrypting the OS volume.

You cannot use an on-premises key management service to safeguard encryption keys. You are required to use Azure Key Management service. Azure Key Management service is a prerequisite for implementing ADE.
---

Azure Disk Encryption for IaaS VMs;https://docs.microsoft.com/en-us/azure/security/fundamentals/azure-disk-encryption-vms-vmss

Azure Disk Encryption prerequisites;https://docs.microsoft.com/en-us/azure/security/fundamentals/azure-disk-encryption-vms-vmss

Azure Disk Encryption for IaaS VMs FAQ;https://docs.microsoft.com/en-us/azure/security/fundamentals/azure-disk-encryption-vms-vmss
###
C
Your company is deploying new virtual machines (VMs) and associated resources using Azure Resource Manager templates. The company wants to use PowerShell cmdlets to provision the resources from a template deployed to your local computer.

You need to complete the PowerShell script to accomplish this.

How should you complete the PowerShell script? Select correct placeholder values.

PLACEHOLDER 1 PLACEHOLDER 2 RG02 -Location "North Central US"
PLACEHOLDER 3 PLACEHOLDER 4 RG02
-TemplateFile c:\\MyTemplates\\newazure.json
---
PLACEHOLDER 1: New-AzResourceGroup *
PLACEHOLDER 1: New-AzResourceGroupDeployment
PLACEHOLDER 2: -Name *
PLACEHOLDER 2: -ResourceGroupName
PLACEHOLDER 3: New-AzResourceGroup
PLACEHOLDER 3: New-AzResourceGroupDeployment *
PLACEHOLDER 4: -Name
PLACEHOLDER 4: -ResourceGroupName *
---
You should complete the PowerShell script as follows:

New-AzResourceGroup -Name RG02 -Location "North Central US"
New-AzResourceGroupDeployment -ResourceGroupName RG02
-TemplateFile c:\\MyTemplates\\newazure.json

You need to first create the resource group and then deploy the resources from the template to the resource group.

You should use the New-AzResourceGroup cmdlet to create the resource group. You should use the -Name parameter to specify the resource group name and -Location to specify the regional location. The cmdlet does not support the -ResourceGroupName parameter.

After you create the resource group, you should use the New-AzResourceGroupDeployment cmdlet to deploy the resources. The -ResourceGroupName parameter is used to identify the resource group, and the -TemplateFile parameter is used to locate the template file to use. The -Name and -Location parameters are not supported by the cmdlet.
---

Deploy resources with Resource Manager templates and Azure PowerShell;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/deploy-powershell

Azure Resource Manager overview;https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/overview

New-AzResourceGroup;https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroup?view=azps-3.8.0

New-AzResourceGroupDeployment;https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroupdeployment?view=azps-3.8.0
###
You have two storage account keys: key1 and key2. Your apps and services use key1, and you maintain key2 as a backup key.

You are concerned that both keys may have been compromised. You want to use the Azure portal to regenerate them without interrupting access to the storage account.

Which four actions should you perform in sequence?
---
1. Regenerate key2 using the Azure portal. 2. Update connection strings in all relevant apps and services to use key2. 3. Verify that all apps and services are running correctly using the new key. 4. Regenerate key1 using the Azure portal. *
1. Update connection strings in all relevant apps and services to use key2. 2. Verify that all apps and services are running correctly using the new key. 3. Regenerate key1 using the Azure portal. 4. Regenerate key2 using the Azure portal.
1. Verify that all apps and services are running correctly using the new key. 2. Regenerate key1 using the Azure portal. 3. Regenerate key2 using the Azure portal. 4. Update connection strings in all relevant apps and services to use key2.
1. Regenerate key1 using the Azure portal. 2. Regenerate key2 using the Azure portal. 3. Update connection strings in all relevant apps and services to use key2. 4. Verify that all apps and services are running correctly using the new key
---
You need to perform the following steps in order:

1. Regenerate key2 using the Azure portal.
2. Update connection strings in all relevant apps and services to use key2.
3. Verify that all apps and services are running correctly using the new key.
4. Regenerate key1 using the Azure portal.

You first regenerate key2 because the apps and services are currently using key1 to gain access to stored data, and you do not want to interrupt their access. Next, you change the storage key to key2 in those apps and services and then verify that they can gain access to storage. This is important because the apps and services will not be able to use the previous primary key after it is regenerated.

Finally, you regenerate key1.
---
Manage storage account settings in the Azure portal;https://docs.microsoft.com/en-us/azure/storage/common/storage-account-keys-manage?tabs=azure-portal

Azure Storage security guide;https://docs.microsoft.com/en-us/azure/storage/blobs/security-recommendations
###
You need to give a user temporary read and write permissions to a blob by using an ad hoc shared access signature (SAS).

Which six actions should you perform in sequence? 
---
1. Open Azure Storage Explorer. 2. Connect to your Azure Storage account. 3. Create a blob container. 4. Upload the blob to the blob container. 5. Get an SAS for the blob and specify start/expiry time and permissions. 6. Use HTTPS to distribute the URL to the user. *
1. Connect to your Azure Storage account. 2. Create a blob container. 3. Upload the blob to the blob container. 4. Get an SAS for the blob and specify start/expiry time and permissions. 5. Use HTTPS to distribute the URL to the user. 6. Open Azure Storage Explorer.
1. Create a blob container. 2. Upload the blob to the blob container. 3. Get an SAS for the blob and specify start/expiry time and permissions. 4. Use HTTPS to distribute the URL to the user. 5. Open Azure Storage Explorer. 6. Connect to your Azure Storage account.
1. Upload the blob to the blob container. 2. Get an SAS for the blob and specify start/expiry time and permissions. 3. Use HTTPS to distribute the URL to the user. 4. Open Azure Storage Explorer. 5. Connect to your Azure Storage account. 6. Create a blob container.
---
You need to perform the following steps in order:

1. Open Azure Storage Explorer.
2. Connect to your Azure Storage account.
3. Create a blob container.
4. Upload the blob to the blob container.
5. Get an SAS for the blob and specify start/expiry time and permissions.
6. Use HTTPS to distribute the URL to the user.

You use Azure Storage Explorer to manage your storage account as well as upload and download blobs, files, and other resources. After you open Azure Storage Explorer, you connect to your storage account. Next, you create a blob container for the blob you will grant access to, and then you upload the blob. Blobs are always uploaded into a container so they can be more easily organized.

You generate a SAS for the blob simply by right-clicking, selecting Get Shared Access Signature, and then specifying start/expiry time and permissions. Finally, you use HTTPS to distribute the SAS to the user. Using HTTP can leave your resources vulnerable to attack.

You should not create a resource group. This is a necessary step when creating VMs in Azure, but it is not part of the procedure to create an SAS by using Azure Storage Explorer.

You should not create a stored access policy for the container. In this scenario, you are creating an ad hoc SAS, and the start time, expiry time, and permissions are specified in the SAS URI. With a stored access policy, the start time, expiry time, and permissions are defined in the policy. An SAS associated with the policy inherits those constraints.
---

Using shared access signatures (SAS);https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview

Quickstart: Use Azure Storage Explorer to create a blob in object storage;https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-storage-explorer

Create and Manage Windows VMs with Azure PowerShell;https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-storage-explorer
###
You have three application virtual machines (VMs) hosted in one region in Azure. You plan to prepare a strategy that will create backups for all data from the VMs. The backup will occur every day at 1 A.M. on each VM. You must ensure that the data is protected upon configuring the solution. In addition, the solution must minimize administrative effort.

Which three actions should you perform in sequence? 
---
1. Create a Recovery Services vault. 2. Define a backup policy to protect the VMs. 3. Perform the initial backup. *
1. Create a storage account for files. 2. Define a backup policy to protect the VMs. 3. Perform the initial backup.
1. Create a Recovery Services vault. 2. Define a separate backup policy on each VM. 3. Perform the initial backup.
1. Create a storage account for files. 2. Define a separate backup policy on each VM. 3. Perform the initial backup.
---
You need to perform the following steps in order:

1. Create a Recovery Services vault.
2. Define a backup policy to protect the VMs.
3. Perform the initial backup.

You first create a Recovery Services vault to contain the backup data and the backup policy. You then define the backup policy, which defines when and how often recovery points are taken, to protect the VMs.

You should not define a separate backup policy for each VM. To minimize administrative effort, you should create only one policy to apply to all VMs. You then perform an initial backup. This is a disaster recovery best practice to trigger the first backup so that your data is protected.

Unless you plan to perform backups manually, you should not create a storage account for files. Recovery Services manages the files internally.
---
Use Azure portal to back up multiple virtual machines;https://docs.microsoft.com/en-us/azure/backup/tutorial-backup-vm-at-scale
###
C
You plan to migrate the virtual machine (VM) running Windows Server 2012 from Amazon Web Services (AWS) to Azure.

You decide to perform the migration by using Azure Site Recovery (ASR).

You need to prepare the migration.

Which three steps should you perform first? Each correct answer presents part of the solution.
---
Set up an Azure network. *
Prepare a vault. *
Turn on replication.
Create a storage account. *
Set the recovery point to latest processed.
---
You should create an Azure storage account. Images of replicated machines are held in Azure Storage. Azure VMs are created from storage when you failover from on-premises to Azure.

You should prepare a vault to store all recovery points in Azure Recovery Services. This allows you to configure recovery points to meet the recovery time objective (RTO).

You should set up an Azure network. When Azure VMs are created after the migration (failover), they are joined to this Azure network.

You should not set the recovery point to last processed during preparation steps. The recovery point configuration is done during testing of the failover. The last-processed option means that the VM fails over to the latest recovery point that was processed by Site Recovery.

You should not turn on replication during the preparation steps. This can be done after the configuration is prepared and sources and targets are configured.
---
Migrate Amazon Web Services (AWS) VMs to Azure;https://docs.microsoft.com/en-us/azure/site-recovery/migrate-tutorial-aws-azure
###
Your office has an on-premises Hyper-V host computer. It contains a virtual machine (VM) named VM1 that is used as a file server.

You need to replicate VM1 to Azure.

What should you do?
---
Install the Site Recovery Provider on the Hyper-V host computer. *
Install the Recovery Services agent on VM1.
Install the Site Recovery Provider on VM1.
Install the Recovery Services agent on the Hyper-V host computer.
---
You should install the Site Recovery Provider on the Hyper-V host computer. Site Recovery Provider is used by Azure Site Recovery. You must install Site Recovery Provider on the Hyper-V host on which the VM is running to be able to replicate VM1 to Azure (actual configuration of the replication is performed in the Azure portal).

You should not install the Recovery Services agent on the Hyper-V host computer. Recovery Services agent is used by Azure Backup to back up files and folders to Azure. You cannot use it to replicate VMs to Azure.

You should not install the Recovery Services agent on VM1. Recovery Services agent is used for backing up files and folders to Azure. You cannot use it to replicate a VM to Azure.

You should not install the Site Recovery Provider on VM1. Site Recovery Provider is used for replicating VMs to Azure, but you must install it on the Hyper-V host computer, not the VM.
---

Hyper-V to Azure disaster recovery architecture;https://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-architecture

Set up disaster recovery of on-premises Hyper-V VMs to Azure;https://docs.microsoft.com/en-us/azure/site-recovery/hyper-v-azure-tutorial
###
You are the cloud administrator for an Azure subscription. Your on-premises network includes a Hyper-V virtual machine (VM) that hosts a SQL Server.

You need to configure Azure Site Recovery to migrate the VM to Azure.

Which five actions should you perform in sequence?
---
1. Create a Recovery Services vault. 2. Set the Protection goal to migrate from on-premises to Azure. 3. Create a Hyper-V. 4. Install the Site Recovery Provider on the Hyper-V host. 5. Register the Hyper-V host in the vault. *
1. Set the Protection goal to migrate from on-premises to Azure. 2. Install the Site Recovery Provider on the Hyper-V host. 3. Create a Hyper-V site. 4. Create a Recovery Services vault. 5. Install the Site Recovery Provider on the Azure VM.
1.Install the Site Recovery Provider on the Hyper-V host. 2. Create a Hyper-V site. 3. Create a Recovery Services vault. 4. Install the Site Recovery Provider on the Azure VM. 5. Create an Azure VM with the same operating system as the local VM.
1. Create a Hyper-V site. 2. Create a Recovery Services vault. 3. Install the Site Recovery Provider on the Azure VM. 4. Create an Azure VM with the same operating system as the local VM. 5. Register the Hyper-V host in the vault.
---
You should perform the following actions in order:

1. Create a Recovery Services vault.
2. Set the Protection goal to migrate from on-premises to Azure.
3. Create a Hyper-V.
4. Install the Site Recovery Provider on the Hyper-V host.
5. Register the Hyper-V host in the vault.

You should first create a Recovery Services vault. This is simply a storage instance that stores backups and VMs that are replicated to Azure by using Azure Site Recovery. You should next set the Protection goal to migrate from on-premises to Azure. You should then create a Hyper-V site, install the Site Recovery Provider on the Hyper-V host and finally you should register the Hyper-V host in the vault.

You should not create an Azure VM. When you set up Azure Site Recovery, VMS that you replicate to Azure will be created automatically. you should not create them manually.

You should not install Site Recovery Provider on an Azure VM. This component should be installed on a Hyper-V host, from which VMs will be replicated to Azure.
---
Migrate on-premises machines to Azure;https://docs.microsoft.com/en-us/azure/site-recovery/migrate-tutorial-on-premises-azure

Recovery Services vault overview;https://docs.microsoft.com/en-us/azure/backup/backup-azure-recovery-services-vault-overview
###
C
You plan to move an Azure virtual machine (VM) to another region by using Azure Site Recovery (ASR). You are not a subscription administrator.

You need permissions to do the following:

* Create a VM in an Azure resource group.
* Perform ASR operations.

Which roles provide the required permissions? Select two.
---
Task: Create a VM in an Azure resource group. Permission: Virtual Machine Contributor *
Task: Create a VM in an Azure resource group. Permission: Virtual Machine Administrator Login
Task: Perform ASR operations. Permission: Site Recovery Contributor *
Task: Perform ASR operations. Permission: Sire Recovery Operator
---
You should have the Virtual Machine Contributor role to create a VM in an Azure resource group. This role allows you to manage VMs. It does not allow access to the VM.

You should not use the Virtual Administrator Login role to create a VM in an Azure resource group. This role allows you to view virtual machines in the portal and log in as administrator.

You should not use the Virtual Machine User Login role to create a VM in an Azure resource group. This role allows you to view VMs in the portal and log in as a regular user.

You should have the Site Recovery Contributor role to perform ASR operations. This role has all permissions required to manage ASR operations in a Recovery Services vault. This role is intended for disaster recovery administrators who can enable and manage disaster recovery for applications or entire organizations.

You should not use the Site Recovery Operator role to perform ASR operations.  This role has permissions to execute and manage Failover and Failback operations. This role is intended for disaster recovery operators who can failover VMs or applications when instructed by application owners and IT administrators.

You should not use the Site Recovery Reader role to perform ASR operations. This role has permissions to view all Site Recovery management operations. It is intended for IT monitoring executives who can monitor the current state of protection and raise support tickets if required.
---

Move Azure VMs to another region;https://docs.microsoft.com/en-us/azure/site-recovery/azure-to-azure-tutorial-migrate

Manage Site Recovery access with role-based access control (RBAC);https://docs.microsoft.com/en-us/azure/site-recovery/site-recovery-role-based-linked-access-control

Built-in roles for Azure resources;https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
###
An Azure Logic app accesses data from an on-premises SQL Server database. The database administrator recently changed the password that is used to connect to the database.

You need to update your Logic app so that it can connect to the database with the new password.

Which Azure option should you modify?
---
Workflow settings
API connections *
Access keys
Properties
---
You should modify API connections. This option allows you to update the connection to an on-premises data gateway, which is a component that allows you to connect an Azure Logic app to an on-premises database.

You should not modify Workflow settings. This option allows you to configure access control to the Logic app, such as which IP addresses are allowed to access the app. It does not allow you to change connections to on-premises databases.

You should not modify the Properties setting. This option specifies the endpoint information that you can use to manage the Logic app from PowerShell or Azure CLI. It does not allow you to change connections to on-premises databases.

You should not modify the Access keys setting. This option allows you to generate access keys that you can use to access Logic apps from code. It does not allow you to change connections to on-premises databases.
---

Connect to on-premises data sources from Azure Logic Apps;https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-gateway-connection

What is Azure Logic Apps?;https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-overview
###
C
An Azure function responds to GET requests at the URL http://shipping.azurewebsites.net/api/HttpTriggerJS1.

You need to modify the setting so that the function responds to requests at http://shipping/azurewebsites.net/Rate

Choose all that apply:
---
Change the routePrefix value to a slash (/) in the host.json file. *	
Change the route template to /Rate. *
Change the Request parameter name to Rate.
---
You should change the routePrefix value to a slash (/) in the host.json file. By default, this value is /api. This means that all functions in this function app have a URL that begin with http://shipping.azurewebsites.net/api. By changing the routePrefix value to /, you allow all functions to have a URL that begin with http://shipping.azurewebsites.net.

You should change the route template to /Rate. This is the path for the actual function. This means that the function in this scenario will be reachable at http://shipping/azurewebsites.net/Rate.

You should not change the Request parameter name to Rate. This Request parameter name represents the parameter to the method that represents the function. By default, this parameter is named req.
---
Create a serverless API using Azure Functions;https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-serverless-api
###
C
You are the cloud administrator for your organization. The development department wants to use Azure Service Bus to send messages whenever an order is placed. Two client applications are responsible for receiving those messages after they are sent.

You need to create the minimum number of Azure resources required to meet the development department's needs.

How should you allocate resources? Choose three:
---
Question: How many namespaces should you create? Answer: 0
Question: How many namespaces should you create? Answer: 1 *
Question: How many namespaces should you create? Answer: 2
Question: How many topics should you create? Answer: 0
Question: How many topics should you create? Answer: 1 *
Question: How many topics should you create? Answer: 2
Question: How many queues should you create? Answer: 0 *
Question: How many queues should you create? Answer: 1
Question: How many queues should you create? Answer: 2
---
You should create one namespace. A Service Bus namespace serves as the container for queues and topics. At least one namespace is required to use Service Bus messaging.

You should create one topic. A Service Bus topic allows multiple subscribers to receive messages that are sent to it. In this scenario, the two client applications act as subscribers to the same topic.

You should not create any queues. Messages in a Service Bus queue can be accessed with only one application. Once the message is retrieved, it disappears.
---
Get started with Service Bus topics;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions

What is Azure Service Bus?;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview

Service Bus queues, topics, and subscriptions;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions
###
You plan to deploy an application that will be analyzing financial transactions.

You need to recommend a messaging service that will allow you to find duplicate transactions while processing the data.

Which messaging service should you create?
---
Event Hub
Service Bus *
Azure Queue
Event Grid
---
You should use Service Bus to find duplicate transactions in the incoming data. Service Bus is a brokered messaging system. It stores data in a queue until the subscriber is ready to receive the message.

You should not use Event Hub to find duplicate transactions in the incoming data. Azure Event Hub is a big data streaming platform that enables capturing, retaining, and replaying telemetry and event stream data. The data may come from a variety of sources.

You should not use Event Hub to find duplicate transactions in the incoming data. Event Grid is a fully managed event service that enables event-driven, reactive programming following a publish-subscribe model. Publishers post events without expectations about which events are being handled. Subscribers can choose which events they want to handle.

You should not use Azure Queue to find duplicate transactions in the incoming data. Azure Queue storage is a service for storing large numbers of messages that can be accessed from anywhere in the world via authenticated calls using HTTP or HTTPS.
---

Choose between Azure messaging services - Event Grid, Event Hubs, and Service Bus;https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services

Duplicate detection;https://docs.microsoft.com/en-us/azure/service-bus-messaging/duplicate-detection
###
C
You have an Azure service bus named ServiceBus1 in a resource group named RG1.

You create a queue named queue1 in ServiceBus1.
 
You find that a client application is reading and removing messages from queue1, but is failing to process them.

You need to prevent messages from being removed from queue1. Queue1 should still be able to receive messages.

What should you do? Select correct placeholder values.

$q = Get-AzureRmServiceBusQueue -ResourceGroup RG1 `
-NamespaceName ServiceBus1 -QueueName queue1

$q.Status = PLACEHOLDER 1

PLACEHOLDER 2 -ResourceGroup RG1 `
-NamespaceName ServiceBus1 -QueueName queue1 -QueueObj $q
---
PLACEHOLDER 1: "SendDisabled" *
PLACEHOLDER 1: "Disabled"
PLACEHOLDER 1: "Active"
PLACEHOLDER 1: "ReceiveDisabled"
PLACEHOLDER 2: Set-AzureRmServiceBusQueue *
PLACEHOLDER 2: Set-AzureRmServiceBusSubscription
PLACEHOLDER 2: Set-AzureRmServiceBusTopic
PLACEHOLDER 2: Stop-AzureRmServiceBusMigration
---
You should use the following code:

$q = Get-AzureRmServiceBusQueue -ResourceGroup RG1 `
-NamespaceName ServiceBus1 -QueueName queue1

$q.Status = "SendDisabled"

Set-AzureRmServiceBusQueue -ResourceGroup RG1 `
-NamespaceName ServiceBus1 -QueueName queue1 -QueueObj $q

You should set the state of the queue to SendDisabled. The SendDisabled state means that the messages cannot be removed from the queue, while it can still receive the messages.

You should not set the state of the queue to Active. This means that the queue is active and all operations, including adding and removing messages, are permitted.

You should not set the state of the queue to Disabled. This means that the queue is suspended and none of the operations on the queue are permitted.

You should not set the state of the queue to ReceiveDisabled. This means that the queue is partially suspended. You can still remove the messages from the queue, but the queue is not allowed to receive new messages.

You should use the Set-AzureRmServiceBusQueue cmdlet to set a new status for the existing queue. First, you must set the status to the proper value and then you can modify the queue.

You should not use the Set-AzureRmServiceBusSubscription cmdlet to set a new status for the existing queue. This cmdlet is used to update the description of a Service Bus subscription in the specified namespace.

You should not use the Set-AzureRmServiceBusTopic cmdlet to set a new status for the existing queue. This cmdlet is used to update the description of a Service Bus topic in the specified namespace.

You should not use the Stop-AzureRmServiceBusMigration cmdlet to set a new status for the existing queue. This cmdlet is used to terminate the migration between standard to premium namespace.
---

Suspend and reactivate messaging entities (disable);https://docs.microsoft.com/en-us/azure/service-bus-messaging/entity-suspend

Service Bus queues, topics, and subscriptions;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions
###
You are running SQL Server on a virtual machine (VM) in Azure.

You need to create an outbound load balancing rule.

Which command should you use?
---
az network private-endpoint
az network nic
az network local-gateway
az network lb *
---
You should use the az network lb command to create an outbound rule. You can specify various parameters, which as protocol, ports, or a list of frontend IP configuration names.

You should not use the az network nic command to create an outbound rule. This command is used to create, update, or delete a network interface. A network interface allows an Azure VM to communicate with the Internet, Azure, and on-premises resources.

You should not use the az network local-gateway command to create an outbound rule. This command is used to create, update, or delete a local VPN gateway. The local network gateway typically refers to your on-premises location.

You should not use the az network private-endpoint command to create an outbound rule. This command is used to manage interface endpoints.
---
Load Balancer outbound rules;https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-outbound-rules-overview

Configure load balancing and outbound rules in Standard Load Balancer using Azure CLI;https://docs.microsoft.com/en-us/azure/load-balancer/configure-load-balancer-outbound-cli

az network lb;https://docs.microsoft.com/en-us/cli/azure/network/lb?view=azure-cli-latest

az network nic;https://docs.microsoft.com/en-us/cli/azure/network/nic?view=azure-cli-latest

az network local-gateway;https://docs.microsoft.com/en-us/cli/azure/network/local-gateway?view=azure-cli-latest

az network private-endpoint;https://docs.microsoft.com/en-us/cli/azure/network/private-endpoint?view=azure-cli-latest
###
C
The DevOps team deploys five virtual machines (VMs) to Azure that host a web application in Internet Information Services (IIS). The team wants you to create a load balancer that routes traffic to the VMs that are available.

The development team creates a web page named HealthCheck.aspx that, when responding with a 200 request, indicates that the VM is available for servicing web requests. If a VM fails to respond after four consecutive checks, the VM should be considered unavailable.

You need to use PowerShell to create a Load Balancer configuration that checks the health of the VMs.

How should you complete the cmdlet?

PLACEHOLDER 1
-Name "checkVmHealth"
-PLACEHOLDER 2 healthcheck.aspx
-Protocol http
-Port 80
-IntervalInSeconds 15
-PLACEHOLDER 3 4
---
PLACEHOLDER 1: New-AzureRmLoadBalancerProbeConfig *
PLACEHOLDER 1: New-AzureRmLoadBalancerFrontendIpConfig
PLACEHOLDER 2: RequestPath *
PLACEHOLDER 2: WhatIf
PLACEHOLDER 3: ProbeCount *
PLACEHOLDER 3: Confirm 
---
You should use the following PowerShell cmdlet:

New-AzureRmLoadBalancerProbeConfig
-Name "checkVmHealth"
-RequestPath healthcheck.aspx
-Protocol http
-Port 80
-IntervalInSeconds 15
-ProbeCount 4

The New-AzureRmLoadBalancerProbeConfig cmdlet creates a health probe. A health probe is a configuration that specifies how Azure Load Balancer determines whether or not a VM is available. The -RequestPath parameter specifies the path to an HTTP resource that determines availability, which is HealthCheck.aspx in this scenario. The -ProbeCount parameter specifies the number of consecutive failures that must occur before the VM is considered unavailable, which is four in this scenario.

You should not use the New-AzureRmLoadBalancerFrontendIpConfig cmdlet. This cmdlet creates a front-end IP configuration, which simply specifies the public IP address of the Load Balancer. It does not perform a health check.

You should not specify the WhatIf parameter. This parameter is part of the New-AzureRmLoadBalancer cmdlet. It simply displays what would happen if the cmdlet is run successfully.

You should not specify the Confirm parameter. This parameter is part of the New-AzureRmLoadBalancer cmdlet. It simply prompts for confirmation before creating a Load Balancer.
---
###
You are starting a new job as an Azure cloud administrator. The previous administrator leaves you a note with the following PowerShell cmdlets:

$publicIP = New-AzureRmPublicIpAddress
  -ResourceGroupName "resourceGroup11"
  -Location "EastUS"
  -AllocationMethod "Static"
  -Name "myPublicIP"

New-AzureRmLoadBalancerFrontendIpConfig
  -Name "nat"
  -PublicIpAddress $publicIP

You need to determine what these cmdlets do.

What should you conclude?
---
They create a firewall configuration that uses round robin to send inbound traffic to an Azure Load Balancer.
They create a load balancer configuration that uses Network Address Translation (NAT) to send inbound traffic to a set of virtual machines (VMs). *
They create a firewall configuration that uses round robin to send outbound traffic to an Azure Load Balancer.
They create a load balancer configuration that uses Network Address Translation (NAT) to send outbound traffic to a set of Service Bus endpoints.
---
The cmdlets create a load balancer configuration that uses NAT to send inbound traffic to a set of virtual machines (VMs). The New-AzureRmPublicIpAddress cmdlet creates a public IP address. The New-AzureRmLoadBalancerFrontendIpConfig cmdlet creates a Load Balancer configuration that specifies the front-end public IP address.

You should not conclude that the cmdlets create an outbound traffic configuration. New-AzureRmLoadBalancerFrontendIpConfig creates an inbound configuration.

You should not conclude that the cmdlets send inbound traffic to a Load Balancer. New-AzureRmLoadBalancerFrontendIpConfig creates an inbound configuration from a Load Balancer to a backend pool.
---
###
C
You create an Azure Application Gateway that represents the front-end for a pool of two Azure backend virtual machines (VMs). One VM hosts images for a web application, while the other VM hosts videos. You create a path map and a backend listener.

You need to associate the path map with the backend listener.

How should you create the PowerShell cmdlet? Select correct placeholder values.

 $gateway = Get-AzureRmApplicationGateway 
 -ResourceGroupName myResourceGroupAG
 -Name myAppGateway
 
 $backendlistener = Get-AzureRmApplicationGatewayHttplistener
 -ApplicationGateway $gateway
 -Name backenclastener
 
 $config = Get-AzureRmApplicationGatewayUrlPathMapConfig
  -PLACEHOLDER 1
  -Name urlpathmap
  
  PLACEHOLDER 2
  -ApplicationGateway $gateway
  -Name rule2
  -RuleType PathBasedRouting
  PLACEHOLDER 3
  -UrlPathMap $config
---
PLACEHOLDER 1: ApplicationGateway $gateway *
PLACEHOLDER 1: HttpListener $backendListener
PLACEHOLDER 2: Add-AzureRmApplicationGatewayRequestRoutingRule *
PLACEHOLDER 2: New-AzureRmApplicationGatewayPathRuleConfig
PLACEHOLDER 3: Set-AzureRmApplicationGateway *
PLACEHOLDER 3: Get-AzureRmApplicationGatewayUrlPathMapConfig
---
You should use the following cmdlet to get a reference to the path map:

$config = Get-AzureRmApplicationGatewayUrlPathMapConfig
  -ApplicationGateway $gateway
  -Name urlpathmap

This cmdlet stores the path map into a variable named $config.

You should use the following cmdlet to associate the path map with the backend listener of the application gateway:

Add-AzureRmApplicationGatewayRequestRoutingRule
  -ApplicationGateway $gateway
  -Name rule2
  -RuleType PathBasedRouting
  -HttpListener $backendlistener
  -UrlPathMap $config

The RuleType parameter specifies that the rule should use path-based routing. The HttpListener parameter specifies a reference to the backend HTTP listener. The UrlPathMap parameter specifies a reference to the path map that you stored in the $config variable.

You should use Set-AzureRmApplicationGateway to update the Application Gateway with the changes.

You should not use the following cmdlet to get a reference to the path map:

$config = Get-AzureRmApplicationGatewayUrlPathMapConfig
  -HttpListener $backendListener
  -Name urlpathmap

You must specify a reference to the Application Gateway, not a reference to the backend listener.

You should not use New-AzureRmApplicationGateway. This cmdlet creates a new Application Gateway. In this scenario, the Application Gateway already exists.
---

Route web traffic based on the URL using Azure PowerShell;https://docs.microsoft.com/en-us/azure/application-gateway/tutorial-url-route-powershell
###
C
You need to configure an application gateway for your company websites.

Two web applications must be hosted on the same application gateway instance. Each website has the following requirements:

* Must be directed to its own backend pool.
* Must have its own domain.
* Must be hosted on its own virtual machine (VM).

Choose all that apply:
---
You must create a virtual network for each application.		
The application gateway must have two request routing rules. *
Each web application must have its own HTTP listener. *
---
You do not need to create a virtual network for each application. You should create only one virtual network for the applications. The virtual network acts as a container for all objects that you need to create.

You should create two request routing rules. Because each application has its own VM, traffic must be redirected to each of them.

You should include an HTTP listener for each web application that specifies a host name, protocol, frontend IP configuration, and frontend port. The HTTP listeners
---
Application Gateway Documentation;https://docs.microsoft.com/en-us/azure/application-gateway/
###
You are an Azure architect at an oil and gas company. The company's field engineers must often work at remote locations.
 
You must design a solution that allows the engineers to connect securely to a virtual network without using a VPN device.
 
Which type of connectivity should you recommend?
---
Multisite
VNet-to-VNet
Site-to-Site
Point-to-Site *
---
You should recommend Point-to-Site connectivity to ensure a secure connection from a client machine to a virtual network without using an external device.

You should not recommend VNet-to-VNet connectivity because a client would need a VPN device to connect to a virtual network.

You should not recommend a Site-to-Site connection. This type of connection requires a VPN device that is located onsite. The device must have a public IP address that does not use NAT.

You should not recommend a multisite connection. Multiple connections must use a route-based VPN.
---

About Point-to-Site VPN;https://docs.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about

What is VPN Gateway?;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways#a-namep2sapoint-to-site-vpn-over-sstp
###
Your company has an Azure virtual network (VNet) and an on-premises network. Your Internet Service Provider offers Multiprotocol Label Switching (MPLS). You create an ExpressRoute circuit.

You need to determine the next step you should perform to connect the Azure VNet to your on-premises network.

What should you do next?
---
Create a link between the circuit and the VNet.
Create a VNet gateway. *
Create a peering.
Create a static public IP address in Azure.
---
You should next create a VNet gateway. A VNet gateway allows you to send traffic between an Azure VNet and the on-premises VNet.

You should not create a link between the circuit and the VNet next. You must first create a VNet gateway. After the VNet gateway is created, you should create the link.

You should not create a peering. When you use an ISP that offers MPLS, the ISP configures peering for you.

You should not create a static public IP address in Azure. The purpose of ExpressRoute is to offer secure private networking. Therefore, a static public IP address is not required.

---

Create and modify an ExpressRoute circuit;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-circuit-portal-resource-manager

Create and modify peering for an ExpressRoute circuit;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-routing-portal-resource-manager

About virtual network gateways for ExpressRoute;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-about-virtual-network-gateways
###
Your company has an Azure virtual network (VNet) and an on-premises network. Your Internet Service Provider (ISP) only offers Layer 2 connectivity services.

You need to connect the Azure VNet to your on-premises network by using a private connection.

Which four actions should you perform in sequence?
---
1. Create an ExpressRoute circuit. 2. Create a peering. 3. Create an ExpressRoute VNet gateway. 4. Create a link between the circuit and the VNet. *
1. Create a link between the circuit and the VNet. 2. Create an Application Gateway. 3. Create a static public IP address in Azure. 4.Create a peering.
1. Create an Application Gateway. 2. Create a static public IP address in Azure. 3. Create a peering. 4. Create an ExpressRoute circuit.
1. Create a static public IP address in Azure. 2. Create a peering. 3. Create an ExpressRoute circuit. 4. Create an ExpressRoute VNet gateway.
---
You should perform the following actions in order:

1. Create an ExpressRoute circuit.
2. Create a peering.
3. Create an ExpressRoute VNet gateway.
4. Create a link between the circuit and the VNet.

You should first create an ExpressRoute circuit. This represents a connection between Azure and your ISP.

You should next create a peering. This is the required next step when your ISP only offers Layer 2 connectivity services. You should next create an ExpressRoute VNet gateway, and finally create a link between the circuit and the VNet.

You should not create a static public IP address in Azure. The purpose of ExpressRoute is to offer secure private networking. Therefore, a static public IP address is not required.

You should not create an Application Gateway. An Application Gateway allows you to create a firewall for a pool of backend servers.
---

Create and modify an ExpressRoute circuit;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-circuit-portal-resource-manager

Create and modify peering for an ExpressRoute circuit;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-routing-portal-resource-manager

About virtual network gateways for ExpressRoute;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-about-virtual-network-gateways

What is Azure Application Gateway?;https://docs.microsoft.com/en-us/azure/application-gateway/overview

Connect a virtual network to an ExpressRoute circuit using the portal;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-linkvnet-portal-resource-manager
###
C
You are an Azure Solution Architect at a large energy company. You are configuring a point-to-site VPN.

You create an Azure VpnGw2 gateway and need to configure it to support specific cryptographic algorithms for a mixed environment consisting of Windows and Mac devices.
Choose all that apply:
---
You can use the Azure portal to enable IKEv2. *
Your IPSec/IKE policy must include all IPSec and IKE algorithms. *
You can apply both a custom and a default policy to a connection to add specific algorithms.		
MacOSX can connect only via Secure Socket Tunneling Protocol (SSTP).		
You can use internal private key infrastructure (PKI) (self-signed) root certificates. *
---
You can enable RADIUS or IKEv2 on already deployed gateways by using either PowerShell or the Azure portal. The gateway SKU VpnGw2 supports both RADIUS and IKEv2.

Your IPSec/IKE policy must specify all algorithms and parameters for both IKE (Main Mode) and IPSec (Quick Mode). Partial policy specifications are not supported.

You can define a custom policy to use a key strength other than that used in the default policy.

You cannot apply both a custom and a default policy to a connection. To use algorithms that are not included in the default policy, you must define and apply a custom policy that includes all IKE and IPSec algorithms in addition to specific algorithms to be added. When you apply a custom policy to a connection, it replaces the default policy.

When you configure both SSTP and IKEv2 in a mixed environment consisting of Windows and Mac devices, the Windows VPN attempts an IKEv2 tunnel first and falls back to SSTP if the IKEv2 connection is not successful. MacOSX connects only via IKEv2.

Only self-signed root certificates can be used. You can upload 20 root certificates for point-to-site connectivity.

You can use your enterprise PKI solution (your internal PKI), Azure PowerShell, MakeCert, or OpenSS to create certificates.
---


VPN Gateway FAQ;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-vpn-faq

Connect an on-premises network to a Microsoft Azure virtual network;https://docs.microsoft.com/en-us/office365/enterprise/connect-an-on-premises-network-to-a-microsoft-azure-virtual-network

About cryptographic requirements and Azure VPN gateways;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-compliance-crypto
###
Your company has only one location, but it will soon open a second facility.

You need to create a site-to-site VPN to establish a secure connection with the new facility.

Which five actions should you perform in sequence? 
---
1. Create the virtual network. 2. Create the gateway subnet. 3. Create the virtual network gateway. 4. Configure the on-premises VPN device. 5. Connect the virtual network gateway and on-premises VPN device. *
1. Create the virtual network gateway. 2. Create the gateway subnet. 3. Connect the virtual network gateway and on-premises VPN device. 4. Configure the on-premises VPN device. 5. Create the virtual network. 
1. Create the gateway subnet. 2. Connect the virtual network gateway and on-premises VPN device. 3. Configure the on-premises VPN device. 4. Create the virtual network.  5. Generate the certificates.
1. Connect the virtual network gateway and on-premises VPN device. 2. Configure the on-premises VPN device. 3. Create the virtual network. 4. Generate the certificates. 5. Specify the tunnel type: SSTP or IKEv2.
---
You should perform the following Actions in order:

1. Create the virtual network.
2. Create the gateway subnet.
3. Create the virtual network gateway.
4. Configure the on-premises VPN device.
5. Connect the virtual network gateway and on-premises VPN device.

You should create a virtual network and make sure there is an IP address range specifically for this virtual network.

You should then create a gateway subnet, which is part of the IP address range to be used by your virtual network.

Next, you should create a virtual network gateway, which establishes a public IP address.

Next, you should configure a VPN device for your on-premises network.

Finally, you should create the connection between your virtual network gateway and your VPN device.

You should not generate certificates when creating a site-to-site VPN. This is necessary only when creating a point-to-site VPN connection.

You should not specify the tunnel type when creating a site-to-site VPN. This is necessary only when creating a point-to-site VPN connection. Site-to-site VPN connections use the IPsec and IKE protocols instead of SSTP and IKEv2.
---

Create a Site-to-Site connection in the Azure portal;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-portal

Configure a Point-to-Site connection to a VNet using native Azure certificate authentication: Azure portal;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-point-to-site-resource-manager-portal
###
Your company has an Azure virtual network (VNet) and an on-premises network. You want to connect the Azure VNet to the on-premises network by using a private connection through your company's Internet Service Provider (ISP). All the servers and virtual machines (VMs) on both networks are used as application servers.

You need to create the most appropriate gateway in Azure.

Which type of gateway should you create?
---
Policy-based VPN gateway
Application gateway
Route-based VPN gateway
ExpressRoute gateway *
---
You should create an ExpressRoute gateway. This allows you to create a private connection between Azure and your on-premises network through your ISP.

You should not use a route-based VPN gateway. This is a dynamic routing gateway that connects directly to your company over the public Internet.

You should not use a policy-based VPN gateway. This is a static routing gateway that connects directly to your company over the public Internet.

You should not create an Application gateway. This type of gateway allows you to create a firewall for a pool of backend servers.
---
About virtual network gateways for ExpressRoute;https://docs.microsoft.com/en-us/azure/expressroute/expressroute-about-virtual-network-gateways

What is Azure Application Gateway?;https://docs.microsoft.com/en-us/azure/application-gateway/overview

What is VPN Gateway;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways
###
Your team is using role-based access control (RBAC) to manage access to Azure resources.

You need to programmatically retrieve the team's most recent 100 events.

Which cmdlet should you use?
---
Get-AzureRmDiagnosticSetting
Get-AzureRmLog *
Get-AzureRmLogProfile
Get-AzureRmMetric
---
You should use the Get-AzureRmLog cmdlet to retrieve the last 100 events. You should use the MaxRecord parameter with this command. You can also filter the events by start and end time and display detailed information.

You should not use the Get-AzureRmLogProfile cmdlet to retrieve the last 100 events. This cmdlet is used for retrieving information about the log profile.

You should not use the Get-AzureRmMetric cmdlet to retrieve the last 100 events. This cmdlet is used for retrieving information about all metrics values connected to a specified resource.

You should not use the Get-AzureRmDiagnosticSetting cmdlet to retrieve the last 100 events. This cmdlet gets the categories and time grains that are logged for a resource. (A time grain is the aggregation interval of a metric.)
---

Get-AzureRmLog;https://docs.microsoft.com/en-us/powershell/module/azurerm.insights/get-azurermlog?view=azurermps-6.13.0

Get-AzureRmLogProfile;https://docs.microsoft.com/en-us/powershell/module/azurerm.insights/get-azurermlogprofile?view=azurermps-6.13.0

Get-AzureRmMetric;https://docs.microsoft.com/en-us/powershell/module/azurerm.insights/get-azurermmetric?view=azurermps-6.13.0

Get-AzureRmDiagnosticSetting;https://docs.microsoft.com/en-us/powershell/module/azurerm.insights/get-azurermdiagnosticsetting?view=azurermps-6.13.0
###
C
You must create a custom role that allows these operations:

* Read data from a blob but not write data to the blob
* Display a list of containers

To define the role, you must assign permissions to these operations.

What permissions should you use? 

PLACEHOLDER 1: Read data from a blob
PLACEHOLDER 2: Exclude write data to a blob
PLACEHOLDER 3: Display a list of containers

Select correct placeholder values.
---
PLACEHOLDER 1: NotDataActions
PLACEHOLDER 1: DataActions *
PLACEHOLDER 1: Actions
PLACEHOLDER 1: NotActions
PLACEHOLDER 2: NotDataActions *
PLACEHOLDER 2: DataActions
PLACEHOLDER 2: Actions
PLACEHOLDER 2: NotActions
PLACEHOLDER 3: NotDataActions
PLACEHOLDER 3: DataActions
PLACEHOLDER 3: Actions *
PLACEHOLDER 3: NotActions
---
You should use the DataActions permission element to allow reading data from a blob because this is a data-related operation. The DataActions permission specifies the data operations that the role allows to be performed to the data within that object.

You should use the NotDataActions permission element to exclude writing data to the blob. The NotDataActions permission specifies the data operations that are excluded from the allowed DataActions. The access granted by the role is computed by subtracting the NotDataActions operations from the DataActions operations. The NotActions permission element is used for management operations. The NotActions permission specifies the management operations that are excluded from the allowed Actions. You should use the NotActions permission if the set of operations that you want to allow is more easily defined by excluding restricted operations. The access granted by a role is computed by subtracting the NotActions operations from the Actions operations.

You should use the Actions permission element to allow displaying a list of containers because this operation is related to management instead of data. The Actions permission specifies the management operations that the role allows to be performed. It is a collection of operation strings that identify securable operations of Azure resource providers.
---


Understand role definitions;https://docs.microsoft.com/en-us/azure/role-based-access-control/role-definitions

Built-in roles for Azure resources;https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
###
A member of the development team needs to have the ability to create Azure resources. However, the developer should not be allowed to grant resource access to other users.

You need to assign the appropriate role to the developer.

Which role should you assign?
---
Contributor *
Owner
Reader
User Access Administrator
---
You should assign the Contributor role to the developer. This role allows the developer to create all types of Azure resources, without the ability to grant resource access to other users.

You should not assign the Owner role to the developer. This role allows the developer to have full access to Azure, including granting resource access to other users.

You should not assign the Reader role to the developer. This role only allows the developer to view resources, not create them.

You should not assign the User Access Administrator role to the developer. This role allows the developer to grant resource access to other users.
---

What is role-based access control (RBAC) for Azure resources?;https://docs.microsoft.com/en-us/azure/role-based-access-control/overview
###
You have a custom role in a file named CustomRole.json.

You need to add this role to Azure by using Azure CLI.

Which command should you use?
---
az role definition create --role-definition CustomRole.json *
az role create --role-definition CustomRole.json
az role create CustomRole.json
az role definition create CustomRole.json
---
You should use the following command:

az role definition create --role-definition CustomRole.json

The az role definition create command creates the role. The --role-definition parameter specifies the name of the role definition JSON file.

You should not use the following command:

az role create --role-definition CustomRole.json

This command is missing the definition token.

You should not use the following command:

az role definition create CustomRole.json

This command is missing the --role-definition parameter.

You should not use the following command:

az role create CustomRole.json

This command is missing the definition token and --role-definition parameter.
---

Create custom roles using Azure CLI;https://docs.microsoft.com/en-us/azure/role-based-access-control/custom-roles-cli
###
You want to add a security group named Development to the Website Contributor built-in role.

You need to use Azure CLI.

Which command should you use?
---
az role definition create --resource-group "Development" --role "Website Contributor"
az role definition create --assignee "Development" --role "Website Contributor"
az role assignment create --assignee "Development" --role "Website Contributor" *
az role assignment create --resource-group "Development" --role "Website Contributor"
---
You should use the following command:

az role assignment create --assignee "Development" --role "Website Contributor"

This command adds the group development to the role Website Contributor. The --assignee parameter specifies the user name or group. The --role parameter specifies the role.

You should not use the following command:

az role definition create --resource-group "Development" --role "Website Contributor"

This command creates a role, not a role assignment.

You should not use the following command:

az role definition create --assignee "Development" --role "Website Contributor"

This command creates a role, not a role assignment.

You should not use the following command:

az role assignment create --resource-group "Development" --role "Website Contributor"

The --resource-group parameter specifies the name of a resource group, not a security group.
---
az role assignment;https://docs.microsoft.com/en-us/cli/azure/role/assignment?view=azure-cli-latest
###
C
Your company requires only single sign-on when employees access resources from the corporate network. Approximately 12 third-party contractors work remotely in various groups throughout the company and access the corporate network by using a virtual private network (VPN).

You want to require multi-factor authentication (MFA) policies for those users by defining a conditional access policy.

What three actions should you perform? Each correct answer presents part of the solution.
---
For Access Controls, click Block and select Require multi-factor authentication.
For Locations, include All trusted locations.
For Access Controls, click Grant and select Require multi-factor authentication. *
For Users and Groups, include each individual user. *
For Cloud Apps, include All Cloud Apps. *
---
For Users and Groups, you should include each individual user. Because this policy applies to only a limited number of users and because they work in different groups throughout the company, it is practical to designate individual users.

For Access Controls, you should click Grant and select Require multi-factor authentication. This allows access to users who successfully authenticate by using multi-factor authentication.

For Cloud Apps, you should include All Cloud Apps. Even though the policy does not designate specific apps, the cloud apps condition is required in conditional access policies.

For Access Controls, you should not click Block and select Require multi-factor authentication. The purpose of the policy is to grant access to users who successfully authenticate.

For Locations, you should not include All trusted locations. The conditional access policy applies to individual users and is not based on location.
---

What is conditional access in Azure Active Directory?;https://docs.microsoft.com/en-us/azure/active-directory/conditional-access/overview

How to: Require MFA for access from untrusted networks with conditional access;https://docs.microsoft.com/en-us/azure/active-directory/conditional-access/untrusted-networks
###
C
Your company uses Azure Multi-Factor Authentication (MFA) in the cloud to safeguard its assets.

A member of your development team at a remote location normally uses her cell phone to authenticate. She calls you from her land line to inform you that her mobile phone has been lost or stolen, and she cannot log in to her corporate account. She does not have an alternate verification method set up for her account.

Because the developer is working on a critical assignment, you must enable her to gain access to corporate resources as soon as possible.

Choose all that apply:
---
You can create a one-time bypass that temporarily grants a user access without two-step authentication.		
You can clear the user's MFA settings and have her specify her land line as a new contact method. *
You can tell the user to click Use a different verification option and use that method
---
You cannot create a one-time bypass that temporarily grants a user access without two-step authentication. This feature is available only with MFA Server, not MFA in the cloud.

You can clear the user's MFA settings and have her specify her land line as a new contact method. Both mobile and non-mobile phones can be used for MFA authentication. When authenticating via land line, the user completes sign-in by answering the call and pressing the pound key (#) on the phone keypad.

You cannot tell the user to click Use a different verification option and use that method. This option is available only if the user has previously set up an alternate verification method for her account.
---

Which version of Azure MFA is right for my organization?;https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks

Configure Azure Multi-Factor Authentication settings;https://docs.microsoft.com/en-us/azure/active-directory/authentication/howto-mfa-mfasettings
###
Your company has an Azure Active Directory (AD) tenant.

You need to ensure that users receive a verification text message on their phones before they can log in to Azure.

What should you do?
---
Enable Multifactor Authentication (MFA). *
Install Microsoft Authenticator on an Azure virtual machine (VM).
Install Active Directory Federation Services (AD FS).
Enable Self-Service Password Reset (SSPR).
---
You should enable MFA. This allows you to configure settings so that users receive text messages, phone calls, or app notifications for verification during sign-in attempts.

You should not install AD FS. AD FS is a single sign-on solution. It does not ensure that users receive text messages before logging on to Azure AD.

You should not enable SSPR. SSPR allows users to reset their passwords without IT involvement.
 
You should not install Microsoft Authenticator on an Azure VM. Microsoft Authenticator is an app that runs on mobile devices to provide MFA.

---

Configure Azure Multi-Factor Authentication settings;https://docs.microsoft.com/en-us/azure/active-directory/authentication/howto-mfa-mfasettings

What are authentication methods?;https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-authentication-methods

Tutorial: Complete an Azure AD self-service password reset pilot roll out;https://docs.microsoft.com/en-us/azure/active-directory/authentication/tutorial-enable-sspr
###
You are configuring Multi-Factor Authentication (MFA) for your company's Azure Active Directory (AD) tenant.

You need to allow users to receive a verification notification on their phones when they attempt to log in to Azure.

What should you do?
---
Create a Notification Hub.
Create a Service Bus Relay.
Have the users download the Azure app on their phones.
Have the users download the Microsoft Authenticator app on their phones. *
---
You should have the users download Microsoft Authenticator. This app allows users to receive notifications on their phones when they log in to Azure.

You should not have the users download Azure. This app allows IT administrators to manage resources from their mobile devices.

You should not create a Notification Hub. This resource allows you to send custom notifications from applications to mobile devices. Azure allows you to send login notifications by using MFA and Microsoft Authenticator.

You should not create a Service Bus Relay. This resource allows you to send messages from Azure to on-premises web services.
---

Set up my account for two-step verification;https://docs.microsoft.com/en-us/azure/active-directory/user-help/multi-factor-authentication-end-user-first-time

Azure mobile app;https://azure.microsoft.com/en-us/features/azure-portal/mobile-app/

What is Azure Relay?;https://docs.microsoft.com/en-us/azure/service-bus-relay/relay-what-is-it

What is Azure Notification Hubs?;https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-overview
###
You are configuring Multi-Factor Authentication (MFA) for your company's Azure Active Directory (AD) tenant.

You need to restrict the devices from which users can log in to Azure.

What should you do?
---
Create a virtual network (VNet) with all private IP addresses.
Create a virtual network (VNet) with all public IP addresses.
Configure Trusted IP settings. *
Install the Microsoft Authenticator app on each user's device.
---
You should configure Trusted IP settings. This feature allows you to control the IP addresses from which users can log in to Azure.

You should not install the Microsoft Authenticator app on each user's device. This allows users to receive notification of login attempts, but it does not control which devices are allowed to authenticate.

You should not create a VNet with all private IP addresses. Private addresses are used to communicate within the network, not over the Internet. This option is not relevant to restricting devices from Azure.
 
You should not create a VNet with all public IP addresses. Public addresses are used to communicate over the Internet. This option is not relevant to restricting devices from Azure.
---
Configure Azure Multi-Factor Authentication settings;https://docs.microsoft.com/en-us/azure/active-directory/authentication/howto-mfa-mfasettings
###
C
You create a custom role named App Service Contributor in your Azure subscription. 

All company developers are members of the Developers Azure Active Directory (AD) group, which is shown in the answer area.

You need to use Azure CLI to assign the App Service Contributor role to the developers.

Which command should you run? 

az PLACEHOLDER 1 assignment create \
--role "App Service Contributor" \
--PLACEHOLDER 2 "5da75e7e-8d19-4f68-8ff1-c9f14298cb5d"

Select correct placeholder values.
---
PLACEHOLDER 1: account
PLACEHOLDER 1: configure
PLACEHOLDER 1: group
PLACEHOLDER 1: role *
PLACEHOLDER 2: assignee
PLACEHOLDER 2: assignee-object-id *
PLACEHOLDER 2: group
PLACEHOLDER 2: Developers
---
You should use the following cmdlet:

az role assignment create \
--role "App Service Contributor" \
--assignee-object-id "5da75e7e-8d19-4f68-8ff1-c9f14298cb5d"

The az role assignment create command assigns a role to a user, service principal, or group. The --role parameter specifies the name of the role. The --assignee-object-id parameter specifies the object ID associated with a security group.

You should not use the --assignee parameter. You should use this parameter when you specify the email alias for a user.

You should not specify Developers as the value of the --assignee-object-id parameter. You must specify the object ID associated with the Developers security group.
---
az role assignment;https://docs.microsoft.com/en-us/cli/azure/role/assignment?view=azure-cli-latest
###
You are developing a web application that will serve as a search engine for the science department at your school. You plan to host the application in Azure. A console application acts as a web crawler. It crawls the web servers on the school's network every 12 hours to build a local table of keywords and links. This table is used by the web application. You plan to host the web application in an Azure App Service.

You need to ensure that the web crawler continues to work while the web application is in Azure without increasing costs.

What should you do?
---
Deploy it as a Docker Container instance.
Convert it to a web application.
Deploy it as a WebJob. *
Convert it to an Azure Function.
---
You should deploy it as a WebJob. A WebJob allows you to run a program in the context of a web application. The program can be written in Java, JavaScript, Python, PHP, Bash, Powershell, or any .NET language. You can configure the WebJob to use a schedule as a trigger, allowing the console application to run every 12 hours. WebJobs are free.

You should not convert it to an Azure Function. Although an Azure Function can use a schedule as a trigger, the cost increases compared to a WebJob.

You should not convert it to a web application. There is no easy way to cause a web application to run on a scheduled basis.

You should not deploy it as a Docker Container instance. Although you can run a Docker Container instance on a schedule, the cost increases compared to a WebJob.
---

Run Background tasks with WebJobs in Azure App Service;https://docs.microsoft.com/en-us/azure/app-service/webjobs-create

Deploy a Docker/Go web app in Web App for Containers;https://docs.microsoft.com/en-us/azure/app-service/containers/quickstart-docker

Azure Functions triggers and bindings concepts;https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings
###
You are developing a web application that will serve as a search engine for the science department at a school. You plan to host the application in Azure.

A console application acts as a web crawler. It browses the web servers on the school's network every 12 hours to build a local table of keywords and links. This table is used by the web application. You plan to host the web application in Azure App Service.

You need to make sure that the web crawler continues to work while the web application is in Azure without increasing costs.

What should you do?
---
Convert it to an Azure Function.
Convert it to a web application.
Deploy it as a WebJob. *
Deploy it as a Docker container instance.
---
You should deploy the web crawler as a WebJob. A WebJob allows you to run a program in the context of a web application. The program can be written in Java, JavaScript, Python, PHP, Bash, PowerShell, or any .NET language. You can configure the WebJob to use a schedule as a trigger, which allows the console application to run every 12 hours. Also, WebJobs involves no additional cost.

You should not convert it to an Azure Function. Although an Azure Function can use a schedule as a trigger, it increases the cost, unlike a WebJob.

You should not convert it to a web application. There is no easy way to cause a web application to run on a scheduled basis.

You should not deploy it as a Docker container instance. Although you can run a Docker container instance on a schedule, it increases the cost, unlike a WebJob.
---

Run Background tasks with WebJobs in Azure App Service;https://docs.microsoft.com/en-us/azure/app-service/webjobs-create

Deploy a Docker/Go web app in Web App for Containers;https://docs.microsoft.com/en-us/azure/app-service/containers/quickstart-docker

Azure Functions triggers and bindings concepts;https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings
###
You are using the WebJobs SDK to create an Azure WebJob. You write the following code (line numbers are included for reference only):

01 static void Main(string[] args)
02 {
03   var config = new JobHostConfiguration();
04   var host = new JobHost(config);
05 
06 }

You need to complete the code at line 05 so that the WebJob can be manually triggered.

Which code should you add at line 05?
---
host.Call(typeof(ServicePoint).GetMethod("SetTcpKeepAlive"));
host.RunAndBlock(); *
host.Start();
host.Call(typeof(ServicePointManager).GetMethod("FindServicePoint"));
---
You should call host.RunAndBlock. This method starts the WebJob and blocks the current thread so that it can keep running.

You should not call host.Start. This method starts the WebJob, but it does not block the current thread. This causes it to stop as soon as the Main method returns.

You should not call host.Call. This method allows you to have the WebJob call an external method.

---


Get started with the Azure WebJobs SDK for event-driven background processing;https://docs.microsoft.com/en-us/azure/app-service/webjobs-sdk-get-started

How to use the Azure WebJobs SDK for event-driven background processing;https://docs.microsoft.com/en-us/azure/app-service/webjobs-sdk-how-to
###
You create an Azure web app.

You need to view HTML documents that provide information about HTTP errors associated with the app.

Which logs should you view?
---
Web server logs
Failed trace requests
Detailed error logs *
Application diagnostics logs
---
You should view detailed error logs. This is an HTML document that provides information about HTTP errors.

You should not view application diagnostics logs. This is either a space-separated value or comma-separated value file that lists the date, process identifier, event level, and message.

You should not view web server logs. These logs are formatted using the W3C extended log format.

You should not view failed trace requests. These are XML files that show trace information.
---

Enable diagnostics logging for apps in Azure App Service;https://docs.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs
###
You are creating an ASP.NET Core web API that you want to host in Azure.

You need to have the API automatically generate JavaScript Object Notation (JSON) and user-friendly documentation.

Which technology should you use?
---
Docker
Swagger *
Gulp
AngularJS
---
You should use Swagger. This technology automatically generates JSON and user-friendly documentation for web APIs.

You should not use Gulp. Gulp is a JavaScript build toolkit that allows you to stream client-side code.

You should not use AngularJS. AngularJS is a JavaScript framework that allows you to bind application data to HTML elements.

You should not use Docker. Docker allows you to automate deployment of containers.
---
ASP.NET Core web API help pages with Swagger / OpenAPI;https://docs.microsoft.com/en-us/aspnet/core/tutorials/web-api-help-pages-using-swagger?view=aspnetcore-3.1

What is Docker?;https://docs.microsoft.com/en-us/dotnet/architecture/microservices/container-docker-introduction/docker-defined

AngularJS Introduction;https://www.w3schools.com/angular/angular_intro.asp

Use Gulp in ASP.NET Core;https://docs.microsoft.com/en-us/aspnet/core/client-side/using-grunt?view=aspnetcore-3.1
###
You use Visual Studio to create an ASP.NET web app named billing and enable Docker Compose support. You publish the app to Docker Hub. You then sign into Azure and create a Windows container app for the web app.

You need to view the progress of the app as it is starting up.

What should you do?
---

Visit http://billing.azurewebsites.net/api/logstream. *
Run the following Azure CLI command: az container show --name billing
Visit http://billing.scm.azurewebsites.net/api/deployments.
Run the following PowerShell cmdlet: Get-AzureRmContainerGroup -Name billing
---
You should visit http://billing.azurewebsites.net/api/logstream. This endpoint provides progress information for web app container instances.

You should not run the following Azure CLI command: az container show --name billing. This command shows the status of a container instance's provisioning state. It does not show its entire progress.

You should not run the following PowerShell cmdlet: Get-AzureRmContainerGroup -Name billing. This cmdlet shows the status of a container instance's provisioning state. It does not show its entire progress.

You should not visit http://billing.scm.azurewebsites.net/api/deployments. This endpoint returns a JSON view of a web app deployment.
---

Run a custom Windows container in Azure (Preview);https://docs.microsoft.com/en-us/azure/app-service/app-service-web-get-started-windows-container

Quickstart: Run a container application in Azure Container Instances with the Azure CLI;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-quickstart
###
You recently created a Web App for Containers instance named prodWeb that uses a Docker image. The name of the resource group is Production.

You need to change the instance to use the new image company1/testapp.

Which command should you use?
---
az webapp config container set -n prodWeb -g Production -c company1/testapp *
az webapp create -n prodWeb -g Production -c company1/testapp
az webapp deployment source config -n prodWeb -g Production c company1/testapp
az webapp deployment container config -n prodWeb -g Production c company1/testapp
---
You should use the following command:

az webapp config container set -n prodWeb -g Production -c company1/testapp

This command changes the image for an existing container.

You should not use the following command:

az webapp deployment container config -n prodWeb -g Production c company1/testapp

This command enables continuous deployment for a container instance.

You should not use the following command:

az webapp create -n prodWeb -g Production -c company1/testapp

This command creates a new container instance.

You should not use the following command:

az webapp deployment source config -n prodWeb -g Production c company1/testapp

This command configures a GIT deployment.
---
Manage Web App for Containers using Azure CLI;https://docs.microsoft.com/en-us/azure/app-service/containers/app-service-linux-cli
###
You pull a Dockerfile from an online repository. You build a container image from this file, and you want to add it to an Azure Container Registry named mytestreg. The name of image is my-test-app.

You need to deploy the image to the registry.

Which command should you run from your developer computer?
---
docker run -p mytestreg my-test-app
az container create --name mytestreg --image my-test-app
docker push mytestreg.azurecr.io/my-test-app *
az acr create --name mytestreg\my-test-app
---
You should use the following command:

docker push mytestreg.azurecr.io/my-test-app

This command pushes the image named my-test-app to an Azure login server named mytestreg.azurecr.io.

You should not use the following command:

docker run -p mytestreg my-test-app

This command runs a container locally. In this scenario, you need to deploy the container image.

You should not use the following command:

az acr create --name mytestreg\my-test-app

The az acr create command creates an Azure Container Registry.

You should not use the following command:

az container create --name mytestreg --image my-test-app

The az container create command creates a container instance in Azure.
---

Tutorial: Deploy an Azure container registry and push a container image;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-prepare-acr

Tutorial: Create a container image for deployment to Azure Container Instances;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-prepare-app

Tutorial: Deploy a container application to Azure Container Instances;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-deploy-app
###
C
You want to create a simple container image that runs on Windows with Internet Information Services (IIS). The base image is named windows/iis.

The image should install Internet Information Services (IIS) and all the Node modules present in the packages.json file. Once installed, the image should load the Index.js file. Both files are in a subdirectory named app on your development computer. The files should be deployed to C:\app on the container.

You need to create the Dockerfile.

How should you complete the commands? Select correct placeholder values.

PLACEHOLDER 1 windows/iis
PLACEHOLDER 2 mkdir -p C:\app
PLACEHOLDER 3 app C:/app
PLACEHOLDER 4 C:/app
PLACEHOLDER 5 npm install
PLACEHOLDER 6 node index.js
---
PLACEHOLDER 1 : CMD
PLACEHOLDER 1 : COPY
PLACEHOLDER 1 : FROM *
PLACEHOLDER 1 : RUN
PLACEHOLDER 1 : WORKDIR
PLACEHOLDER 2 : CMD
PLACEHOLDER 2 : COPY
PLACEHOLDER 2 : FROM
PLACEHOLDER 2 : RUN *
PLACEHOLDER 2 : WORKDIR
PLACEHOLDER 3 : CMD
PLACEHOLDER 3 : COPY *
PLACEHOLDER 3 : FROM
PLACEHOLDER 3 : RUN
PLACEHOLDER 3 : WORKDIR
PLACEHOLDER 4 : CMD
PLACEHOLDER 4 : COPY
PLACEHOLDER 4 : FROM
PLACEHOLDER 4 : RUN
PLACEHOLDER 4 : WORKDIR *
PLACEHOLDER 5 : CMD
PLACEHOLDER 5 : COPY
PLACEHOLDER 5 : FROM
PLACEHOLDER 5 : RUN *
PLACEHOLDER 5 : WORKDIR
PLACEHOLDER 6 : CMD *
PLACEHOLDER 6 : COPY
PLACEHOLDER 6 : FROM
PLACEHOLDER 6 : RUN
PLACEHOLDER 6 : WORKDIR
---
You should first run FROM windows/iis. The FROM command specifies the container image from which the newly created image is based. In this scenario, it is a Microsoft Windows image with IIS.

Next you should run RUN mkdir -p C:\app. This creates a directory named app on the C: drive on the container.

Next you should run COPY ./app/* C:\app. This copies the files from the app subdirectory on your development computer to the C:\app directory on the container.

Next you should run WORKDIR c:\app. This changes the working directory to C:\app on the container.

Next you should run RUN npm install. This installs the Node modules from the package.json file in the current directory, which is C:\app.

Next you should run CMD node Index.js. This runs the Node server and loads Index.js.
---

Tutorial: Create a container image for deployment to Azure Container Instances;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-prepare-app

Dockerfile on Windows;https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-docker/manage-windows-dockerfile
###
You obtain a Docker container image from a third-party source.

You need to push the image to an Azure Container Registry that you created.

What should you do first?
---
Create a load balancer.
Deploy an Azure virtual machine (VM).
Assign the Owner role to the Owner security group.
Tag the image with the login server. *
---
You should tag the image with the login server. This is required before you can push the image.

You should not deploy an Azure VM. A container image runs in a container. It does not require a VM.

You should not assign the Owner role to the appropriate security group. Owner role assignment is not required to deploy a Docker container image.

You should not create a load balancer. A load balancer distributes load to a pool of VMs. This is not required for a Docker container image.

---

Tutorial: Deploy an Azure container registry and push a container image;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-prepare-acr

What is Azure Load Balancer?;https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-overview

Built-in roles for Azure resources;https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles

What is Azure Container Instances?;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-overview
###
You recently moved a critical production workload to Azure Kubernetes Service (AKS). A second AKS cluster is used for other application workloads.

You want to collect performance metrics directly from the AKS cluster that is used for the critical workloads.

Which four actions should you perform in sequence?
---
1. From the Azure portal, enable monitoring for the cluster. 2. Create a Log Analytics workspace. 3. Add Azure Monitor for Containers to the workspace. 4. View charts on the Insights page of the AKS cluster. *
1. Create a Log Analytics workspace. 2. From the Azure portal, enable monitoring for the cluster. 3. Retrieve entries from the activity log. 4. Run a query on the cluster in Log Analytics.
1. From the Azure portal, enable monitoring for the cluster. 2. Retrieve entries from the activity log. 3. Run a query on the cluster in Log Analytics. 4. View charts on the Insights page of the AKS cluster.
1. Retrieve entries from the activity log. 2. Run a query on the cluster in Log Analytics. 3. View charts on the Insights page of the AKS cluster. 4. Add Azure Monitor for Containers to the workspace.
---
You should perform the following steps in order:

1. From the Azure portal, enable monitoring for the cluster.
2. Create a Log Analytics workspace.
3. Add Azure Monitor for Containers to the workspace.
4. View charts on the Insights page of the AKS cluster.

You must first enable monitoring for the target cluster. You must then create a new Log Analytics workspace or select and existing one. Next, you add Azure Monitor for Containers to the workspace. This allows the collection of performance data from the nodes in the cluster. Although you can use Azure Monitor to view performance data on all clusters, you can also view this data directly from the cluster.

After you have enabled monitoring for a cluster, you do not need to run queries to see detailed performance data.

Because you are gathering metrics instead of logs, you do not need to obtain data from the activity log.
---
How to onboard Azure Monitor for containers;https://docs.microsoft.com/en-us/azure/azure-monitor/insights/container-insights-onboard

Understand AKS cluster performance with Azure Monitor for containers;https://docs.microsoft.com/en-us/azure/azure-monitor/insights/container-insights-analyze
###
You use the following commands to create a container in Azure:

az group create --name sampleResourceGroup --location eastus
az container create --resource-group sampleResourceGroup --name sampleContainer --image microsoft/aci-helloworld --dns-name-label aci-demo --ports 80

You need to navigate to the application hosted in the container.

Which URL should you use?
---
eastus.aci-demo-azurecontainer.io
aci-demo.azurecontainer.eastus.io
eastus.azurecontainer.aci-demo.io
aci-demo.eastus.azurecontainer.io *
---
You should navigate to aci-demo.eastus.azurecontainer.io. The container application's URL format is [container-image].[resource-location].azurecontainer.io.
---

Quickstart: Run a container application in Azure Container Instances with the Azure CLI;https://docs.microsoft.com/en-us/azure/container-instances/container-instances-quickstart
###
C
You use the following Azure CLI command to create an Azure container instance:

az container create --resource-group testgroup --name testcontainer --image microsoft/aci-helloworld

You need to be able to browse to the container's URL.

Which two parameters must you set?
---
--environment-variables
--protocol
--dns-name-label *
--ports *
--os-type
---
You should set the --dns-name-label parameter. This parameter is necessary so that Azure can resolve the DNS name to the IP address that hosts the container instance.

You should set the --ports parameter. This parameter is necessary so that you can have Azure open the appropriate TCP port.

You do not need to set the --environment-variables parameter. This parameter allows you to set environment variables for container instances, which is unnecessary in this scenario.

You do not need to set the --os-type parameter. This parameter specifies the operating system for the container instance. The type of operating system is irrelevant in this scenario.

You do not need to set the --protocol parameter. This parameter specifies either TCP or UDP. When browsing from a web browser, the protocol is automatically TCP.
---
az container;https://docs.microsoft.com/en-us/cli/azure/container?view=azure-cli-latest
###
C
You create a web API that will be accessed by a web application and two different mobile applications. You want to secure the web API by using OAuth 2.0.

You need to determine which applications to register in Azure Active Directory (Azure AD).

Choose all that apply:
---
Web API	*
Mobile applications	*
Web application *
---
You should register all applications in Azure AD. Both client applications and web APIs are required to be registered to support OAuth 2.0 in an AD tenant.
---

Protect an API by using OAuth 2.0 with Azure Active Directory and API Management;https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-protect-backend-with-aad
###
You deploy an application to an Azure virtual machine (VM). You use Secure Shell (SSH) to connect to the VM.

You need to get an access token using the assigned VM's managed identity.

To which IP address should you issue a web request?
---
169.254.169.254 *
10.10.10.10.
192.168.0.1
127.0.0.1
---
You should issue a web request to 169.254.169.254. Specifically, the entire URL is http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com. This is the URL you should use on all VMs.

You should not issue a web request to any other IP address. Only 169.254.169.254 is available for issuing identity tokens on VMs.
---

Use a Windows VM system-assigned managed identity to access Resource Manager;https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/tutorial-windows-vm-access-arm
###
You have an Azure API Management gateway named mycompany. You are adding OAuth 2.0 authentication to secure the gateway's APIs.

The client ID for the application is 49aef0d1-502a-4f31-9cde-616fa2ccffb6. The tenant ID for your Azure Active Directory (AD) tenant is aa9463cb-b2f1-45be-adcd-ee892279b196.

You need to specify the URL endpoint so that developers can authenticate with your company's AD tenant.

Which URL should you specify?
---
https://login.microsoftonline.com/aa9463cb-b2f1-45be-adcd-ee892279b196/oauth2/authorize *
https://49aef0d1-502a-4f31-9cde-616fa2ccffb6.azure-api.net
https://mycompany.azurewebsites.net/aa9463cb-b2f1-45be-adcd-ee892279b196/oauth2/authorize
https://mycompany.azure-api.net/authenticate/49aef0d1-502a-4f31-9cde-616fa2ccffb6
---
You should use the following URL:

https://login.microsoftonline.com/aa9463cb-b2f1-45be-adcd-ee892279b196/oauth2/authorize

This URL represents the authorization endpoint that allows developers to authenticate with your company's AD tenant. It is in the format https://login.microsoft.com/{tenant id}/oauth2/authorize.

You should not use any other URL. The other URLs do not allow authentication against an AD tenant.;https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-oauth2
---
How to authorize developer accounts using OAuth 2.0 in Azure API Management;https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-oauth2
###
You create a Linux Azure virtual machine (VM) and enable the system-assigned identity. You want to use Managed Service Identity to allow the VM to access the Azure Resource Manager application programming interface (API).
Which three actions should you perform in sequence? 
---
1. Grant to the VM the Reader role for all resource groups. 2. Run the Invoke-WebRequest PowerShell cmdlet to retrieve an access token. 3. Call Azure Resource Manager using the access token. *
1. Call Azure Resource Manager using the access token. 2. Grant to the VM the Reader role for all resource groups. 3. Grant to your account the Virtual Machine Contributor role.
1. Grant to the VM the Reader role for all resource groups. 2. Grant to your account the Virtual Machine Contributor role. 3. Run the az identity create CLI command to specify the name of the identity.
1. Grant to your account the Virtual Machine Contributor role. 2. Run the az identity create CLI command to specify the name of the identity. 3. Run the Invoke-WebRequest PowerShell cmdlet to retrieve an access token.
---
You need to perform the following steps in order:

1. Grant to the VM the Reader role for all resource groups.
2. Run the Invoke-WebRequest PowerShell cmdlet to retrieve an access token.
3. Call Azure Resource Manager using the access token.

You should grant to the VM the Reader role for all resource groups. This ensures that the VM can access resources in all resource groups. You must grant the Reader role before taking action to retrieve an access token.

Next, you should run the Invoke-WebRequest cmdlet to retrieve an access token. You extract the access token from the response, and then, finally, you call Azure Resource Manager using the access token.

You should not run the az identity create CLI command to specify the name of the system identity. You should run this command when you want to set the name of a user identity, not a system identity.

You should not grant to your account the Virtual Machine Contributor role. This role is required to create a VM with the system-assigned identity enabled. However, because the VM is already created with the system assigned identity enabled, your account already has the required permissions.
---
Use a Windows VM system-assigned managed identity to access Resource Manager;https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/tutorial-windows-vm-access-arm

Configure managed identities for Azure resources on an Azure VM using Azure CLI;https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/qs-configure-cli-windows-vm
###
You create a web API that is hosted in Azure.

You need to protect the API by using OAuth 2.0 authentication with your company's Azure Active Directory (AD) tenant.

Which additional Azure resource should you create?
---
Key vault
Network Security Group (NSG)
Application Gateway
API Management instance *
---
You should create an API Management instance. This is required for allowing a client application to use OAuth 2.0 authentication with an Azure AD tenant.

You should not create a key vault. A key vault allows you to store secrets, keys, and certificates. It is not required for using OAuth 2.0.

You should not create an NSG. An NSG allows you to filter traffic to and from Azure resources. It is not required for using OAuth 2.0.

You should not create an Application Gateway. An Application Gateway allows you to create a load balancer to backend web applications. It is not required for using OAuth 2.0.
---

Protect an API by using OAuth 2.0 with Azure Active Directory and API Management;https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-protect-backend-with-aad

What is Azure Key Vault?;https://docs.microsoft.com/en-us/azure/key-vault/general/basic-concepts

Security groups;https://docs.microsoft.com/en-us/azure/virtual-network/security-overview

What is Azure Application Gateway?;https://docs.microsoft.com/en-us/azure/application-gateway/overview
###
C
An Azure key vault named exam-answer exists in your company's cloud subscription. You want to store a password in the key vault. The password is S3449PT!@90Q. The name of the entry should be ApplicationPassword. The password should not be stored as plain text.

You need to use PowerShell to store the password in the key vault.

How should you complete the cmdlets? Select correct placeholder values.

$value = PLACEHOLDER 1 'S3449PT!@90Q' -PLACEHOLDER 2 -Force
PLACEHOLDER 3 -VaultName 'exam-answer' -Name 'ApplicationPassword' -PLACEHOLDER 4 $value
---
PLACEHOLDER 1: ConvertTo-SecureString *
PLACEHOLDER 1: AsPlainText 
PLACEHOLDER 1: Set-AzureKeyVaultSecret
PLACEHOLDER 1: SecretValue 
PLACEHOLDER 1: Add-AzureKeyVaultKey
PLACEHOLDER 2: ConvertTo-SecureString
PLACEHOLDER 2: AsPlainText *
PLACEHOLDER 2: Set-AzureKeyVaultSecret
PLACEHOLDER 2: SecretValue 
PLACEHOLDER 2: Add-AzureKeyVaultKey
PLACEHOLDER 3: ConvertTo-SecureString
PLACEHOLDER 3: AsPlainText 
PLACEHOLDER 3: Set-AzureKeyVaultSecret *
PLACEHOLDER 3: SecretValue 
PLACEHOLDER 3: Add-AzureKeyVaultKey
PLACEHOLDER 4: ConvertTo-SecureString
PLACEHOLDER 4: AsPlainText 
PLACEHOLDER 4: Set-AzureKeyVaultSecret
PLACEHOLDER 4: SecretValue *
PLACEHOLDER 4: Add-AzureKeyVaultKey
---
You should use the following cmdlets:

$value = ConvertTo-SecureString 'S3449PT!@90Q' -AsPlainText -Force
Set-AzureKeyVaultSecret -VaultName 'exam-answer' -Name 'ApplicationPassword' -SecretValue $value

The ConvertTo-SecureString cmdlet converts a plain text value into a secure (encrypted) string. This meets the requirement of the password not being stored as plain text. The first parameter to this cmdlet is the string to convert. The -AsPlainText parameter indicates that the string to convert it plain text. The -Force parameter must be used when -AsPlainText is used to verify that you understand the implications of using -AsPlainText.

The Set-AzureKeyVaultSecret cmdlet stores the password in the key vault with the name specified as the -Name parameter. The -SecretValue parameter specifies the secret. In this scenario, the secret is the encrypted password.

You should not use Add-AzureKeyVaultKey. This cmdlet generates a software or hardware key and saves it in a key vault. In this scenario, you need to store a known secret, not generate a key.
---
What is Azure Key Vault?;https://docs.microsoft.com/en-us/azure/key-vault/general/basic-concepts

Quickstart: Set and retrieve a secret from Azure Key Vault using PowerShell;https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-powershell

Set-AzureKeyVaultSecret;https://docs.microsoft.com/en-us/powershell/module/azurerm.keyvault/set-azurekeyvaultsecret?view=azurermps-6.13.0

Add-AzureKeyVaultKey;https://docs.microsoft.com/en-us/powershell/module/azurerm.keyvault/add-azurekeyvaultkey?view=azurermps-6.13.0
###
C
The following secret identifier exists in an Azure key vault: https://exam-answer.vault.azure.net/secrets/billingApiKey/a23df1a2eb5cb4a3696348504f74704c8

You need to use Azure CLI to retrieve the value for the secret.

Which command should you use? Select correct placeholder values.

az keyvault secret show --name PLACEHOLDER 1 --vault-name PLACEHOLDER 2
---
PLACEHOLDER 1: a23df1a2eb5cb4a3696348504f74704c8
PLACEHOLDER 1: billingApiKey *
PLACEHOLDER 1: exam-answer
PLACEHOLDER 2: a23df1a2eb5cb4a3696348504f74704c8
PLACEHOLDER 2: billingApiKey
PLACEHOLDER 2: exam-answer *
---
You should use the following command:

az keyvault secret show --name billingApiKey --vault-name exam-answer

This command sets the --name parameter to billingApiKey, which represents the name of the secret. It also sets the --vault-name parameter to exam-answer, which represents the name of the key vault. The secret identifier URL is always in the format https://{key vault name}.vault.azure.net/secrets/{secret name}/{secret version}.
---
Quickstart: Set and retrieve a secret from Azure Key Vault by using a .NET web app;https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-net
###
You use the following command to store a connection string in Azure Key Vault:

az keyvault secret set --vault-name "exam-answer" --name "connectionString" --value " server=10.10.10.100;database=prodSql;user id=webapp;password=4$gg65"

Developers need to retrieve the connection string.

Which URL should they use?
---
https://exam-answer.vault.azure.net/value/connectionString
https://exam-answer.vault.azure.net/keys/connectionString
https://exam-answer.vault.azure.net/secrets/connectionString *
https://exam-answer.vault.azure.net/connectionStrings/prodSql
---
The developers should use the following URL:

https://exam-answer.vault.azure.net/secrets/connectionString

This URL uses the format https://{key vault}.vault.azure.net/secrets/{secret name} to retrieve a secret from the vault.
---
Quickstart: Set and retrieve a secret from Azure Key Vault by using a .NET web app;https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-net
###
C
Your company has an on-premises infrastructure and an Azure cloud infrastructure. Data in Azure resides in Azure blob storage.

You need to access this data so that it cannot be compromised while in transit.

Which two actions should you perform? Each correct answer presents part of the solution.
---
Create a Service Bus relay.
Access the REST endpoint using HTTPS/TLS. *
Create an Application Gateway instance.
Deploy a VPN Gateway. *
---
You should access the REST endpoint representing the blob storage container over HTTPS/TLS. This ensures that a middleman attack cannot occur.

You should also deploy a VPN Gateway. This allows you to send encrypted traffic between Azure and an on-premises network.

You should not create an Application Gateway instance. This allows you to create a load balancer to distribute traffic to a cluster of backend virtual machines (VMs).

You should not create a Service Bus relay. This resource allows external applications to call on-premises services through Azure.
---
Azure Data Security and Encryption Best Practices;https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption-best-practices

What is VPN Gateway?;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways

What is Azure Application Gateway?;https://docs.microsoft.com/en-us/azure/application-gateway/overview

What is Azure Relay?;https://docs.microsoft.com/en-us/azure/service-bus-relay/relay-what-is-it
###
C
You plan to create a Windows Server 2019 Azure virtual machine (VM) for processing sensitive data. Other applications and operating systems should not be able to access or view the sensitive data.

You need to decide which security feature to use and which type of Azure VM to create.

What should you use? Select correct placeholder values.

Feature to use: PLACEHOLDER 1
Azure virtual machine type to use PLACEHOLDER 2
---
PLACEHOLDER 1: Secure Enclave *
PLACEHOLDER 1: Windows Defender Application Guard (WDAG)
PLACEHOLDER 1: Windows Defender Application Control (WDAC)
PLACEHOLDER 2: DC-series *
PLACEHOLDER 2: E-series
PLACEHOLDER 2: F-series
PLACEHOLDER 2: G-series
PLACEHOLDER 2: Ls-series
---
You should use the secure enclave security feature. A secure enclave is a protected memory region that appears as a black box to the containing process and the other processes that are running on the machine. Enclaves are the perfect solution for processing sensitive data because you cannot view the data or code inside the enclave from the outside. Only the DC-series of Azure VMs supports secure enclave. The other Azure VM types do not support secure enclave.

You should not select Data Execution Prevention (DEP). DEP can be described as a set of hardware and software technologies that conduct additional memory checks to help to prevent malicious attacks.

You should not select Windows Defender Application Guard (WDAG). WDAG is a security tool built into Microsoft Edge that isolates browser sessions from the desktop in a VM to prevent any malicious activity from reaching the desktop.

You should not select Windows Defender Application Control (WDAC). WDAC can reduce security threats by limiting the applications that users are allowed to run and the code running in the System Core (kernel).
---

Virtual Machine series;https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/

Azure confidential computing;https://azure.microsoft.com/en-us/blog/azure-confidential-computing/
###
An Azure Cosmos DB database is used to track inventory for a company. Queries are most often based on date received, serial number, or both.

You need to horizontally partition data to optimize both read and write operations.

What should you do?
---
Use a partition key based on serial number.
Use a synthetic partition key based on the date and a random suffix.
Use a synthetic partition key based on the date and a precalculated suffix based on serial number. *
Use a partition key based on date.
---
You should use a synthetic partition key based on the date and a precalculated suffix based on serial number. A Cosmos DB partitions data into logical horizontal partitions based on partition keys. The best practice is to use a partition key that has a large number of unique values. This helps distribute data and the workload evenly across partitions.

Using a key based on the date and a precalculated suffix based on serial number meets the goal of spreading data across multiple logical partitions, which helps to optimize write performance. Using the values that are primarily used for queries helps to improve read performance.

You should not use a synthetic partition key based on the date and a random suffix. This would spread the data across multiple partitions but does not help with data reads because you do not know the value used when generating the key.

You should not use either just the date or just the serial number. Using just the date means that you would have more entries in each partition and would help with queries based on date only, not serial number. A partition key based on serial number would distribute the data but would not help optimize reads using a date in the query.
---

Partitioning in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/partitioning-overview

Partitioning and horizontal scaling in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/partition-data

Create a synthetic partition key;https://docs.microsoft.com/en-us/azure/cosmos-db/synthetic-partition-keys
###
C
Your company plans to use an Azure Cosmos SQL DB for data storage. The company plans to use partitioning to meet application performance goals.

You need to verify Cosmos DB partitioning features to ensure that it will meet the company's requirements.

Choose all that apply:
---
A single logical partition can contain no more than 10 GB of data. *
Microsoft guarantees a throughput of 1000 request units per second (RU/s) for a partitioned container.		
Partitioning is automatic and managed transparently by Azure Cosmos DB. *
Transactions using stored procedures or triggers can be performed against a single partition only. *
---
A single logical partition can contain no more than 10 GB of data. This is an enforced upper storage limit that cannot be overridden.

Microsoft guarantees a throughput of 400, not 1000, RU/s for a partitioned container. RUs are used as a way to express a normalized cost of database operations and can be used for throughput comparisons. RU calculations are based on CPU, I/O operations (IOPS), and memory. For example, the cost to read a 1 KB item is 1 RU.

Partitioning is automatic and managed transparently by Azure Cosmos DB. You do not get directly involved with either logical or physical partitioning. Logical partitioning is the horizontal partitioning of the data in a Cosmos DB container. Cosmos DB can scale horizontally by spreading logical partitions across multiple servers. Logical partitioning is based on your defined partition key. Physical partitioning determines where the data is physically stored and uses a hash of the partition key to distribute logical partitions over physical partitions.

Transactions using stored procedures or triggers can be performed against a single partition only. This can be a key factor when determining the value or values to use when defining a partition key. Only those items with the same partition key value are part of the same logical partition. Also, queries are more efficient when run across a single partition, but are supported over multiple partitions.
---

Partitioning in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/partitioning-overview

Partitioning and horizontal scaling in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/partition-data

Create a synthetic partition key;https://docs.microsoft.com/en-us/azure/cosmos-db/synthetic-partition-keys

Request Units in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/request-units
###
Your company creates an Azure Cosmos DB in Azure Portal. The database must be a graph database with the ability to model and traverse relationships between entities in the database.

You need to recommend the appropriate Cosmos DB API to use.

Which API should you use?
---
API for MongoDB
Casandra API
SQL API
Table API
Gremlin API *
---
You should choose the Gremlin API. This is the API used to build a graph database. In Azure portal, the API is identified as Gremlin (graph). When using this API, in addition to having an Azure subscription, you must install Visual Studio 2017 and enable Azure development.

The APIs supported by Azure Cosmos DB are:

* Azure Cosmos DB's API for MongoDB - Used when migrating from a MongoDB and supports the MongoDB wire protocol and connections by MongoDB client drivers
* Cassandra API - Used to create a data store for use with apps written for Apache Cassandra with compatibility with existing applications and support for the Cassandra Query Language (CQL)
* Gremlin API - Used when creating graph databases for modeling and traversing relationships between entities
* SQL API - Default Cosmos DB API that supports building a non-relational document database that supports SQL syntax queries
* Table API - Provides premium database support for applications written for Azure Table storage

None of these APIs, with the exception of the Gremlin API, can be used to build a graph database.

If you need to support multiple APIs, you must create a separate database with a unique account name for each.
---

Azure Cosmos DB Documentation;https://docs.microsoft.com/en-us/azure/cosmos-db/

Frequently asked questions about different APIs in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/faq

Introduction to Azure Cosmos DB: Gremlin API;https://docs.microsoft.com/en-us/azure/cosmos-db/graph-introduction

Azure Cosmos DB Gremlin graph support;https://docs.microsoft.com/en-us/azure/cosmos-db/gremlin-support

Introduction to Azure Cosmos DB database and the SQL API;https://www.mssqltips.com/sqlservertip/5331/introduction-to-azure-cosmos-db-database-and-the-sql-api/
###
You need to determine the results of a query against an Azure Cosmos DB that uses the SQL data model. You execute the following query:

SELECT *
    FROM Invoices i
    WHERE i.id =1

What should you expect the query to produce?
---
A table structured as rows and columns
JSON-formatted data *
XML-formatted data 
A syntax error
---
You should expect JSON-formatted data. SELECT queries against a Cosmos SQL database return data in a JSON format.

You should not expect XML-formatted data. None of the APIs supported by Cosmos DB default to returning data formatted as XML.

You should not expect a table structured as rows and columns. You would expect this result when using the Table API.

You should not expect a syntax error. The SQL API uses standard SQL syntax and the query does not include any syntax errors.
---

SQL query examples for Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/sql-query-getting-started

Azure Cosmos DB: Designing your data structure;https://social.technet.microsoft.com/wiki/contents/articles/39421.azure-cosmos-db-designing-your-data-structure.aspx

SQL language reference for Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/sql-query-getting-started

Tutorial: Query Azure Cosmos DB by using the Table API;https://docs.microsoft.com/en-us/azure/cosmos-db/tutorial-query-table

Introduction to Azure Cosmos DB database and the SQL API;https://www.mssqltips.com/sqlservertip/5331/introduction-to-azure-cosmos-db-database-and-the-sql-api/
###
A static resource database for a public multiplayer game site is hosted in a Cosmos DB that uses the SQL data model.

You need to guarantee the highest possible availability and lowest latency for data reads.

Which consistency level should you use?
---
Consistent prefix
Strong
Bounded staleness
Eventual *
Session
---
Eventual consistency is recommended for applications that require the highest availability and lowest latency. Eventual consistency does not guarantee the ordering of reads, but this is not an issue for a static database because it will not be receiving new data writes.

Supported consistency levels are:

* Strong - Reads always return the most recent committed version of an item.
* Bounded staleness - Reads might lag behind writes based on configured update versions (K) or time (t).
* Session - Scoped to a client session, and reads honor consistency guarantees including the consistent-prefix, monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees.
* Consistent prefix - Updates that are returned contain some prefix of all the updates, and reads never see out-of-order writes.
* Eventual - There is no ordering guarantee for reads, and replicas eventually converge.

Service level agreements (SLAs) for Azure Cosmos DB guarantee that 100 percent of read requests meet the consistency guarantee for the consistency level you choose.
---

Consistency levels in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels

Consistency levels and Azure Cosmos DB APIs;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels-across-apis

Choose the right consistency level;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels-choosing

Consistency, availability, and performance tradeoffs;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels-tradeoffs
###
You need to ensure client consistency with read-your-writes and write-follows-reads guarantees. The solution should maximize read throughput while minimizing latency for read and write operations.

Which Azure Cosmos DB consistency should you choose?
---
Bounded staleness
Strong
Consistent prefix
Eventual
Session *
---
You should choose Session consistency. Session consistency provides the consistency levels needed at a client or device session context.

Supported consistency levels are:

* Strong - Reads always return the most recent committed version of an item.
* Bounded staleness - Reads might lag behind writes based on configured update versions (K) or time (t).
* Session - Scoped to a client session, and reads honor consistency guarantees including the consistent-prefix, monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees.
* Consistent prefix - Updates that are returned contain some prefix of all the updates, and reads never see out-of-order writes.
* Eventual - There is no ordering guarantee for reads, and replicas eventually converge.

Session consistency also has lower request units per second (RU/s) costs than Strong or Bounded staleness consistency.
---

Consistency levels in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels

Consistency, availability, and performance tradeoffs;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels-tradeoffs

Choose the right consistency level;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels-choosing

High availability with Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/high-availability
###
A company's operations are supported by an Azure Cosmos DB. The database is configured for single master replication across the North Central US and South Central US regions. The database is configured with Staleness bound consistency as its default consistency.

You need to determine how this impacts your company's recovery objectives in case of a catastrophic regional failure.

What is the guaranteed recovery time objective (RTO) for this configuration?
---
0 minutes
< 1 day
< 15 minutes *
< 1 week
---
The RTO for this configuration is < 15 minutes. The same value applies for Session, Consistent Prefix, and Eventual consistency for single master replication over multiple regions. It also applies to Strong consistency with single or multi-master replication.

RTO and recovery point objective (RPO) are key considerations in calculating recovery. RTO refers to maximum time a resource may be down after a catastrophic failure. RPO is related to allowable data loss and is the age of backups that must be recovered to restore data.

Supported consistency levels are:

* Strong - Reads always return the most recent committed version of an item.
* Bounded staleness - Reads might lag behind writes based on configured update versions (K) or time (t).
* Session - Scoped to a client session, and reads honor consistency guarantees including the consistent-prefix, monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees.
* Consistent prefix - Updates that are returned contain some prefix of all the updates, and reads never see out-of-order writes.
* Eventual - There is no ordering guarantee for reads, and replicas eventually converge.

RPO for the scenario configuration is based on the K and t values.

Multi-master replication over multiple regions provides an RTO of 0 minutes for all consistencies except Strong.

When deployed in a single region, the RTO is < 1 week for any consistency.
---
Consistency levels in Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels

Consistency, availability, and performance tradeoffs;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels-tradeoffs

High availability with Azure Cosmos DB;https://docs.microsoft.com/en-us/azure/cosmos-db/high-availability

How to fit RPO and RTO into your backup and recovery plans;https://searchstorage.techtarget.com/feature/What-is-the-difference-between-RPO-and-RTO-from-a-backup-perspective
###
A company wants to set up an elastic pool to support 20 single SQL databases that are managed as part of the same SQL database server. Database Transaction Unit (DTU) utilization is as follows:

* Average DTU utilization per database - 18
* Peak DTU utilization per database - 47
* Number of concurrently peaking databases - 2

You need to determine the size of the elastic DTU (eDTU) pool you need to configure.

Which pool size should you configure?
---
360
400 *
300
100
---
You should configure a 400 eDTU pool. The following are used to calculate the pool size:

Number of databases X average DTU per database
Number of currently peaking databases X peak DTU

The larger value of the two is used to determine the eDTU pool.

20 (databases) X 18 (average DTU) = 360
2 (concurrent peaks) X 47 (peak DTU) = 94

The larger value, 360, is used. The nearest fit from the supported eDTU pool sizes is 400.

You should not choose 100 or 200. Neither is sufficient to support the pool requirements.

You should not choose 360. This is not supported as a pool size.
---
Resources limits for elastic pools using the DTU-based purchasing model;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-dtu-resource-limits-elastic-pools

Service tiers in the DTU-based purchase model;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-service-tiers-dtu

Elastic pools help you manage and scale multiple Azure SQL databases;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-pool

New-AzureRmSqlElasticPool;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/new-azurermsqlelasticpool?view=azurermps-6.13.0
###
You add a new Azure SQL Database single database to an existing database server.

You need to add the database to an existing elastic pool.

Which PowerShell cmdlet should you use?
---
Set-AzureRmSqlDatabase *
Set-AzureRmSqlElasticPool
Set-AzureRmSqlDatabaseSecondary
Set-AzureRmSqlInstance
---
You should use the Set-AzureRmSqlDatabase cmdlet. This cmdlet modifies the properties of an existing database, which includes adding the database to an elastic pool. You would run a command similar to the following:

Set-AzSqlDatabase -ResourceGroupName RGDB1 -ServerName DBServe1
 -DatabaseName DB12 -ElasticPoolName MyPool

You should not use the Set-AzureRmSqlElasticPool cmdlet. This cmdlet lets you modify elastic pool properties, such as pool size, minimum DTUs, and maximum DTUs. It does not let you add databases to or remove databases from the pool.

You should not use the Set-AzureRmSqlDatabaseSecondary cmdlet. This cmdlet is not used to manage elastic pools. It is used to switch a secondary database to be the primary database to initiate failover in a fault tolerant configuration.

You should not use the Set-AzureRmSqlInstance cmdlet. This cmdlet is used to set properties for an Azure SQL Database Managed Instance. A managed instance cannot be part of an elastic pool.
---

Elastic pools help you manage and scale multiple Azure SQL databases;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-pool

Use PowerShell to create elastic pools and move databases between elastic pools;https://docs.microsoft.com/en-us/azure/sql-database/scripts/sql-database-move-database-between-pools-powershell

Set-AzureRmSqlElasticPool;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/set-azurermsqlelasticpool?view=azurermps-6.13.0

Set-AzureRmSqlDatabase;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/set-azurermsqldatabase?view=azurermps-6.13.0

Set-AzureRmSqlDatabaseSecondary;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/set-azurermsqldatabasesecondary?view=azurermps-6.13.0

Set-AzureRmSqlInstance;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/set-azurermsqlinstance?view=azurermps-6.13.0
###
C
You are creating an elastic pool for databases on SQL Database server DBServ01. The pool must meet the following requirements:

* Ensure pool support for two databases peaking concurrently at 70 Database Transaction Units (DTUs).
* Ensure that a maximum of as near to 75 DTUs as possible can be consumed by a database.
* Minimize the DTUs that are guaranteed to all databases in the pool.
* Minimize pool costs and configuration.

You need to create the pool. Select correct placeholder values.

New-AzureRmSqlElasticPool -ResourceGroupName "RGDB01" -ServerName "DBServ01"
-ElasticPoolName "MyPool01" -Edition "Premium" -Dtu PLACEHOLDER 1
-DatabaseDtuMin PLACEHOLDER 2 -DatabaseDtuMax PLACEHOLDER 3
---
PLACEHOLDER 1: 75
PLACEHOLDER 1: 125
PLACEHOLDER 1: 250 *
PLACEHOLDER 1: 500
PLACEHOLDER 2: 0 *
PLACEHOLDER 2: 10
PLACEHOLDER 2: 25
PLACEHOLDER 2: 75 
PLACEHOLDER 3: 25
PLACEHOLDER 3: 75 *
PLACEHOLDER 3: 125
PLACEHOLDER 3: 250
---
You should complete the PowerShell cmdlet as follows:

New-AzureRmSqlElasticPool -ResourceGroupName "RGDB01" -ServerName "DBServ01"
-ElasticPoolName "MyPool01" -Edition "Premium" -Dtu 250
-DatabaseDtuMin 0 -DatabaseDtuMax 75

The pool needs to support 140 DTUs to support concurrent peaks. For a premium elastic pool, you need to choose a 250 DTU pool. That is the smallest supported pool size that meets your needs. A 75 DTU pool size is not supported, 125 DTUs is too small, and 500 DTUs is more than needed.

The -DatabaseDtuMin property sets the minimum DTUs that are guaranteed to each database in the pool. The smallest value that is supported is 0. Values of 25 and 75 are larger than needed. A value of 10 is not supported in a premium pool, but it is supported in a standard pool.

The -DatabaseDtuMax sets the maximum DTUs that a database in the pool can consume. A value of 75 is supported for a premium pool. A value of 25 would be too low, and 125 and 250 are more than necessary.
---

Elastic pools help you manage and scale multiple Azure SQL databases;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-pool

New-AzureRmSqlElasticPool;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/new-azurermsqlelasticpool?view=azurermps-6.13.0

Resources limits for elastic pools using the DTU-based purchasing model;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-dtu-resource-limits-elastic-pools
###
A company is migrating its on-premises datacenter to Azure. The solution should:

* Support migration without database changes
* Provide for company control over maintenance and update schedules
* Provide for control over the recovery model

You need to identify the appropriate database solution.

What solution should you choose?
---
Azure SQL Database Managed Instance
Azure SQL Database Elastic Pool
Azure SQL Database Single Database
SQL Server on Azure Virtual Machine (VM) *
---
You should choose SQL Server on Azure VM. This is a Infrastructure-as-a-Service (IaaS) model that gives you complete control over the database server. This solution uses standard SQL Server editions that run on standard hardware, so no database changes are necessary. Because this is an IaaS deployment, the company has complete control over database engine management, including maintenance, update schedules, and the recovery model that is used.

You should not choose single database, elastic pool, or managed instance solutions. These are all Platform-as-a-Service (PaaS) models where the company has limited control over the database engine. Activities such as maintenance and updates are under Microsoft's schedule and control.

A single database or an elastic pool made up of single instance databases does not meet the requirements. These kinds of deployments are best matched to the development and deployment of cloud-based applications.

A managed instance deployment can often support the migration from an on-premises deployment with little or no database changes, but it does not meet the company management requirements. It provides near 100% compatibility with an on-premises SQL server.
---
Choose the right SQL Server option in Azure;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-paas-vs-sql-server-iaas
###
C
A company is migrating its on-premises database to Azure. You use the following commands to create the database:

New-AzureRmSqlInstance
New-AzureRmSqlInstanceDatabase

You need to determine the features of this deployment. Choose all that apply:
---
This deployment is limited to using the vCore purchasing model only. *
The database can be moved to an existing elastic pool.		
Migration can be completed with little or no changes to the on-premises database. *
Microsoft is responsible for database engine updates and maintenance. *
---
The commands are used to create an Azure SQL Database Managed Instance, which is a platform-as-a-service (PaaS) SQL database deployment. It is near 100% compatible with on-premises SQL Server editions and lets you use your existing SQL Server licenses to reduce migration costs.

Managed instance is limited to using the vCore purchasing model only. This purchasing model lets you choose compute and storage resources independently for your deployment. This is different from Azure SQL Database Single Instance and Elastic Pool deployments, which support both vCore and DTU purchasing options.

The database cannot be moved into an existing elastic pool, nor can a new elastic pool be created for the database. Elastic pools are supported for Azure SQL Database Single Instance deployments.

Because of the compatibility between on-premises instances and managed instances, migration can be completed with little or no changes to the on-premises database. This model is often used for migration from an on-premises datacenter.

Because this is a PaaS deployment, Microsoft is responsible for the updates and maintenance of the database. These also occur on Microsoft's schedule.
---

Choose the right SQL Server option in Azure;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-paas-vs-sql-server-iaas

New-AzureRmSqlInstance;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/new-azurermsqlinstance?view=azurermps-6.13.0

New-AzureRmSqlInstanceDatabase;https://docs.microsoft.com/en-us/powershell/module/azurerm.sql/new-azurermsqlinstancedatabase?view=azurermps-6.13.0

Use SQL Database advanced data security with virtual networks and near 100% compatibility;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-managed-instance

vCore service tiers, Azure Hybrid Benefit, and migration;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-service-tiers-vcore?tabs=azure-portal
###
C
A company is moving the database that is used to support an important application to an Azure SQL Database Managed Instance.

You need to review the source code of the application to identify potential incompatibilities.

Choose all that apply:
---
Filestream data types are supported for temporary tables.		
Bulk insert operations are limited to importing from Azure Blob storage only. *
Standard query operations, including SELECT, UPDATE, and DELETE, are supported. *		
Commands that are executed using xp_cmdshell return JSON-formatted data instead of nvarchar(255) type data.
---
Filestream data types are not supported for any type of database tables, including temporary tables. The filestream data type is not supported on Managed Instance databases, and filegroups cannot contain filestream data. Attempts to restore from backups that include filestream data will fail.

Bulk insert operations are limited to importing from Azure Blob storage only. Operations that use the BULK INSERT or OPENROWSET commands must include a DATASOURCE parameter that identifies the data source. A managed instance cannot access file shares or Windows folders. The same is true for restore operations, which must also specify Azure Blob storage as their data source.

Standard query operations, including SELECT, UPDATE, and DELETE, are supported. There is near 100% compatibility between on-premises SQL Server editions and Azure SQL Database Managed Instance. This means that few changes are usually needed during migration.

Azure SQL Database Managed Instance databases do not support executing commands through xp_cmdshell. In addition, sp_execute_external_scripts and extended stored procedures are not supported.
---

Azure SQL Database Managed Instance T-SQL differences from SQL Server;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-managed-instance-transact-sql-information

Use SQL Database advanced data security with virtual networks and near 100% compatibility;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-managed-instance
###
You create and save a text file that contains Transact-SQL (T-SQL) statements to create a new table.

You need to execute the script.

Which PowerShell cmdlet should you use?
---
Write-SqlTableData
Invoke-Sqlcmd *
Invoke-ASCmd
Invoke-ProcessTable
---
You should use the Invoke-Sqlcmd cmdlet. You can use this cmdlet to execute a literal T-SQL command string or the contents of a text file that contains T-SQL commands.

You should not use the Write-SqlTableData cmdlet. This cmdlet is used to write data directly to an existing table, not to create a new table.

You should not use the Invoke-ASCmd cmdlet. This cmdlet is used to execute queries or statements against a Microsoft SQL Server Analysis Services instance. It is not used to execute standard database queries.

You should not use the Invoke-ProcessTable cmdlet. This cmdlet is used to process Analysis Services tables against a specified RefreshType.
---

Invoke-Sqlcmd;https://docs.microsoft.com/en-us/powershell/module/sqlserver/invoke-sqlcmd?view=sqlserver-ps

How to Create a Table in Azure SQL Database;https://dataplatformlabs.com/how-to-create-a-table-in-azure-sql-database/

Write-SqlTableData;https://docs.microsoft.com/en-us/powershell/module/sqlserver/write-sqltabledata?view=sqlserver-ps

Invoke-ASCmd;https://docs.microsoft.com/en-us/powershell/module/sqlserver/invoke-ascmd?view=sqlserver-ps

Invoke-ProcessTable;https://docs.microsoft.com/en-us/powershell/module/sqlserver/invoke-processtable?view=sqlserver-ps
###
C
You create a Windows Communication Foundation (WCF) service that allows internal applications to calculate shipping rates from three shipping providers. The service is hosted on the corporate network, and it is accessible over TCP port 4800. Your company's firewall only allows inbound traffic over TCP port 8080.

You need to expose this service to applications outside the corporate network.

What two actions should you perform? Each correct answer presents part of the solution.
---
Create an API Management gateway in Azure.
Create an Application Gateway in Azure.
Create a relay binding to the WCF service endpoint configuration. *
Create a Service Bus namespace in Azure. *
---
You should create a Service Bus namespace in Azure. A Service Bus namespace is a container for messaging. In this scenario, you need to allow external applications to send messages to Azure, which can then forward the messages to your corporate network over a TCP connection.

You should also add a TCP relay binding to the WCF service endpoint configuration. Because applications cannot connect directly to the service because of the firewall, a relay binding allows the service to open a bidirectional connection to Azure. When Azure receives messages, it forwards those messages over the connection.

You should not create an API Management gateway in Azure. An API Management gateway allows you to publish and secure web APIs. It does not provide relay binding to WCF services.

You should not create an Application Gateway in Azure. An Application Gateway is a load balancer that allows you to route traffic to different virtual machines (VMs) or backend servers based on IP address, port, and route pattern. However, you cannot force traffic to bypass a corporate firewall.
---
What is Azure Service Bus?;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview

What is Azure Relay?;https://docs.microsoft.com/en-us/azure/service-bus-relay/relay-what-is-it

How to use Azure Relay WCF relays with .NET;https://docs.microsoft.com/en-us/azure/service-bus-relay/service-bus-relay-tutorial

What is Azure Application Gateway?;https://docs.microsoft.com/en-us/azure/application-gateway/overview
###
You create an Azure web API that must send push notifications to Internet-of-Things (IoT) devices in the East United States region. You deploy both a production web API and a test web API. You want to be able to test push notifications through both web APIs. You plan to use Azure Notification Hubs to implement push notifications.

You need to determine the minimum number of namespaces and hubs to create.

How many namespaces and hubs should you create?
---
One namespace and one hub
Two namespaces and two hubs
Two namespaces and one hub
One namespace and two hubs *
---
You should create one namespace and two hubs. A hub represents a push resource for one app. In this scenario, one hub should represent the production web API, while the other hub should represent the test web API. A namespace represents a collection of hubs for a specific region.
---

Push notifications with Azure Notification Hubs: Frequently asked questions;https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-faq
###
Your office uses Azure for cloud computing. Your team consists of over 40 IT administrators across the country. Each IT administrator has permission to create virtual machines (VMs) in Azure.

You need to receive an e-mail whenever a VM is added or changed. The solution must be the most cost-effective and easy to implement.

What should you do?
---
Create a Logic app that uses the Event Grid connector. *
Create a Service Bus namespace and implement a relay binding.
Create a Function app that uses the HTTP trigger.
Create a Notification Hub namespace and implement a push notification.
---
You should create a Logic app that uses the Event Grid connector. A Logic app allows you to automate business processes. The Event Grid connector allows the Logic app to run whenever a resource event is added to Event Grid. In this scenario, a resource event is the VM addition or change. You can have the Logic app automatically e-mail you when this happens.

You should not create a Function app that uses the HTTP trigger. A Function app provides a serverless architecture that allows you to run code on a trigger. The HTTP trigger requires you to run the function by making an HTTP request. This would require you to manually monitor Azure for changes and then make the HTTP request. Event Grid is a better solution.

You should not create a Notification Hub namespace and implement a push notification. This allows a backend application to send notifications to Internet-connected devices. This is not suitable in this scenario.

You should not create a Service Bus namespace and implement a relay binding. This allows you to forward Internet messages to a backend network. This is not suitable for this scenario.

---
Tutorial: Monitor virtual machine changes with Azure Event Grid and Logic Apps;https://docs.microsoft.com/en-us/azure/event-grid/monitor-virtual-machine-changes-event-grid-logic-app

Azure Functions HTTP triggers and bindings;https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook
###
C
You manage an ecommerce site that is hosted in Azure App Service. You need to use Azure to allow multiple applications to be notified whenever a new order is placed.

How should you complete the code? Select correct placeholder values.

static async Task SendMessage(string connectionString, string entityPath, byte[] message)
{
    var client = new PLACEHOLDER 1(connectionString, entityPath);
    await client.SendAsync(PLACEHOLDER 2);
}
---
PLACEHOLDER 1: QueueClient
PLACEHOLDER 1: TopicClient *
PLACEHOLDER 2: message
PLACEHOLDER 2: new Message(message) *
---
You should use the following code:

static async Task SendMessage(string connectionString, string entityPath, byte[] message)
{
    var client = new TopicClient(connectionString, entityPath);
    await client.SendAsync(new Message(message));
}

This code creates an instance of TopicClient, which allows you to send messages to a Service Bus topic. A Service Bus topic allows client subscriptions, which allows multiple applications to receive messages that are sent to the topic. The SendAsync method accepts a Message instance, which represents the message being sent.

You should not create an instance of QueueClient. This class represents a Service Bus queue, which allows only one client to retrieve a message. Once the message is retrieved, it is removed from the queue.

You should not pass a byte as a parameter to the SendAsync method. You must wrap the byte in a Message instance.
---

Service Bus queues, topics, and subscriptions;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions

Get started with Service Bus topics;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions
###
C
You create a Service Bus namespace named company1 with a topic named orders. The topic contains subscriptions that are shown in the exhibit.

You need to determine what happens when the code in the exhibit is run.

Exhibit:
Service bus Topic Overview Page:

Name: orderEmailer, Status Active, Message count: 10
Name: orderProcessor, Status Active, Message count: 10

Code:

static void RetrieveMessage(string connectionString, string entityPath) 
{ 
 var client = new SubscriptionClient(connectionString, entityPath, "orderEmailer"); 
 client. RegisterMessageHandler(async (msg, token) => 
 { 
 await client.CompleteAsync(msg.SystemProperties.LockToken); 
 }, new MessageHandlerOptions((args) => 
 { 
 return Task.CompletedTask; 
 }));
} 

Choose all that apply:
---
SubscriptionClient.CompleteAsync is called 10 times. *
One message is removed from the orderProcessor subscription.		
Ten messages are removed from the orderEmailer subscription. *
---
SubscriptionClient.CompleteAsync is called 10 times. When you use SubscriptionClient to retrieve messages from a Service Bus topic, all the messages in the associated subscription are retrieved and removed. The RegisterMessageHandler method is responsible for assigning a delegate that gets called whenever a message is available for retrieving. In this scenario, that delegate is an anonymous method that calls SubscriptionClient.CompleteAsync. Because there are 10 messages, the anonymous method is called 10 times, resulting in SubscriptionClient.CompleteAsync being called 10 times.

No message is removed from the orderProcessor subscription. The SubscriptionClient constructor accepts as its third parameter the name of the subscription for which messages should be retrieved. Only messages in that subscription are retrieved and removed.

Ten messages are removed from the orderEmailer subscription. When you use SubscriptionClient to retrieve messages from a Service Bus topic, all the messages in the associated subscription are retrieved and removed. The RegisterMessageHandler method is responsible for assigning a delegate that gets called whenever a message is available for retrieving. Because there are 10 messages, 10 are retrieved and removed.
---

Service Bus queues, topics, and subscriptions;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-queues-topics-subscriptions

Get started with Service Bus topics;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dotnet-how-to-use-topics-subscriptions
###
C
You want to use Azure Notification Hubs to deliver notifications from a cloud web service to a mobile app. You want to be able to send notifications to both the production version of the app and the development version of the app.

You need to determine the number of hubs, namespaces, and access policies to create.

Select correct placeholder values.

How many namespaces should you create? Answer: Placeholder 1
How many hubs should you create? Answer: Placeholder 2
How many access policies should you create? Answer: Placeholder 3
---
Placeholder 1: 1 *
Placeholder 1: 2
Placeholder 1: 3
Placeholder 2: 1
Placeholder 2: 2 *
Placeholder 2: 3
Placeholder 3: 1 *
Placeholder 3: 2
Placeholder 3: 3
---
You should create one namespace. Namespaces should have one-to-one mappings with apps. In this scenario, there is only one app, so you should create one namespace.

You should create two hubs. Hubs should have one-to-one mappings with different versions or implementations of apps. In this scenario, there is a production version and a development version. Therefore, you should create two hubs.

You should create one access policy. An access policy represents the connection string and access key for an Azure resource. The cloud web service uses the access policy to access the resource, which in this case is Notification Hubs.
---

Push notifications with Azure Notification Hubs: Frequently asked questions;https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-faq
###
C
Your company is implementing a messaging solution for the cloud. The solution must allow client applications to submit URLs to videos that must be converted from Windows Media Video to MPEG-2.

A pool of cloud services is responsible for converting the videos. A video must be converted only once. The URLs must be sent to the cloud at endpoint https://exam-answer.servicebus.windows.net.

You need to use Azure CLI to create the appropriate Azure resource.

How should you complete the commands? Select correct placeholder values.

az PLACEHOLDER 1 PLACEHOLDER 2 create
--name exam-answer
--resource-group services --location eastus

az PLACEHOLDER 3 PLACEHOLDER 4 create
--name converter
--resource-group services
--namespace-name exam-answer
---
PLACEHOLDER 1: eventhub
PLACEHOLDER 1: namespace
PLACEHOLDER 1: queue
PLACEHOLDER 1: servicebus *
PLACEHOLDER 2: eventhub
PLACEHOLDER 2: namespace *
PLACEHOLDER 2: queue
PLACEHOLDER 2: servicebus
PLACEHOLDER 3: eventhub
PLACEHOLDER 3: namespace
PLACEHOLDER 3: queue
PLACEHOLDER 3: servicebus *
PLACEHOLDER 4: eventhub
PLACEHOLDER 4: namespace
PLACEHOLDER 4: queue *
PLACEHOLDER 4: servicebus
---
You should use the following commands:

az servicebus namespace create
--name exam-answer
--resource-group services --location eastus

az servicebus queue create
--name converter
--resource-group services
--namespace-name exam-answer

The first command creates a Service Bus namespace named exam-answer. Service Bus allows you to send messages that are processed by other applications. You should use exam-answer as the namespace because the container URL to which you want to send messages is https://exam-answer.servicebus.windows.net. A namespace is a collection of queues or topics.

The second command creates the actual queue. A queue is where messages are sent to be processed by a single application. The --namespace-name parameter specifies the namespace under which the queue should be created.

You should not use the az eventhub namespace create command. This command creates an Azure Event Hubs namespace. Although both Event Hubs and Service Bus use the same URL format, they are different in terms of usage. Service Bus is used for sending messages, while Event Hubs is used for sending events, such as telemetry data.

You should not use the az servicebus queue create as the first command. Queue can receive and send messages and can be created only after the service bus already exists.
---

Quickstart: Use the Azure CLI to create a Service Bus queue;https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-quickstart-cli

Quickstart: Create an event hub using Azure CLI;https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-quickstart-cli

Choose between Azure messaging services - Event Grid, Event Hubs, and Service Bus;https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services
###
You deploy an e-commerce site as an Azure web app. You notice that every weekend your site has four times as many users and response time slows.

You need to implement a horizontal scaling solution at the lowest cost and with the least amount of effort.

What should you do?
---
Enable the Azure Monitor auto-scale feature. *
Deploy an Azure Function and take advantage of automatic scaling.
Implement a custom scaling solution with a WebJob.
Migrate the web app to a virtual machine (VM) scale set.
---
You should enable the Azure Monitor auto-scale feature. This allows you to scale the web app onto additional VMs only on weekends.

You should not migrate the web app to a VM scale set. This is more expensive than Azure Monitor.

You should not implement a custom scaling solution with a WebJob. This requires more effort than Azure Monitor.

You should not deploy an Azure Function and take advantage of automatic scaling. This causes the function to scale, but not the web app itself.
---
Autoscaling;https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling
###
C
Your company has a mobile app that accesses an Azure SQL Database. You want to ensure that the app is developed to handle temporary Azure service interruptions due to connectivity issues. You must ensure that whenever a connection fails, a new attempt is made, up to four times. A variable named connectionString represents the connection string to Azure SQL Database.

You need to complete the code.

How should you complete the code? Select correct placeholder values.

var x = PLACEHOLDER 1;
using (var conn = new PLACEHOLDER 2(PLACEHOLDER 3))
{
    conn.Open();
}
---
PLACEHOLDER 1: 4
PLACEHOLDER 1: RetryPolicy<SqlDatabaseTransientErrorDetectionStrategy>(4) *
PLACEHOLDER 2: SqlConnection
PLACEHOLDER 2: ReliableSqlConnection *
PLACEHOLDER 3: connectionString
PLACEHOLDER 3: connectionString, 4 *
---
You should use the following code:

var x = new RetryPolicy<SqlDatabaseTransientErrorDetectionStrategy>(4);
using (var conn = new ReliableSqlConnection(connectionString, x))
{
    conn.Open();
}

The first statement creates a RetryPolicy instance that represents how retries should occur in the event of a connection failure. The class accepts a generic type parameter that specifies the transient detection strategy. In this scenario, it specifies the SqlDatabaseTransientErrorDetectionStrategy class. The constructor accepts a parameter that specifies the number of retries, which is four in this scenario.

The next statement creates an instance of ReliableSqlConnection, passing to it the connection string and the RetryPolicy instance. This represents a connection to the database with the retry policy.

You should not set the variable x to 4. You should set this to a RetryPolicy instance.

You should not create an instance of SqlConnection. This class does not support retry policies.
---
Transient Fault Handling (Building Real-World Cloud Apps with Azure);https://docs.microsoft.com/en-us/aspnet/aspnet/overview/developing-apps-with-windows-azure/building-real-world-cloud-apps-with-windows-azure/transient-fault-handling
###
You create an Azure Function that must connect to a Cosmos DB. Cosmos DB is replicated to the following regions that support read and write:

West Europe
North Europe
West US
West US 2
You need to use a singleton pattern to create a connection to the Cosmos DB.

How many connections to Cosmos DB should the Azure Function establish?
---
4
3
1 *
2
---
The singleton pattern is a widely used software design pattern that limits the instantiation of a class to one object. This is helpful when you need exactly one object to coordinate system actions. Because you want to use the singleton pattern to create connection to the Cosmos DB, you should establish a single connection.

You should not establish two, three or four connections to Cosmos DB, because in that case you would not follow the singleton pattern.
---

Singleton orchestrators in Durable Functions (Azure Functions);https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-singletons?tabs=csharp
###
C
You are the administrator of the ACME banking group. You are responsible for adding your company's custom domain to the Azure tenant. Which of the following configuration is supported when creating the records at the registrar level?
---
TXT Record + Alias + Destination + TTL *
TXT Record + Alias + TTL
MX Record + Alias + Destination +TTL
MX Record + Alias + Destination + TTL + Priority *
---
When using TXT records, you need to configure the following at your registrar: TXT record (type), Alias (@), Destination (Microsoft generated code) and TTL (Time To Live standard). When using MX records, you need to configure the following: MX record (type), Alias (@), Destination (Microsoft generated code), TTL (Time to Live standard), Priority (Microsoft auto-generated)
---
Add your custom domain name using the Azure Active Directory portal;https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/add-custom-domain
###
You are the administrator of the ACME banking group. You are responsible for the daily operations regarding Identities on Azure. You notice that there are several requests daily to reset their passwords. Upon delving deeper, you find that the on-premises passwords and Azure/Office365 passwords are not the same and that is causing the main confusion. You need to ensure that passwords are synced from your local Active Directory to Azure and that users can change passwords in Azure, which should update the local Active Directory password and vice versa. How would you accomplish this goal most cost-effectively?
---​
Implement AD Connect with a P2 license
Configure single sign-on
Implement AD connect with a P1 license *
Deploy Self Service Reset Portal
---
Implement AD Connect with AAD P1 license is correct, as this is the most cost-effective license, which enabled password writeback to on-premises AD. Single Sign-On will not suffice, as the identities are still considered separate. Deploying the Self Service Reset Portal (SSRP) will not suffice, as this will not merge the two identities. Implementing AD Connect with the AAD P2 license will suffice; however, this is not the most cost-effective manner as the same can be achieved by using the AAD P1 license.
---
Azure Active Directory pricing;https://azure.microsoft.com/en-in/pricing/details/active-directory/
###
You are the administrator of the ACME banking group. You are responsible for billing and administration for all subscriptions in Azure. ACME plans to deploy several Web App for the marketing department. You need to show the cost graph for the past 6 months on the subscription you want to suggest. Which option from the Azure portal should use?
---
Overview Tab
​
Payment Methods

​
Invoices *
​
Partner Information
---
Invoices are correct, as you can view the cost per month in histogram format for the past 6 months. Partner information will not suffice as this is used to add a Partner ID. The overview tab will show the overall details of all Azure services for that subscription and not a broken-down view. Payment methods will not suffice, as this is where you choose how to pay for your Azure consumption.


---
View and download your Microsoft Azure invoice;https://docs.microsoft.com/en-us/azure/cost-management-billing/understand/download-azure-invoice
###
You are the architect of the ACME shipping group. You are responsible for designing a storage solution for a new application that requires storing a list of client details in Azure. The solution needs to enable the administrators to filter the client details. Which Azure storage service should you use?


---

Blob Storage
​
File Storage
​
Table Storage *
​
Queue Storage
---
Table Storage is correct as its structured storage providing a key/attribute store for storing client details. Blob Storage will not suffice as it used to store blob objects, azure disks and not suitable for structured data. File Storage will not suffice as this is used for file shares. Queue Storage will not suffice as this is used for storing message queues


---
Table Storage;https://azure.microsoft.com/en-us/services/storage/tables/
###
C
You are the administrator of the ACME banking group. You are in the process of automating the virtual machine creation process via ARM templates in PowerShell. Which of the following is required to successfully create an ARM template, choose all that applies?


---
​
Template *
​
Parameters *
​
CLI
​
Variables
---
Templates and parameters are correct, as these files are needed when automating a VM installation. The template file is used to store the overall structure (think schema) as well as the variables used. Parameters file links all the information required in order to deploy to your VM to your VNet, resource group, location, disk types, etc. CLI is not directly required as we should make use of the Template and Parameters file and then use PowerShell for deployment. Variables are a section in the main template file.
---
Understand the structure and syntax of ARM templates;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-syntax
###
You are the administrator of the ACME banking group. You are in the process of automating the virtual machine creation process via ARM templates in JSON format. You need to configure the VM to automatically allow RDP traffic when this template is used. Under which variable can you edit the access rules?


---
"NetworkInterfaceName"
​
"NetworkSecurityGroupName"
​
"NetworkSecurityGroupRules" *
​
"PublicIPAddressType"
---
"NetworkSecurityGroupRules" is correct, this is the equivalent to configuring the NSG rules to allow RDP access via the Network Security Group linked to this VM. "NetworkInterfaceName" is incorrect as this is only the name of the network interface. "NetworkSecurityGroupName" Is incorrect as it only references the NSG name, not the rules within it. "PublicIPAddressType" is incorrect as this is the public IP type, which can be dynamic or static.


---
Understand the structure and syntax of ARM templates;https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-syntax
###
You are the administrator of the ACME banking group. You have an Azure virtual machine called "Tax_Returns" which has Azure backup enabled. The branch manager has accidentally deleted an important file and request that you recover that file. Which recovery method will be the fastest without disrupting the current VM and does not require additional resources to be created?


---
Restore VM
​
File Recovery *
​
Restore VHD
​
Azure Site Recovery Failover
---
File recovery is correct. We can restore download the script to create an SMB link to browse and recover the file. Restore VM will not suffice, as this will take some time and require additional resources to be created. Restore VHD will not suffice, as this will require some time and resources to mount. Azure Site Recovery will not suffice, as the deleted file will replicate to the other region, this is the distinct difference between backup and failover.


---
Instant File Recovery from Cloud using Azure Backup;https://azure.microsoft.com/en-us/blog/instant-file-recovery-from-cloud-backups-using-azure-backup/
###
You are the architect of the ACME shipping group. You are tasked to design a failover strategy for your Azure VMs, which reside in West Europe. You decide to use Azure Site Recovery and need to guide the administrator on the high-level configuration. In which region should the recovery services vault be created?


---
West Europe *
​
North Europe
---
West Europe is correct, as the recovery service vault has to be in the same region as the virtual machines.


---
Create a Recovery Services vault;https://docs.microsoft.com/bs-cyrl-ba/azure/backup/backup-create-rs-vault
###
You are the architect of the ACME shipping group. You are responsible for designing remote connectivity for selected users to all virtual machines on the Azure virtual network. The connection needs to be secure and minimal effort on the user’s side to connect each time. The solution should not include any on-premises hardware and be cost-effective. What connectivity solution should be used?


---
​
Virtual Network Peering
​
Point-to-Site VPN *
​
Site-to-site VPN
​
Express route
---
Point to Site VPN is correct as this connection does not require hardware on-premises and minimal effort to connect each time. Site-to-Site VPN will not suffice as this connection required on-premises hardware. Virtual Network Peering will not suffice as this is used to connect virtual networks in Azure with each other. Express route will not suffice as this is used to connect large sites to Azure directly with low latency and high bandwidth.


---
About Point-to-Site VPN;https://docs.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about
###
You are the architect of the ACME shipping group. You are responsible for designing remote connectivity between 4 of your branches and your main virtual network in Azure. The connection needs to be secure and no additional intervention to connect from the remote branches to Azure and vice versa. Additional remote branches are also to be connected to Azure in the future, however, there is no need for the remote branches to communicate with each other directly. What connectivity solution should be used?


---
​
Virtual Network Peering
​
Point-to-Site VPN
​
Site-to-site VPN *
​
Express route
---
Site-to-Site VPN is correct as this solution is correct and supports up to 30 simultaneous connections as well as no user intervention to access the other sites. Point-to-Site VPN will not suffice as this is used for remote users to connect individually to the Azure VNets. Virtual Network Peering will not suffice as this is used to connect virtual networks in Azure with each other. Express route will not suffice as this is considerably costlier than Site-to-Site VPN. Express route will not suffice as this is used to connect large sites to Azure directly with low latency and high bandwidth.


---
Create a Site-to-Site connection in the Azure portal;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-portal
###
You are the architect of the ACME shipping group. You are responsible for designing remote connectivity between your head office and your virtual network in Azure. The connection needs to be private, high speed and low latency. The bandwidth requirement is also very large, estimated at 25Gbps. What connectivity solution should be used?


---
​
Virtual Network Peering
​
Point-to-Site VPN
​
Site-to-site VPN
​
Express route *
---
Express route is correct as this is used to connect large sites to Azure directly with low latency and high bandwidth. Site-to-Site VPN will not suffice as the connection speed supports up to 1 Gbps per tunnel. Virtual Network Peering will not suffice as this is used to connect virtual networks in Azure with each other. Point-to-Site VPN will not suffice as this is used for remote users to connect individually to the Azure VNets.


---
Azure ExpressRoute;https://azure.microsoft.com/en-us/services/expressroute/
###
You are the administrator of the ACME banking group. You are responsible for managing identities and their roles within the organization. You need to delegate the minimum access to the new IT support engineer to reset user passwords in AAD. Which RBAC role should you assign to the support engineer?


---
User Administrator
​
Password Administrator *

​
Global Administrator

​
Service Administrator
---
Password administrator is correct as this role allows passwords to be reset for non-admin accounts and helpdesk admins. Global administrator will not suffice as this role grants access to all aspects for Azure AD and Microsoft services that are in Azure. User administrator will not suffice as this role allows management of all aspects of users, groups and admin password resets. Service administrator will not suffice as this role provides read access to health information and manage support requests.


---
https://docs.microsoft.com/en-us/azure/active-directory/users-groups-roles/directory-assign-admin-roles;https://docs.microsoft.com/en-us/azure/active-directory/users-groups-roles/directory-assign-admin-roles
###
You are the administrator of the ACME banking group. You are responsible for managing identities and their roles within the organization. You have been tasked to supply a specific guest account the minimal rights to the firewall VM in the IT resource group. The guest account should only be able to view and reboot the firewall VM. Which custom Role-Based Access Control (RBAC) permission should the new role have?


---
​
Microsoft.Compute/virtualMachines/restart/action *
​
Microsoft.Compute/virtualMachines/start/action
​
Microsoft.ClassicCompute/virtualMachines/*Reader role
​
Microsoft.Compute/virtualMachines/deallocate/action
---
Microsoft.Compute/virtualMachines/restart/action * is correct as this provides the restart ability. Microsoft.Compute/virtualMachines/start/action will not suffice as this will only allow starting the VM. Microsoft.ClassicCompute/virtualMachines/*Reader role will not suffice as this will only allow viewing the VM. Microsoft.Compute/virtualMachines/deallocate/action will not suffice as this will only allow the stop functionality and release the compute resources.


---
https://docs.microsoft.com/en-us/azure/role-based-access-control/custom-roles;https://docs.microsoft.com/en-us/azure/role-based-access-control/custom-roles
###
You are the administrator of the ACME banking group. Your company makes use of Microsoft Teams as a communication tool. Every time a new user joins the company HR manually creates a new post welcoming the users. You are tasked to automate this process by implementing a low-cost solution without having to write code for the solution to work. What technology should you implement based on the requirements?


---
Function App
​
Logic App *
​
Event Grid
​
Service Bus
---
Logic App is correct as this can be used to create workflows without having to write code (i.e. when a new user is created post a new chat in MS Teams welcoming them). Functions will not suffice as they are more focused on executing code without having to use IaaS and this requires to write code. Event Grid will not suffice as this is more focused on serverless events like events from blob storage, resource groups, and even custom events. Service bus will not suffice as is used where messaging between platforms is decoupled, an example would be interbank transfers as the banks do not have to be integrated on know about each other, hence this will not suffice as Teams is responsible for the messaging in this scenario.
---
https://docs.microsoft.com/en-us/azure/logic-apps/;https://docs.microsoft.com/en-us/azure/logic-apps/
###
You are the architect of the ACME shipping group. You are responsible for designing a solution which should automatically monitor events and action-specific events. You are tasked to design a solution that should automatically notify you via email when a new resource is created or deleted in the "Production" resource group. Which technology should you use to create and send events?


---
Event Hub
​
Event Grid *
​
Resource Lock
​
Service Bus
---
Event grid is correct as this is can be used to create events when resources are deleted or created within a resource group. Once the event is created, you can configure a function trigger or logic app to send an email notification. Event hubs are used to ingest and process real-time data streams from apps or devices. Resource lock will not suffice, as the requirement is to be notified when a resource is created/deleted, not to prevent it from happening. Service bus will not suffice this is primarily used to send messages between applications that are decoupled.


---
Event Grid;https://azure.microsoft.com/en-us/services/event-grid/


###
You are the administrator of the ACME banking group. You are responsible for managing all virtual machines on Azure. The security team requests that all Linux VMs must use an authentication method other than passwords. Which authentication method should be used?


---
SSH Public Key Authentication *
​
Use Root Access
​
Azure Key Vault Secret
---
SSH authentication is correct as this will use a key on your local machine with the password to authenticate.  Root access will not suffice as this is not recommended and you will still need to enter the root password. Azure key vault secret will not suffice as this still uses a password to authenticate, even if it is stored in a secure place.


---
Quick steps: Create and use an SSH public-private key pair for Linux VMs in Azure;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys
###
You are the architect for the ACME shipping group. You are responsible for designing the integration of 2 existing applications at a high level, one app is running on-premises and the other running in Azure. The integration requires a secure connection between the two apps directly, without exposing other resources on-premises or in Azure. Which technology would be the best fit?

---
​
Point-to-Site VPN
​
Site-to-Site VPN
​
Azure Relay *

​
NSG Rules
---
Azure relay service is correct as this is far less intrusive, this is used to securely connect hybrid applications which can be scoped to a single application endpoint on a single machine. This connection is seen as peer-to-peer without exposing other elements as VPN would. Site-to-Site VPN will not suffice as this would not create a direct link between the two apps without exposing other resources. Point-to-Site will not suffice as the Azure portion must be linked to a VNet which exposes other resources.  NSG’s are used to allow and block traffic, it cannot be used to link hybrid environments, only manage basic firewall rules once the connection is already configured.


---
What is Azure Relay?;https://docs.microsoft.com/en-us/azure/service-bus-relay/relay-what-is-it
###
You are the architect of the ACME shipping group. You are responsible for designing a notification system that will be used to send promotional content via push notifications to millions of devices. The design should cater to all popular platforms like Android, iOS, and Windows. You are also planning to use this solution with shared access secrets. Which of the following technologies would best fit the design?


---
​
Event Hub
​
Service Bus
​
Event Grid
​
Notification Hub *
---
Notification Hub is correct as this supports the sending of large amounts of data to the popular devices via PUSH notifications as well as make use of shared access secrets. Event Hub will not suffice as this is used to collect millions of events per second for processing, not sending the notifications. Service bus will not suffice, as this is a messaging service and not a notification service. Service bus is used for apps that make use of transactions, ordering, and duplicate detection as well as apps that require handling of high-value messages that cannot be lost. Event Grid would not suffice as this is used to provide developers access to the events generated by cloud infrastructure.


---
Notification Hubs;https://azure.microsoft.com/en-us/services/notification-hubs/
###
You are the architect of the ACME shipping group. You are responsible for designing a messaging system that will be used when users purchase goods, as such the messaging system needs to be reliable. Which of the following technologies would be the best for the design?


---
Event Hub
​
Service Bus *
​
Event Grid
​
Notification Hub
---
Service bus is correct as this is used as a reliable messaging service. Notification Hub will not suffice as this is used to send PUSH notifications on a large scale. Event Hub will not suffice as this is used to collect millions of events per second for processing. Event Grid would not suffice as this is used to provide developers access to the events generated by cloud infrastructure.


---
###
You are the architect of the ACME shipping group. You are responsible for designing autoscaling solutions. You have a VM whose sole purpose is to run a specific job every 8 hours. Which autoscaling pattern would be the best fit?


---
​
Off and On *
​
Adding Resources

​
Unpredictable by CPU
​
Predictable
---
Off and On is correct, as this autoscaling pattern should be used to start and stop a VM when not in use. Adding resources pattern will not suffice, as there is not a huge load consistently on the machine. Unpredictable autoscaling will not suffice as this pattern is used for example when the CPU threshold is above 95% for 5 minutes and needs to add more resources, which in this case is not needed. Predictable will not suffice as this is primarily used when you know or suspect when resources will be maxed out, an example of predictable autoscaling would be to add resources before the Superbowl adverts go live and you predict a surge in traffic.

Overview of common autoscale patterns;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/autoscale-common-scale-patterns
---
###
You are the architect of the ACME shipping group. You are responsible for designing autoscaling solutions. You have a web server which runs at a load of 70-90% most of the time. Which autoscaling pattern would be the best fit?


---
Off and On
​
Unpredictable by CPU
​
Adding Resources *

​
Predictable
---
Adding resources is correct as you can scale this solution manually. Off and On autoscaling will not suffice as this solution is already working full time at a high capacity, shutting it down will not improve anything. Unpredictable autoscaling will not suffice as this pattern is used for example when the CPU threshold is above 95% for 5 minutes and you did not predict it, however, the current load is consistently running around 70-90%. Predictable autoscaling will not suffice as this is primarily used when you know or suspect when resources will be maxed out, however in this scenario resources are already maxed out and needs immediate attention.


---
Overview of autoscale in Microsoft Azure Virtual Machines, Cloud Services, and Web Apps;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/autoscale-overview
###
You are the architect of the ACME shipping group. You are responsible for designing autoscaling solutions. The marketing team is currently running several small advertisement campaigns and you are unsure how this will affect the traffic to the current webserver, which is running in full production mode 24x7. Which autoscaling pattern would be the best fit?
---
Unpredictable by CPU *
​
Off and On
​
Predictable
​
Adding resources
---
Unpredictable autoscaling is correct, as this solution will enable you to auto-scale when the parameters you configure are met. Adding resources autoscaling will not suffice as you are unsure of when to add additional resources and not sure how much more resources. Predictable autoscaling will not suffice as you are unsure if and when the resources need autoscaling. Off and On autoscaling will not suffice, as this resource needs to run 24x7.


---
Overview of autoscale in Microsoft Azure Virtual Machines, Cloud Services, and Web Apps;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/autoscale-overview
###
You are the architect of the ACME shipping group. You are responsible for designing autoscaling solutions. You are preparing for Black Friday sale, which in history brings loads of additional traffic to the current webserver, which is running in full production mode 24x7. Which autoscaling pattern would be the best fit?


---
Off and On
​
Unpredictable by CPU
​
Adding resources
​
Predictable *
---
Predictable autoscaling is correct, as you know there will be a huge spike in traffic as per recent years. Off and On is not an option, as you cannot turn off a 24x7-production system. Adding resources autoscaling will not suffice as you are unsure of when to add additional resources and not sure how much more resources. Unpredictable autoscaling is not ideal you are aware that the traffic load will increase, however, this might be considered a second option.
---
Overview of autoscale in Microsoft Azure Virtual Machines, Cloud Services, and Web Apps;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/autoscale-overview
###
You are the administrator of the ACME banking group. You are responsible for designing a notification system that will send a confirmation email to users when they purchased a new service. The solution also requires to make use of distribution lists as well as collecting real-time metrics of who blocked email engagement. Which of the following technologies would best fit the design?


---
​
SendGrid *
​
Notification Hub
​
Service Bus
​
Event Grid
---
SendGrid is correct, as this is an email solution that provides email functionality via distribution groups as well as metric gathering. Notification Hub will not suffice as this is used to send PUSH notifications on a large scale. Event Grid would not suffice as this is used to provide developers access to the events generated by cloud infrastructure. Service bus will not suffice, as this is a messaging service and not a notification service.


---
SendGrid on Microsoft Azure;https://sendgrid.com/partners/azure/
###
You are the architect of the ACME shipping group. You are responsible for designing a solution that tracks all IoT data from all shipping containers worldwide. You are concerned about the load the traffic will put on the backend systems. You need to decide which technology will be able to ingest these large amounts of data and temporary store and process them. Which of the following technologies would be the best for the design?


---
Event Grid
​
Event Hub *
​
Notification Hub
​
Service Bus
---
Event Hub is correct as this allows large quantities of events to be ingested, processed and temporarily stored. Event Grid would not suffice as this is used to provide developers access to the events generated by cloud infrastructure. Notification Hub will not suffice as this is used to send PUSH notifications on a large scale. Service bus will not suffice as this is a messaging service and not an ingestion and processing service.
---

###
You are the administrator of the ACME banking group. You are responsible for maintaining certificates in Azure Key Vault. Is it possible to do auto-renewal of certificates before they expire?


---
TRUE *
​
FALSE
---
True is correct. It is possible to renew certificates in the Key Vault automatically before they expire.


---
Update Certificate - Update Certificate;https://docs.microsoft.com/en-us/rest/api/keyvault/updatecertificate/updatecertificate
###
You are the administrator of the ACME banking group. You are responsible for security on the Azure SQL database called SQL_DB_Main. You have been tasked to ensure that all data in transit should be encrypted as well as that database administrators are not able to view sensitive information in the database. Which encryption technology should be used?


---

Transparent Data Encryption (TDE)
​
Always Encrypted *
---
Always encrypted is correct, as this ensures encryption happens during transport and that the encryption keys are never revealed to the database engine. Transparent Data Encryption will not suffice as this is database-level encryption, which means data is protected at rest.


---
https://docs.microsoft.com/en-us/azure/sql-database/sql-database-always-encrypted;https://docs.microsoft.com/en-us/azure/sql-database/sql-database-always-encrypted
###
You are the administrator of the ACME banking group. You are responsible for security on the Azure SQL database called SQL_DB_Main. The requirement from the auditors is that all data in the database needs to be encrypted as rest. Which encryption technology should be used?


---
​
Transparent Data Encryption (TDE) *
​
Always Encrypted
---
Transparent Data Encryption is correct as it is intended to add a layer of security to protect data at rest from offline access to raw files or backups. Always Encrypted is used for encrypted in transit and prevent database admins from viewing sensitive data in the database.


---
Transparent data encryption for SQL Database and Azure Synapse;https://docs.microsoft.com/en-us/azure/sql-database/transparent-data-encryption-azure-sql?tabs=azure-portal
###
You are the architect for the ACME shipping group. You are responsible for designing a secure solution for one of the new applications that have very sensitive intellectual property code and data going to run on it. Which technology would be best suited?


---
Azure Confidential Compute with the F-Series VMs
​
Azure Confidential Compute with the L-series VMs
​
Azure Confidential Compute with the M-Series VMs
​
Azure Confidential Compute with the DC-series VMs *
---
Azure Confidential Compute (ACC) is only supported on the DC-Series VMs, Azure Confidential Compute allows code and data in the processor to be secured when running. Azure Confidential Compute is not supported on any other VM series except DC-series.


---
###
You are the administrator of the ACME banking group. You are responsible for managing the key vault in Azure. You need to create a new certificate in the ACMEvault with a key size of 2018 and that cannot be reused via an API call, which should be called ACMEcertificate. Which statement below is correct?


---
POST https://ACMEvault.vault.azure.net/certificates/{ACMEcertificate}/create?api-version=7.0 *
​
POST http://ACMEvault.vault.azure.net/certificates/{ACMEcertificate}/create?api-version=7.0
​
GET https://ACMEvault.vault.azure.net/certificates/{ACMEcertificate}/create?api-version=7.0
​
SET https://ACMEvault.vault.azure.net/certificates/{ACMEcertificate}/create?api-version=7.0
---
POST {https://ACMEvault.vault.azure.net}/certificates/{ACMEcertificate}/create?api-version=7.0 is correct as this follows the correct way to create a new certificate. Here is the way the statement is used in general: POST {vaultBaseUrl}/certificates/{certificate-name}/create?api-version=7.0. It uses HTTPS by default, GET and SET are incorrect when creating a new certificate.


---
https://docs.microsoft.com/en-us/rest/api/keyvault/createcertificate/createcertificate;https://docs.microsoft.com/en-us/rest/api/keyvault/createcertificate/createcertificate
###
C
You are the administrator of the ACME banking group. You are responsible for managing the key vault in Azure. You need to delete an existing certificate in the ACMEvault called ACMEcertificate via an API call. This certificate must not be recoverable after deletion. Select which 2 API statements below are required?


---
DELETE https://ACMEvault.vault.azure.net/certificates/ACMEcertificate/create?api-version=7.0 *

​
DELETE http://ACMEvault.vault.azure.net/certificates/ACMEcertificate/create?api-version=7.0

​
DELETE https://ACMEvault.vault.azure.net/deletedcertificates/ACMEcertificate/create?api-version=7.0 *

​
DELETE http://ACMEvault.vault.azure.net/deletedcertificates/ACMEcertificate/create?api-version=7.0
---
1 and 3 is correct as we need to do a soft delete of the certificate, once done we need to purge the deleted certificate so that it cannot be restored. 2,4 are incorrect as the vault address is using HTTP instead of HTTPS.


---
Delete Certificate - Delete Certificate;https://docs.microsoft.com/en-us/rest/api/keyvault/deletecertificate/deletecertificate
###
You are the administrator of the ACME banking group. You are responsible for managing the key vault in Azure called ACMEvault. You have decommissioned a production server that has its password stored in the key vault labeled "FinanceAdmin". You need to remove the password from the vault by using an API call. Which API call is correct?


---
REMOVE https://ACMEvault.vault.azure.net/secrets/FinanceAdmin?api-version=7.0
​
PURGE https://ACMEvault.vault.azure.net/secrets/FinanceAdmin?api-version=7.0
​
DELETE https://ACMEvault.vault.azure.net/secrets/FinanceAdmin?api-version=7.0 *
​
RECOVER https://ACMEvault.vault.azure.net/secrets/FinanceAdmin?api-version=7.0
---
DELETE is the correct operation name as it references the correct vault and secret name. REMOVE not a valid operation name. PURGE is used to remove the password irreversibly, almost the same as emptying the recycle bin on your desktop. RECOVER will not suffice as this is used to recover a deleted secret on soft-delete enabled vaults.


---
Delete Secret - Delete Secret;https://docs.microsoft.com/en-us/rest/api/keyvault/deletesecret/deletesecret
###
You are the architect of the ACME shipping group. You are responsible for designing the migration for a production Web app from on-premises to publish code in Azure. The Web App requires to be linked to your company’s domain name as well as have 5 staging slots. The solution needs to be backed up daily as well. Which if of the following App Service Plan tiers will suffice and be the most cost-effective?


---
​
Production1 Version 2 (P1V2)
​
Development 1 (D1)
​
Standard 1 (S1) *
​
Basic 1 (B1)
---
Standard Tier 1 plan is correct as it caters for custom domain names, has 5 staging slots, supports daily backup as well as being the most cost-effective solution. D1 plan only supports custom domains and not the other technical requirements. B1 plan supports custom domain names and manual scaling, however not the other technical requirements like backup and staging slots. P1V2 will suffice from a technical perspective however its not the most cost-effective solution compared to S1.


---

###
You are the architect of the ACME shipping group. You are responsible for designing the migration for a production Web app from on-premises to publish code in Azure. The Web App requires to be linked to your company’s domain name and scale manually with a dedicated instance. Daily backups and staging slots are not a requirement. Which if of the following App Service Plan tiers will suffice and be the most cost-effective?


---
Production1 Version 2 (P1V2)
​
Development 1 (D1)
​
Standard 1 (S1)
​
Basic 1 (B1) *
---
The B1 plan is correct, as this is the most cost-effective solution that provides custom domains and manual scalability. P1v2, D1, and S1 supports autoscaling and custom domains, however its not the most cost-effective solution.


---
###
You are the administrator of the ACME banking group. You want to deploy an application as code to Azure for testing. The only requirement is that this solution does not incur any costs while in testing mode. Which if of the following App Service Plan tiers will suffice and be the most cost-effective?


---
Development 1 (D1)
​
Standard 1 (S1)
​
Basic 1 (B1)

​
F1 *
---
The F1 plan is correct, as this is the free version of the App service Plan, however, limited in functionality. D1,B1 and S1 tiers all will incur costs, even if they have more functionalities.


---
###
You are the architect of the ACME shipping group. You are responsible for designing the migration for a production Web app from on-premises to publish code in Azure. The Web App handles very sensitive information and therefore needs to run on an isolated network. The App also requires at least 4.5 GB of memory to run and needs to scale when needed. Which if of the following App Service Plan tiers will suffice and be the most cost-effective?


---
Production 3 Version 2 (P3V2)
​
Isolated 1 (I1)

​
Isolated 2 (I2) *

​
Isolated (I3)
---
The I2 plan is correct as this supports the single-tenant system with the option to run the Web App on your virtual network and supports 7GB of memory, I2 is also the most cost-effective. I1 supports the technical requirements however it only has 3.5GB of memory. I3 supports all the requirements however, it's not the most cost-effective option. P3V2 does not support the single-tenant system and isolated networks.


---

###
C
You are the administrator of the ACME banking group. You want to deploy your Web App code to Azure. Which of the following applications does Azure support with regards to continuous deployment, select all supported solutions.


---
Bitbucket *
​
GitHub *
​
Azure Repos *
​
OneDrive
​
DropBox
​
FTP
---
Bitbucket, GitHub and Azure repo's are supported for continuous deployment. OneDrive, Dropbox and FTP does support deployment however not continuous integration.


---
Azure Repos Documentation;https://docs.microsoft.com/en-us/azure/devops/repos/?view=azure-devops
###
You are the administrator of the ACME banking group. You have a multi-container Web App running in production, however, you need to run a continuous job on the Web App to clean up a directory. Which of the following should you configure?


---
​
Create a continuous Multi-Instance WebJob
​
Create a continuous Single-Instance WebJob as a Continuous Type *
​
Create a triggered Single-Instance WebJob as a Continuous Type
​
Create a triggered Multi-Instance WebJob as a Continuous Type
---
Creating a continuous Single-Instance WebJob is correct as this needs to be a continuous and a single instance, it is not recommended to use multi-instance to cleanup directories as they do the same job at the same time. The type should not be triggered as the requirement is continuous.


---
Run background tasks with WebJobs in Azure App Service;https://docs.microsoft.com/bs-latn-ba/azure/app-service/webjobs-create
###
You are the architect of the ACME shipping group. You are responsible for designing a Kubernetes cluster for future workloads and need to provide guidance to the technical team. Which of the following cannot be changed once a Kubernetes cluster is created?


---
Node Size *
​
Node Count
​
RBAC Enablement

​
HTTP Application Routing
---
Node size cannot be changed once the Kubernetes cluster is created. Node count, enabling RBAC and HTTP application routing settings can all be changed after the cluster is created.


---
Quotas, virtual machine size restrictions, and region availability in Azure Kubernetes Service (AKS);https://docs.microsoft.com/en-us/azure/aks/quotas-skus-regions
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
###
---
---
---
